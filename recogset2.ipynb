{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recogset2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alicetears/thanadolsingkhornart/blob/master/recogset2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9Xgu1PBr6Z_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "068514b3-5326-4b2f-b16f-5acbfcfeaf01"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYQBMIoxp6WZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import fnmatch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import string\n",
        "import time\n",
        "import sys\n",
        "\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
        "from keras.models import Model\n",
        "from keras.activations import relu, sigmoid, softmax\n",
        "import keras.backend as K\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "\n",
        "# ignore warnings in the output\n",
        "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "# Check all available devices if GPU is available\n",
        "# print(device_lib.list_local_devices())\n",
        "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "\n",
        "import string\n",
        "# char_list:   'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
        "# total number of our output classes: len(char_list)\n",
        "char_list = string.ascii_letters+string.digits + \\\n",
        "    'กขขคฃฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮ ่้๊๋็ุูึืิี์ัํฯำใไโาๅเแะๆ๑๒๓๔๕๖๗๘๙๐.,!()-$฿'\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd8SfMZU6wNE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eae43618-0ecc-440f-b32b-2316e18e5afd"
      },
      "source": [
        "len(char_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbRaJh25uZXf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55893476-e2ab-450b-a11b-f59142a40f9f"
      },
      "source": [
        "! ls '/content/drive/My Drive/recog/allDataSet'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best_model.hdf5  trains  validations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBf3FtJRqcNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage import transform\n",
        "\n",
        "def encode_to_labels(txt):\n",
        "    # encoding each output word into digits\n",
        "    dig_lst = []\n",
        "    for index, char in enumerate(txt):\n",
        "        try:\n",
        "            dig_lst.append(char_list.index(char))\n",
        "        except:\n",
        "            print(char)\n",
        "\n",
        "    return dig_lst\n",
        "\n",
        "\n",
        "Max_char = 90\n",
        "def read_dataset(path):\n",
        "    # lists for training dataset\n",
        "    training_img = []\n",
        "    training_txt = []\n",
        "    train_input_length = []\n",
        "    train_label_length = []\n",
        "    orig_txt = []\n",
        "\n",
        "    # lists for validation dataset\n",
        "    valid_img = []\n",
        "    valid_txt = []\n",
        "    valid_input_length = []\n",
        "    valid_label_length = []\n",
        "    valid_orig_txt = []\n",
        "\n",
        "    max_label_len = 0\n",
        "    all=2733\n",
        "    i = 1\n",
        "    flag = 0\n",
        "    count = 0\n",
        "    for root, dirnames, filenames in os.walk(path):\n",
        "        for f_name in fnmatch.filter(filenames, '*.jpg'):\n",
        "            sys.stdout.write('\\r'+str(count/all*100)+'%')\n",
        "            sys.stdout.flush()\n",
        "            #if count==all:\n",
        "              #filename = 'myfile.wav'\n",
        "              #wave_obj = sa.WaveObject.from_wave_file(filename)\n",
        "              #play_obj = wave_obj.play()\n",
        "              #play_obj.wait_done()\n",
        "            count += 1\n",
        "            # read input image and convert into gray scale image\n",
        "            img = cv2.cvtColor(cv2.imread(\n",
        "                os.path.join(root, f_name)), cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # convert each image of shape (32, 128, 1)\n",
        "            img = transform.resize(img, (32, int(128/31*Max_char)))\n",
        "\n",
        "            # get the text from the image\n",
        "            dtxt = f_name.split('.jpg')[0]\n",
        "            txt = dtxt.split('_')[1]\n",
        "            #print('\\t'+txt+'\\t'+f_name)\n",
        "\n",
        "            # compute maximum length of the text\n",
        "            if len(txt) > max_label_len:\n",
        "                max_label_len = len(txt)\n",
        "\n",
        "            # split the 150000 data into validation and training dataset as 10% and 90% respectively\n",
        "            #valid_orig_txt.append(txt)\n",
        "            #valid_label_length.append(len(txt))\n",
        "            #valid_input_length.append(31)\n",
        "            #valid_img.append(img)\n",
        "            #valid_txt.append(encode_to_labels(txt))\n",
        "            orig_txt.append(txt)\n",
        "            train_label_length.append(len(txt))\n",
        "            train_input_length.append(Max_char)\n",
        "            training_img.append(img)\n",
        "            training_txt.append(encode_to_labels(txt))\n",
        "    return orig_txt, training_txt, training_img, train_input_length, train_label_length, max_label_len\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_G9PILQ5jK8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee198ce5-71a8-41f6-e10a-03c7024b4a30"
      },
      "source": [
        "orig_txt, training_txt, training_img, train_input_length, train_label_length, max_label_len = read_dataset('/content/drive/My Drive/recognition/set2/train')\n",
        "valid_orig_txt, valid_txt, valid_img, valid_input_length, valid_label_length, max_label_len = read_dataset('/content/drive/My Drive/recognition/set2/test')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19.978046103183313%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AheJMrRMyrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_label_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0BLzS9Mqq0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "inputs = Input(shape=(32, int(128/31*Max_char), 1))\n",
        "\n",
        "# convolution layer with kernel size (3,3)\n",
        "conv_1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "# poolig layer with kernel size (2,2)\n",
        "pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
        "\n",
        "conv_2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool_1)\n",
        "pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
        "\n",
        "conv_3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool_2)\n",
        "\n",
        "conv_4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv_3)\n",
        "# poolig layer with kernel size (2,1)\n",
        "pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
        "\n",
        "conv_5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool_4)\n",
        "# Batch normalization layer\n",
        "batch_norm_5 = BatchNormalization()(conv_5)\n",
        "\n",
        "conv_6 = Conv2D(512, (3, 3), activation='relu', padding='same')(batch_norm_5)\n",
        "batch_norm_6 = BatchNormalization()(conv_6)\n",
        "pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
        "\n",
        "conv_7 = Conv2D(512, (2, 2), activation='relu')(pool_6)\n",
        "\n",
        "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
        "\n",
        "# bidirectional LSTM layers with units=128\n",
        "blstm_1 = Bidirectional(\n",
        "    LSTM(128, return_sequences=True, dropout=0.2))(squeezed)\n",
        "blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(blstm_1)\n",
        "\n",
        "outputs = Dense(len(char_list)+1, activation='softmax')(blstm_2)\n",
        "\n",
        "# model to be used at test time\n",
        "act_model = Model(inputs, outputs)\n",
        "\n",
        "# act_model.summary()\n",
        "\n",
        "\n",
        "labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        " "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgDObD_w3wDs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "92878854-90d1-4750-f537-ab8287cda6ad"
      },
      "source": [
        "labels, outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor 'the_labels:0' shape=(None, 90) dtype=float32>,\n",
              " <tf.Tensor 'dense/truediv:0' shape=(None, 91, 153) dtype=float32>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kH_FrPNqySj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "03983eef-9203-4817-cf75-1b5d7db1f71e"
      },
      "source": [
        "act_model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 371, 1)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 371, 64)       640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 185, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 185, 128)      73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 92, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 92, 256)        295168    \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 92, 256)        590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 92, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 92, 512)        1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 4, 92, 512)        2048      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 92, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4, 92, 512)        2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 92, 512)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 1, 91, 512)        1049088   \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (None, 91, 512)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 91, 256)           656384    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 91, 256)           394240    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 91, 153)           39321     \n",
            "=================================================================\n",
            "Total params: 6,642,841\n",
            "Trainable params: 6,640,793\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eIq9SKJrQDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        " \n",
        " \n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        " \n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        " \n",
        " \n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
        "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
        "\n",
        "# model to be used at training time\n",
        "model = Model(inputs=[inputs, labels, input_length,\n",
        "                      label_length], outputs=loss_out)\n",
        "\n",
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')\n",
        " "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N9Dvc2J3j6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "0ad12e1f-24a5-444c-ba79-d2f9784526c4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 371, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 371, 64)  640         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 16, 185, 64)  0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 16, 185, 128) 73856       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 8, 92, 128)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 8, 92, 256)   295168      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 8, 92, 256)   590080      conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 4, 92, 256)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 4, 92, 512)   1180160     max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 4, 92, 512)   2048        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 4, 92, 512)   2359808     batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 4, 92, 512)   2048        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 2, 92, 512)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 1, 91, 512)   1049088     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 91, 512)      0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 91, 256)      656384      lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 91, 256)      394240      bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 91, 153)      39321       bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "the_labels (InputLayer)         [(None, 76)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "label_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ctc (Lambda)                    (None, 1)            0           dense[0][0]                      \n",
            "                                                                 the_labels[0][0]                 \n",
            "                                                                 input_length[0][0]               \n",
            "                                                                 label_length[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 6,642,841\n",
            "Trainable params: 6,640,793\n",
            "Non-trainable params: 2,048\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stnQn1Tzq2lO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "filepath='/content/drive/My Drive/recognition/set2/best_model2.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "train_padded_txt = pad_sequences(\n",
        "    training_txt, maxlen=max_label_len, padding='post', value=len(char_list))\n",
        "valid_padded_txt = pad_sequences(\n",
        "    valid_txt, maxlen=max_label_len, padding='post', value=len(char_list))\n",
        "# input with shape of height=32 and width=128\n",
        "\n",
        "training_img = np.array(training_img)\n",
        "train_input_length = np.array(train_input_length)\n",
        "train_label_length = np.array(train_label_length)\n",
        "\n",
        "valid_img = np.array(valid_img)\n",
        "valid_input_length = np.array(valid_input_length)\n",
        "valid_label_length = np.array(valid_label_length)\n",
        "#alid_orig_txt = training_txt\n",
        "#valid_img = training_img"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvkTi_z0N6pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#nn = (training_img.shape[0]*1)//4\n",
        "#valid_img = training_img[:nn]\n",
        "#valid_padded_txt = train_padded_txt[:nn]\n",
        "#valid_input_length = train_input_length[:nn]\n",
        "#valid_label_length = train_label_length[:nn]\n",
        "\n",
        "#training_img = training_img[nn:]\n",
        "#train_padded_txt = train_padded_txt[nn:]\n",
        "#train_input_length = train_input_length[nn:]\n",
        "#train_label_length = train_label_length[nn:]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymZPE8Y1uKby",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fccb86a0-7225-461c-8858-e503b07a6468"
      },
      "source": [
        "\n",
        "\n",
        "batch_size = 256\n",
        "epochs = 1000\n",
        "history=model.fit(x=[training_img, train_padded_txt, train_input_length, train_label_length], y=np.zeros(len(training_img)), batch_size=batch_size, epochs=epochs,validation_data=([valid_img, valid_padded_txt, valid_input_length, valid_label_length], [np.zeros(len(valid_img))]), verbose=1, callbacks=callbacks_list)\n",
        "\n",
        "#inputs, labels, input_length,\n",
        "                      #label_length"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 186.6843\n",
            "Epoch 00001: val_loss improved from inf to 127.76978, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 22s 2s/step - loss: 186.6843 - val_loss: 127.7698\n",
            "Epoch 2/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 118.1779\n",
            "Epoch 00002: val_loss improved from 127.76978 to 119.56374, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 118.1779 - val_loss: 119.5637\n",
            "Epoch 3/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 113.2119\n",
            "Epoch 00003: val_loss did not improve from 119.56374\n",
            "9/9 [==============================] - 12s 1s/step - loss: 113.2119 - val_loss: 120.3555\n",
            "Epoch 4/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 110.9064\n",
            "Epoch 00004: val_loss did not improve from 119.56374\n",
            "9/9 [==============================] - 12s 1s/step - loss: 110.9064 - val_loss: 125.1311\n",
            "Epoch 5/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 109.7783\n",
            "Epoch 00005: val_loss did not improve from 119.56374\n",
            "9/9 [==============================] - 12s 1s/step - loss: 109.7783 - val_loss: 125.0509\n",
            "Epoch 6/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 108.9819\n",
            "Epoch 00006: val_loss did not improve from 119.56374\n",
            "9/9 [==============================] - 12s 1s/step - loss: 108.9819 - val_loss: 126.9245\n",
            "Epoch 7/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 108.7312\n",
            "Epoch 00007: val_loss improved from 119.56374 to 114.84837, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 108.7312 - val_loss: 114.8484\n",
            "Epoch 8/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 108.4833\n",
            "Epoch 00008: val_loss did not improve from 114.84837\n",
            "9/9 [==============================] - 12s 1s/step - loss: 108.4833 - val_loss: 120.4223\n",
            "Epoch 9/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 108.4198\n",
            "Epoch 00009: val_loss improved from 114.84837 to 113.23808, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 108.4198 - val_loss: 113.2381\n",
            "Epoch 10/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 108.1885\n",
            "Epoch 00010: val_loss did not improve from 113.23808\n",
            "9/9 [==============================] - 12s 1s/step - loss: 108.1885 - val_loss: 113.4752\n",
            "Epoch 11/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 108.0028\n",
            "Epoch 00011: val_loss did not improve from 113.23808\n",
            "9/9 [==============================] - 12s 1s/step - loss: 108.0028 - val_loss: 113.5901\n",
            "Epoch 12/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 107.6928\n",
            "Epoch 00012: val_loss did not improve from 113.23808\n",
            "9/9 [==============================] - 12s 1s/step - loss: 107.6928 - val_loss: 113.5728\n",
            "Epoch 13/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 107.3625\n",
            "Epoch 00013: val_loss did not improve from 113.23808\n",
            "9/9 [==============================] - 12s 1s/step - loss: 107.3625 - val_loss: 115.7512\n",
            "Epoch 14/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 106.8676\n",
            "Epoch 00014: val_loss improved from 113.23808 to 113.22089, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 106.8676 - val_loss: 113.2209\n",
            "Epoch 15/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 105.9867\n",
            "Epoch 00015: val_loss did not improve from 113.22089\n",
            "9/9 [==============================] - 12s 1s/step - loss: 105.9867 - val_loss: 115.7136\n",
            "Epoch 16/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 104.8981\n",
            "Epoch 00016: val_loss improved from 113.22089 to 112.77974, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 104.8981 - val_loss: 112.7797\n",
            "Epoch 17/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 103.4444\n",
            "Epoch 00017: val_loss improved from 112.77974 to 108.41927, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 103.4444 - val_loss: 108.4193\n",
            "Epoch 18/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 102.0384\n",
            "Epoch 00018: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 102.0384 - val_loss: 112.6518\n",
            "Epoch 19/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 99.8574\n",
            "Epoch 00019: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 99.8574 - val_loss: 109.4781\n",
            "Epoch 20/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 97.6948\n",
            "Epoch 00020: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 97.6948 - val_loss: 117.3863\n",
            "Epoch 21/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 95.3269\n",
            "Epoch 00021: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 95.3269 - val_loss: 118.3776\n",
            "Epoch 22/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 93.2596\n",
            "Epoch 00022: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 93.2596 - val_loss: 132.1759\n",
            "Epoch 23/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 90.2883\n",
            "Epoch 00023: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 90.2883 - val_loss: 126.8745\n",
            "Epoch 24/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 87.2163\n",
            "Epoch 00024: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 87.2163 - val_loss: 143.9564\n",
            "Epoch 25/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 83.9188\n",
            "Epoch 00025: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 83.9188 - val_loss: 139.5993\n",
            "Epoch 26/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 80.5802\n",
            "Epoch 00026: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 80.5802 - val_loss: 126.8086\n",
            "Epoch 27/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 77.2635\n",
            "Epoch 00027: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 77.2635 - val_loss: 126.2889\n",
            "Epoch 28/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 73.4336\n",
            "Epoch 00028: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 73.4336 - val_loss: 130.4963\n",
            "Epoch 29/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 69.2675\n",
            "Epoch 00029: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 69.2675 - val_loss: 141.0617\n",
            "Epoch 30/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 65.1074\n",
            "Epoch 00030: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 65.1074 - val_loss: 138.2485\n",
            "Epoch 31/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 60.6127\n",
            "Epoch 00031: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 60.6127 - val_loss: 143.2056\n",
            "Epoch 32/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 56.0031\n",
            "Epoch 00032: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 56.0031 - val_loss: 149.2033\n",
            "Epoch 33/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 51.9167\n",
            "Epoch 00033: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 51.9167 - val_loss: 145.8964\n",
            "Epoch 34/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 47.5770\n",
            "Epoch 00034: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 47.5770 - val_loss: 136.1672\n",
            "Epoch 35/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 43.4549\n",
            "Epoch 00035: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 43.4549 - val_loss: 124.9757\n",
            "Epoch 36/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 39.8503\n",
            "Epoch 00036: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 39.8503 - val_loss: 143.9808\n",
            "Epoch 37/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 36.5181\n",
            "Epoch 00037: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 36.5181 - val_loss: 136.8543\n",
            "Epoch 38/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 33.3194\n",
            "Epoch 00038: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 33.3194 - val_loss: 147.0231\n",
            "Epoch 39/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 31.0468\n",
            "Epoch 00039: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 31.0468 - val_loss: 137.8756\n",
            "Epoch 40/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 28.4136\n",
            "Epoch 00040: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 28.4136 - val_loss: 129.9081\n",
            "Epoch 41/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 26.0313\n",
            "Epoch 00041: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 26.0313 - val_loss: 134.0363\n",
            "Epoch 42/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 24.0210\n",
            "Epoch 00042: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 24.0210 - val_loss: 141.1092\n",
            "Epoch 43/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 21.9391\n",
            "Epoch 00043: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 21.9391 - val_loss: 135.2353\n",
            "Epoch 44/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 20.0565\n",
            "Epoch 00044: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 20.0565 - val_loss: 136.3620\n",
            "Epoch 45/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 18.5383\n",
            "Epoch 00045: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 18.5383 - val_loss: 134.7317\n",
            "Epoch 46/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 16.7134\n",
            "Epoch 00046: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 16.7134 - val_loss: 134.1202\n",
            "Epoch 47/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 15.1268\n",
            "Epoch 00047: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 15.1268 - val_loss: 147.9567\n",
            "Epoch 48/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 13.8904\n",
            "Epoch 00048: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 13.8904 - val_loss: 140.1319\n",
            "Epoch 49/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 12.7734\n",
            "Epoch 00049: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 12.7734 - val_loss: 122.6732\n",
            "Epoch 50/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 11.7494\n",
            "Epoch 00050: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 11.7494 - val_loss: 128.6072\n",
            "Epoch 51/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 10.7054\n",
            "Epoch 00051: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 10.7054 - val_loss: 135.1113\n",
            "Epoch 52/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.9411\n",
            "Epoch 00052: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 9.9411 - val_loss: 114.6998\n",
            "Epoch 53/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.0289\n",
            "Epoch 00053: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 9.0289 - val_loss: 125.9489\n",
            "Epoch 54/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 8.1754\n",
            "Epoch 00054: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 8.1754 - val_loss: 126.5831\n",
            "Epoch 55/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 7.4399\n",
            "Epoch 00055: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 7.4399 - val_loss: 128.0650\n",
            "Epoch 56/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 6.8808\n",
            "Epoch 00056: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 6.8808 - val_loss: 117.4857\n",
            "Epoch 57/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 6.2531\n",
            "Epoch 00057: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 6.2531 - val_loss: 132.4868\n",
            "Epoch 58/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 5.7953\n",
            "Epoch 00058: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 5.7953 - val_loss: 132.6208\n",
            "Epoch 59/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 5.3917\n",
            "Epoch 00059: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 5.3917 - val_loss: 122.4316\n",
            "Epoch 60/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 4.8766\n",
            "Epoch 00060: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 4.8766 - val_loss: 128.9262\n",
            "Epoch 61/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 4.4276\n",
            "Epoch 00061: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 4.4276 - val_loss: 129.3352\n",
            "Epoch 62/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 4.1453\n",
            "Epoch 00062: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 4.1453 - val_loss: 128.9684\n",
            "Epoch 63/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 3.7806\n",
            "Epoch 00063: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 3.7806 - val_loss: 122.6213\n",
            "Epoch 64/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 3.4725\n",
            "Epoch 00064: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 3.4725 - val_loss: 120.9287\n",
            "Epoch 65/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 3.1714\n",
            "Epoch 00065: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 3.1714 - val_loss: 121.4851\n",
            "Epoch 66/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 2.8936\n",
            "Epoch 00066: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 2.8936 - val_loss: 123.5661\n",
            "Epoch 67/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 2.5909\n",
            "Epoch 00067: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 2.5909 - val_loss: 118.7798\n",
            "Epoch 68/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 2.3584\n",
            "Epoch 00068: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 2.3584 - val_loss: 112.2698\n",
            "Epoch 69/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 2.1961\n",
            "Epoch 00069: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 2.1961 - val_loss: 117.6340\n",
            "Epoch 70/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 2.0287\n",
            "Epoch 00070: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 2.0287 - val_loss: 116.0336\n",
            "Epoch 71/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.9226\n",
            "Epoch 00071: val_loss did not improve from 108.41927\n",
            "9/9 [==============================] - 12s 1s/step - loss: 1.9226 - val_loss: 115.7325\n",
            "Epoch 72/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.7949\n",
            "Epoch 00072: val_loss improved from 108.41927 to 104.27077, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 1.7949 - val_loss: 104.2708\n",
            "Epoch 73/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.6384\n",
            "Epoch 00073: val_loss did not improve from 104.27077\n",
            "9/9 [==============================] - 12s 1s/step - loss: 1.6384 - val_loss: 107.7719\n",
            "Epoch 74/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.5100\n",
            "Epoch 00074: val_loss did not improve from 104.27077\n",
            "9/9 [==============================] - 12s 1s/step - loss: 1.5100 - val_loss: 104.7362\n",
            "Epoch 75/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.3966\n",
            "Epoch 00075: val_loss improved from 104.27077 to 103.83900, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 1.3966 - val_loss: 103.8390\n",
            "Epoch 76/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.3424\n",
            "Epoch 00076: val_loss improved from 103.83900 to 101.31097, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 1.3424 - val_loss: 101.3110\n",
            "Epoch 77/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.2247\n",
            "Epoch 00077: val_loss improved from 101.31097 to 88.70409, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 1.2247 - val_loss: 88.7041\n",
            "Epoch 78/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.1552\n",
            "Epoch 00078: val_loss did not improve from 88.70409\n",
            "9/9 [==============================] - 12s 1s/step - loss: 1.1552 - val_loss: 88.9299\n",
            "Epoch 79/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.0428\n",
            "Epoch 00079: val_loss improved from 88.70409 to 85.44513, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 1.0428 - val_loss: 85.4451\n",
            "Epoch 80/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.9673\n",
            "Epoch 00080: val_loss improved from 85.44513 to 78.68804, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.9673 - val_loss: 78.6880\n",
            "Epoch 81/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.9126\n",
            "Epoch 00081: val_loss improved from 78.68804 to 75.73790, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.9126 - val_loss: 75.7379\n",
            "Epoch 82/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.8546\n",
            "Epoch 00082: val_loss improved from 75.73790 to 67.90543, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.8546 - val_loss: 67.9054\n",
            "Epoch 83/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.8124\n",
            "Epoch 00083: val_loss improved from 67.90543 to 62.73067, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.8124 - val_loss: 62.7307\n",
            "Epoch 84/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7813\n",
            "Epoch 00084: val_loss improved from 62.73067 to 59.63081, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.7813 - val_loss: 59.6308\n",
            "Epoch 85/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7350\n",
            "Epoch 00085: val_loss improved from 59.63081 to 55.38221, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.7350 - val_loss: 55.3822\n",
            "Epoch 86/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6930\n",
            "Epoch 00086: val_loss improved from 55.38221 to 53.18624, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.6930 - val_loss: 53.1862\n",
            "Epoch 87/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6404\n",
            "Epoch 00087: val_loss did not improve from 53.18624\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.6404 - val_loss: 54.2467\n",
            "Epoch 88/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6201\n",
            "Epoch 00088: val_loss improved from 53.18624 to 50.95647, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.6201 - val_loss: 50.9565\n",
            "Epoch 89/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6029\n",
            "Epoch 00089: val_loss improved from 50.95647 to 45.82834, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.6029 - val_loss: 45.8283\n",
            "Epoch 90/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5841\n",
            "Epoch 00090: val_loss improved from 45.82834 to 42.13753, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.5841 - val_loss: 42.1375\n",
            "Epoch 91/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5515\n",
            "Epoch 00091: val_loss did not improve from 42.13753\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.5515 - val_loss: 43.1528\n",
            "Epoch 92/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5185\n",
            "Epoch 00092: val_loss improved from 42.13753 to 39.55534, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.5185 - val_loss: 39.5553\n",
            "Epoch 93/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4927\n",
            "Epoch 00093: val_loss improved from 39.55534 to 37.24770, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.4927 - val_loss: 37.2477\n",
            "Epoch 94/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4661\n",
            "Epoch 00094: val_loss improved from 37.24770 to 35.88837, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.4661 - val_loss: 35.8884\n",
            "Epoch 95/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4366\n",
            "Epoch 00095: val_loss improved from 35.88837 to 34.54428, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.4366 - val_loss: 34.5443\n",
            "Epoch 96/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4096\n",
            "Epoch 00096: val_loss improved from 34.54428 to 31.72058, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.4096 - val_loss: 31.7206\n",
            "Epoch 97/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3913\n",
            "Epoch 00097: val_loss improved from 31.72058 to 31.28437, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.3913 - val_loss: 31.2844\n",
            "Epoch 98/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3678\n",
            "Epoch 00098: val_loss improved from 31.28437 to 29.47460, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.3678 - val_loss: 29.4746\n",
            "Epoch 99/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3529\n",
            "Epoch 00099: val_loss improved from 29.47460 to 28.16529, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.3529 - val_loss: 28.1653\n",
            "Epoch 100/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3342\n",
            "Epoch 00100: val_loss did not improve from 28.16529\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.3342 - val_loss: 29.2737\n",
            "Epoch 101/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3219\n",
            "Epoch 00101: val_loss improved from 28.16529 to 28.07146, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.3219 - val_loss: 28.0715\n",
            "Epoch 102/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3067\n",
            "Epoch 00102: val_loss improved from 28.07146 to 28.00780, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.3067 - val_loss: 28.0078\n",
            "Epoch 103/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3066\n",
            "Epoch 00103: val_loss improved from 28.00780 to 24.91980, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.3066 - val_loss: 24.9198\n",
            "Epoch 104/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3056\n",
            "Epoch 00104: val_loss did not improve from 24.91980\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.3056 - val_loss: 26.0513\n",
            "Epoch 105/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2955\n",
            "Epoch 00105: val_loss did not improve from 24.91980\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2955 - val_loss: 25.4260\n",
            "Epoch 106/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2808\n",
            "Epoch 00106: val_loss did not improve from 24.91980\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2808 - val_loss: 25.5532\n",
            "Epoch 107/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2742\n",
            "Epoch 00107: val_loss improved from 24.91980 to 24.61789, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.2742 - val_loss: 24.6179\n",
            "Epoch 108/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2714\n",
            "Epoch 00108: val_loss improved from 24.61789 to 24.32082, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.2714 - val_loss: 24.3208\n",
            "Epoch 109/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2540\n",
            "Epoch 00109: val_loss did not improve from 24.32082\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2540 - val_loss: 24.6113\n",
            "Epoch 110/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2507\n",
            "Epoch 00110: val_loss improved from 24.32082 to 23.44727, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.2507 - val_loss: 23.4473\n",
            "Epoch 111/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2363\n",
            "Epoch 00111: val_loss did not improve from 23.44727\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2363 - val_loss: 24.6933\n",
            "Epoch 112/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2259\n",
            "Epoch 00112: val_loss improved from 23.44727 to 23.04799, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.2259 - val_loss: 23.0480\n",
            "Epoch 113/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2177\n",
            "Epoch 00113: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2177 - val_loss: 24.0004\n",
            "Epoch 114/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2040\n",
            "Epoch 00114: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2040 - val_loss: 24.1017\n",
            "Epoch 115/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2003\n",
            "Epoch 00115: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2003 - val_loss: 23.5989\n",
            "Epoch 116/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1894\n",
            "Epoch 00116: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1894 - val_loss: 23.7597\n",
            "Epoch 117/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1832\n",
            "Epoch 00117: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1832 - val_loss: 23.5773\n",
            "Epoch 118/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1786\n",
            "Epoch 00118: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1786 - val_loss: 23.7760\n",
            "Epoch 119/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1729\n",
            "Epoch 00119: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1729 - val_loss: 23.4243\n",
            "Epoch 120/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1688\n",
            "Epoch 00120: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1688 - val_loss: 23.6062\n",
            "Epoch 121/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1655\n",
            "Epoch 00121: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1655 - val_loss: 23.6333\n",
            "Epoch 122/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1580\n",
            "Epoch 00122: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1580 - val_loss: 23.3696\n",
            "Epoch 123/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1552\n",
            "Epoch 00123: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1552 - val_loss: 23.5174\n",
            "Epoch 124/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1508\n",
            "Epoch 00124: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1508 - val_loss: 23.6186\n",
            "Epoch 125/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1506\n",
            "Epoch 00125: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1506 - val_loss: 23.5691\n",
            "Epoch 126/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1553\n",
            "Epoch 00126: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1553 - val_loss: 23.2034\n",
            "Epoch 127/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2114\n",
            "Epoch 00127: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2114 - val_loss: 23.6062\n",
            "Epoch 128/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3581\n",
            "Epoch 00128: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.3581 - val_loss: 25.3600\n",
            "Epoch 129/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.9913\n",
            "Epoch 00129: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.9913 - val_loss: 55.2365\n",
            "Epoch 130/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 67.5064\n",
            "Epoch 00130: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 67.5064 - val_loss: 81.7051\n",
            "Epoch 131/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 40.5202\n",
            "Epoch 00131: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 40.5202 - val_loss: 107.6873\n",
            "Epoch 132/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 27.5027\n",
            "Epoch 00132: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 27.5027 - val_loss: 132.1638\n",
            "Epoch 133/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 20.5547\n",
            "Epoch 00133: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 20.5547 - val_loss: 103.4583\n",
            "Epoch 134/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 16.0401\n",
            "Epoch 00134: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 16.0401 - val_loss: 98.8071\n",
            "Epoch 135/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 13.0450\n",
            "Epoch 00135: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 13.0450 - val_loss: 111.8618\n",
            "Epoch 136/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 10.8441\n",
            "Epoch 00136: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 10.8441 - val_loss: 99.4742\n",
            "Epoch 137/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 8.9460\n",
            "Epoch 00137: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 8.9460 - val_loss: 79.6857\n",
            "Epoch 138/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 7.6942\n",
            "Epoch 00138: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 7.6942 - val_loss: 77.2393\n",
            "Epoch 139/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 6.5144\n",
            "Epoch 00139: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 6.5144 - val_loss: 78.5303\n",
            "Epoch 140/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 5.5312\n",
            "Epoch 00140: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 5.5312 - val_loss: 76.9226\n",
            "Epoch 141/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 4.7140\n",
            "Epoch 00141: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 4.7140 - val_loss: 52.4804\n",
            "Epoch 142/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 4.1118\n",
            "Epoch 00142: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 4.1118 - val_loss: 51.8142\n",
            "Epoch 143/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 3.4751\n",
            "Epoch 00143: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 3.4751 - val_loss: 53.9945\n",
            "Epoch 144/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 3.0411\n",
            "Epoch 00144: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 3.0411 - val_loss: 47.4817\n",
            "Epoch 145/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 2.6328\n",
            "Epoch 00145: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 2.6328 - val_loss: 38.5086\n",
            "Epoch 146/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 2.3147\n",
            "Epoch 00146: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 2.3147 - val_loss: 39.2309\n",
            "Epoch 147/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.9972\n",
            "Epoch 00147: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 1.9972 - val_loss: 34.7148\n",
            "Epoch 148/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.7332\n",
            "Epoch 00148: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 1.7332 - val_loss: 29.4965\n",
            "Epoch 149/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.5764\n",
            "Epoch 00149: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 1.5764 - val_loss: 31.9168\n",
            "Epoch 150/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.3697\n",
            "Epoch 00150: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 1.3697 - val_loss: 27.0506\n",
            "Epoch 151/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.1974\n",
            "Epoch 00151: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 1.1974 - val_loss: 26.9930\n",
            "Epoch 152/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.0766\n",
            "Epoch 00152: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 1.0766 - val_loss: 25.4706\n",
            "Epoch 153/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.9233\n",
            "Epoch 00153: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.9233 - val_loss: 24.5807\n",
            "Epoch 154/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.8333\n",
            "Epoch 00154: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.8333 - val_loss: 23.6103\n",
            "Epoch 155/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7412\n",
            "Epoch 00155: val_loss did not improve from 23.04799\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.7412 - val_loss: 23.0574\n",
            "Epoch 156/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6592\n",
            "Epoch 00156: val_loss improved from 23.04799 to 22.63886, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.6592 - val_loss: 22.6389\n",
            "Epoch 157/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5893\n",
            "Epoch 00157: val_loss improved from 22.63886 to 22.28539, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.5893 - val_loss: 22.2854\n",
            "Epoch 158/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5336\n",
            "Epoch 00158: val_loss improved from 22.28539 to 21.70042, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.5336 - val_loss: 21.7004\n",
            "Epoch 159/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4949\n",
            "Epoch 00159: val_loss improved from 21.70042 to 21.67098, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.4949 - val_loss: 21.6710\n",
            "Epoch 160/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4513\n",
            "Epoch 00160: val_loss did not improve from 21.67098\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.4513 - val_loss: 22.1502\n",
            "Epoch 161/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4255\n",
            "Epoch 00161: val_loss improved from 21.67098 to 21.54784, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.4255 - val_loss: 21.5478\n",
            "Epoch 162/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3908\n",
            "Epoch 00162: val_loss improved from 21.54784 to 21.03862, saving model to /content/drive/My Drive/recognition/set2/best_model2.hdf5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.3908 - val_loss: 21.0386\n",
            "Epoch 163/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3644\n",
            "Epoch 00163: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.3644 - val_loss: 21.0419\n",
            "Epoch 164/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3507\n",
            "Epoch 00164: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.3507 - val_loss: 21.5324\n",
            "Epoch 165/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3281\n",
            "Epoch 00165: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.3281 - val_loss: 21.3395\n",
            "Epoch 166/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3118\n",
            "Epoch 00166: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.3118 - val_loss: 21.2628\n",
            "Epoch 167/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2979\n",
            "Epoch 00167: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2979 - val_loss: 21.0581\n",
            "Epoch 168/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2717\n",
            "Epoch 00168: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2717 - val_loss: 21.5581\n",
            "Epoch 169/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2561\n",
            "Epoch 00169: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2561 - val_loss: 21.2270\n",
            "Epoch 170/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2437\n",
            "Epoch 00170: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2437 - val_loss: 21.5515\n",
            "Epoch 171/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2351\n",
            "Epoch 00171: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2351 - val_loss: 21.3745\n",
            "Epoch 172/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2196\n",
            "Epoch 00172: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2196 - val_loss: 21.6854\n",
            "Epoch 173/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2068\n",
            "Epoch 00173: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2068 - val_loss: 21.7209\n",
            "Epoch 174/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2037\n",
            "Epoch 00174: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2037 - val_loss: 21.9344\n",
            "Epoch 175/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1929\n",
            "Epoch 00175: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1929 - val_loss: 21.7707\n",
            "Epoch 176/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1851\n",
            "Epoch 00176: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1851 - val_loss: 21.9703\n",
            "Epoch 177/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1773\n",
            "Epoch 00177: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1773 - val_loss: 21.8533\n",
            "Epoch 178/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1699\n",
            "Epoch 00178: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1699 - val_loss: 21.8904\n",
            "Epoch 179/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1635\n",
            "Epoch 00179: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1635 - val_loss: 22.0663\n",
            "Epoch 180/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1592\n",
            "Epoch 00180: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1592 - val_loss: 22.2694\n",
            "Epoch 181/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1528\n",
            "Epoch 00181: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1528 - val_loss: 22.1710\n",
            "Epoch 182/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1509\n",
            "Epoch 00182: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1509 - val_loss: 22.2275\n",
            "Epoch 183/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1443\n",
            "Epoch 00183: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1443 - val_loss: 22.3358\n",
            "Epoch 184/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1382\n",
            "Epoch 00184: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1382 - val_loss: 22.2787\n",
            "Epoch 185/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1352\n",
            "Epoch 00185: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1352 - val_loss: 22.3853\n",
            "Epoch 186/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1304\n",
            "Epoch 00186: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1304 - val_loss: 22.5963\n",
            "Epoch 187/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1255\n",
            "Epoch 00187: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1255 - val_loss: 22.5834\n",
            "Epoch 188/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1247\n",
            "Epoch 00188: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1247 - val_loss: 22.7386\n",
            "Epoch 189/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1182\n",
            "Epoch 00189: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1182 - val_loss: 22.8101\n",
            "Epoch 190/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1144\n",
            "Epoch 00190: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1144 - val_loss: 22.8678\n",
            "Epoch 191/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1117\n",
            "Epoch 00191: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1117 - val_loss: 22.9638\n",
            "Epoch 192/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1088\n",
            "Epoch 00192: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1088 - val_loss: 23.0889\n",
            "Epoch 193/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1051\n",
            "Epoch 00193: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1051 - val_loss: 22.9597\n",
            "Epoch 194/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1035\n",
            "Epoch 00194: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1035 - val_loss: 23.2929\n",
            "Epoch 195/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1009\n",
            "Epoch 00195: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1009 - val_loss: 23.0022\n",
            "Epoch 196/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0986\n",
            "Epoch 00196: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0986 - val_loss: 23.3980\n",
            "Epoch 197/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0987\n",
            "Epoch 00197: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0987 - val_loss: 23.1860\n",
            "Epoch 198/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0964\n",
            "Epoch 00198: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0964 - val_loss: 23.4206\n",
            "Epoch 199/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0937\n",
            "Epoch 00199: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0937 - val_loss: 23.3660\n",
            "Epoch 200/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0897\n",
            "Epoch 00200: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0897 - val_loss: 23.4416\n",
            "Epoch 201/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0886\n",
            "Epoch 00201: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0886 - val_loss: 23.3613\n",
            "Epoch 202/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0868\n",
            "Epoch 00202: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0868 - val_loss: 23.4225\n",
            "Epoch 203/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0849\n",
            "Epoch 00203: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0849 - val_loss: 23.3826\n",
            "Epoch 204/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0834\n",
            "Epoch 00204: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0834 - val_loss: 23.5404\n",
            "Epoch 205/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0820\n",
            "Epoch 00205: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0820 - val_loss: 23.5762\n",
            "Epoch 206/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0816\n",
            "Epoch 00206: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0816 - val_loss: 23.7654\n",
            "Epoch 207/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0793\n",
            "Epoch 00207: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0793 - val_loss: 23.7702\n",
            "Epoch 208/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0782\n",
            "Epoch 00208: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0782 - val_loss: 23.5774\n",
            "Epoch 209/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0872\n",
            "Epoch 00209: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0872 - val_loss: 23.9388\n",
            "Epoch 210/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0933\n",
            "Epoch 00210: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0933 - val_loss: 23.4069\n",
            "Epoch 211/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0922\n",
            "Epoch 00211: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0922 - val_loss: 24.1664\n",
            "Epoch 212/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0899\n",
            "Epoch 00212: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0899 - val_loss: 23.5335\n",
            "Epoch 213/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0976\n",
            "Epoch 00213: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0976 - val_loss: 23.8388\n",
            "Epoch 214/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1068\n",
            "Epoch 00214: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1068 - val_loss: 23.5652\n",
            "Epoch 215/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1389\n",
            "Epoch 00215: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1389 - val_loss: 24.1353\n",
            "Epoch 216/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1360\n",
            "Epoch 00216: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1360 - val_loss: 24.2492\n",
            "Epoch 217/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1619\n",
            "Epoch 00217: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1619 - val_loss: 23.5268\n",
            "Epoch 218/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1941\n",
            "Epoch 00218: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1941 - val_loss: 23.8916\n",
            "Epoch 219/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1974\n",
            "Epoch 00219: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1974 - val_loss: 23.3812\n",
            "Epoch 220/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2372\n",
            "Epoch 00220: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2372 - val_loss: 24.8750\n",
            "Epoch 221/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2881\n",
            "Epoch 00221: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2881 - val_loss: 24.1825\n",
            "Epoch 222/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3470\n",
            "Epoch 00222: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.3470 - val_loss: 24.2265\n",
            "Epoch 223/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4066\n",
            "Epoch 00223: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.4066 - val_loss: 24.7132\n",
            "Epoch 224/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4787\n",
            "Epoch 00224: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.4787 - val_loss: 24.5475\n",
            "Epoch 225/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5055\n",
            "Epoch 00225: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.5055 - val_loss: 24.3348\n",
            "Epoch 226/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5021\n",
            "Epoch 00226: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.5021 - val_loss: 24.0807\n",
            "Epoch 227/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4941\n",
            "Epoch 00227: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.4941 - val_loss: 24.9937\n",
            "Epoch 228/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4268\n",
            "Epoch 00228: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.4268 - val_loss: 25.5654\n",
            "Epoch 229/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3670\n",
            "Epoch 00229: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.3670 - val_loss: 24.4429\n",
            "Epoch 230/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3326\n",
            "Epoch 00230: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.3326 - val_loss: 24.3753\n",
            "Epoch 231/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2852\n",
            "Epoch 00231: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2852 - val_loss: 23.8927\n",
            "Epoch 232/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2458\n",
            "Epoch 00232: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2458 - val_loss: 23.9275\n",
            "Epoch 233/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1892\n",
            "Epoch 00233: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1892 - val_loss: 23.6938\n",
            "Epoch 234/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1635\n",
            "Epoch 00234: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1635 - val_loss: 23.1040\n",
            "Epoch 235/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1361\n",
            "Epoch 00235: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1361 - val_loss: 23.7188\n",
            "Epoch 236/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1234\n",
            "Epoch 00236: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1234 - val_loss: 23.5809\n",
            "Epoch 237/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1013\n",
            "Epoch 00237: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1013 - val_loss: 23.3609\n",
            "Epoch 238/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0887\n",
            "Epoch 00238: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0887 - val_loss: 23.5118\n",
            "Epoch 239/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0802\n",
            "Epoch 00239: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0802 - val_loss: 23.6425\n",
            "Epoch 240/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0713\n",
            "Epoch 00240: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0713 - val_loss: 23.4624\n",
            "Epoch 241/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0690\n",
            "Epoch 00241: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0690 - val_loss: 23.7985\n",
            "Epoch 242/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0640\n",
            "Epoch 00242: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0640 - val_loss: 23.9728\n",
            "Epoch 243/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0605\n",
            "Epoch 00243: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0605 - val_loss: 23.7938\n",
            "Epoch 244/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0585\n",
            "Epoch 00244: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0585 - val_loss: 23.9450\n",
            "Epoch 245/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0540\n",
            "Epoch 00245: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0540 - val_loss: 24.0303\n",
            "Epoch 246/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0535\n",
            "Epoch 00246: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0535 - val_loss: 23.7902\n",
            "Epoch 247/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0501\n",
            "Epoch 00247: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0501 - val_loss: 24.0120\n",
            "Epoch 248/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0494\n",
            "Epoch 00248: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0494 - val_loss: 24.0864\n",
            "Epoch 249/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0474\n",
            "Epoch 00249: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0474 - val_loss: 24.1433\n",
            "Epoch 250/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0464\n",
            "Epoch 00250: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0464 - val_loss: 24.0978\n",
            "Epoch 251/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0452\n",
            "Epoch 00251: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0452 - val_loss: 24.0701\n",
            "Epoch 252/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0445\n",
            "Epoch 00252: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0445 - val_loss: 23.9559\n",
            "Epoch 253/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0439\n",
            "Epoch 00253: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0439 - val_loss: 24.2390\n",
            "Epoch 254/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0427\n",
            "Epoch 00254: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0427 - val_loss: 24.1869\n",
            "Epoch 255/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0416\n",
            "Epoch 00255: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0416 - val_loss: 24.2541\n",
            "Epoch 256/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0419\n",
            "Epoch 00256: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0419 - val_loss: 24.2823\n",
            "Epoch 257/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0406\n",
            "Epoch 00257: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0406 - val_loss: 24.2453\n",
            "Epoch 258/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0391\n",
            "Epoch 00258: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0391 - val_loss: 24.3542\n",
            "Epoch 259/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0394\n",
            "Epoch 00259: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0394 - val_loss: 24.3890\n",
            "Epoch 260/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0386\n",
            "Epoch 00260: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0386 - val_loss: 24.3534\n",
            "Epoch 261/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0372\n",
            "Epoch 00261: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0372 - val_loss: 24.3551\n",
            "Epoch 262/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0371\n",
            "Epoch 00262: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0371 - val_loss: 24.4821\n",
            "Epoch 263/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0367\n",
            "Epoch 00263: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0367 - val_loss: 24.5732\n",
            "Epoch 264/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0361\n",
            "Epoch 00264: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0361 - val_loss: 24.3871\n",
            "Epoch 265/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0352\n",
            "Epoch 00265: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0352 - val_loss: 24.5311\n",
            "Epoch 266/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0346\n",
            "Epoch 00266: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0346 - val_loss: 24.5616\n",
            "Epoch 267/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0345\n",
            "Epoch 00267: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0345 - val_loss: 24.5296\n",
            "Epoch 268/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0337\n",
            "Epoch 00268: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0337 - val_loss: 24.4690\n",
            "Epoch 269/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0333\n",
            "Epoch 00269: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0333 - val_loss: 24.6471\n",
            "Epoch 270/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0331\n",
            "Epoch 00270: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0331 - val_loss: 24.7013\n",
            "Epoch 271/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0323\n",
            "Epoch 00271: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0323 - val_loss: 24.6661\n",
            "Epoch 272/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0322\n",
            "Epoch 00272: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0322 - val_loss: 24.6040\n",
            "Epoch 273/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0314\n",
            "Epoch 00273: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0314 - val_loss: 24.6841\n",
            "Epoch 274/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0316\n",
            "Epoch 00274: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0316 - val_loss: 24.7319\n",
            "Epoch 275/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0307\n",
            "Epoch 00275: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0307 - val_loss: 24.6325\n",
            "Epoch 276/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0307\n",
            "Epoch 00276: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0307 - val_loss: 24.7429\n",
            "Epoch 277/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0302\n",
            "Epoch 00277: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0302 - val_loss: 24.8680\n",
            "Epoch 278/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0299\n",
            "Epoch 00278: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0299 - val_loss: 24.7763\n",
            "Epoch 279/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0299\n",
            "Epoch 00279: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0299 - val_loss: 24.8179\n",
            "Epoch 280/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0293\n",
            "Epoch 00280: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0293 - val_loss: 24.8771\n",
            "Epoch 281/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0289\n",
            "Epoch 00281: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0289 - val_loss: 24.7561\n",
            "Epoch 282/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0283\n",
            "Epoch 00282: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0283 - val_loss: 24.7783\n",
            "Epoch 283/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0285\n",
            "Epoch 00283: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0285 - val_loss: 24.9986\n",
            "Epoch 284/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0288\n",
            "Epoch 00284: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0288 - val_loss: 24.9497\n",
            "Epoch 285/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0278\n",
            "Epoch 00285: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0278 - val_loss: 24.8341\n",
            "Epoch 286/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0278\n",
            "Epoch 00286: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0278 - val_loss: 24.8742\n",
            "Epoch 287/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0275\n",
            "Epoch 00287: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0275 - val_loss: 24.7911\n",
            "Epoch 288/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0270\n",
            "Epoch 00288: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0270 - val_loss: 24.8641\n",
            "Epoch 289/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0270\n",
            "Epoch 00289: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0270 - val_loss: 24.9884\n",
            "Epoch 290/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0267\n",
            "Epoch 00290: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0267 - val_loss: 25.0610\n",
            "Epoch 291/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0261\n",
            "Epoch 00291: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0261 - val_loss: 25.0351\n",
            "Epoch 292/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0257\n",
            "Epoch 00292: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0257 - val_loss: 24.9521\n",
            "Epoch 293/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0260\n",
            "Epoch 00293: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0260 - val_loss: 24.9863\n",
            "Epoch 294/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0256\n",
            "Epoch 00294: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0256 - val_loss: 25.0703\n",
            "Epoch 295/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0251\n",
            "Epoch 00295: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0251 - val_loss: 25.1007\n",
            "Epoch 296/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0246\n",
            "Epoch 00296: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0246 - val_loss: 25.1864\n",
            "Epoch 297/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0249\n",
            "Epoch 00297: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0249 - val_loss: 25.2350\n",
            "Epoch 298/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0249\n",
            "Epoch 00298: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0249 - val_loss: 24.9372\n",
            "Epoch 299/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0244\n",
            "Epoch 00299: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0244 - val_loss: 24.9819\n",
            "Epoch 300/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0238\n",
            "Epoch 00300: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0238 - val_loss: 25.2088\n",
            "Epoch 301/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0241\n",
            "Epoch 00301: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0241 - val_loss: 25.2283\n",
            "Epoch 302/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0234\n",
            "Epoch 00302: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0234 - val_loss: 25.2307\n",
            "Epoch 303/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0235\n",
            "Epoch 00303: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0235 - val_loss: 25.2182\n",
            "Epoch 304/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0232\n",
            "Epoch 00304: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0232 - val_loss: 25.0647\n",
            "Epoch 305/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0234\n",
            "Epoch 00305: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0234 - val_loss: 25.0988\n",
            "Epoch 306/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0227\n",
            "Epoch 00306: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0227 - val_loss: 25.2038\n",
            "Epoch 307/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0227\n",
            "Epoch 00307: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0227 - val_loss: 25.3528\n",
            "Epoch 308/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0223\n",
            "Epoch 00308: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0223 - val_loss: 25.2935\n",
            "Epoch 309/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0218\n",
            "Epoch 00309: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0218 - val_loss: 25.2743\n",
            "Epoch 310/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0219\n",
            "Epoch 00310: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0219 - val_loss: 25.3015\n",
            "Epoch 311/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0217\n",
            "Epoch 00311: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0217 - val_loss: 25.3008\n",
            "Epoch 312/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0216\n",
            "Epoch 00312: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0216 - val_loss: 25.3317\n",
            "Epoch 313/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0212\n",
            "Epoch 00313: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0212 - val_loss: 25.3478\n",
            "Epoch 314/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0210\n",
            "Epoch 00314: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0210 - val_loss: 25.3656\n",
            "Epoch 315/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0211\n",
            "Epoch 00315: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0211 - val_loss: 25.3305\n",
            "Epoch 316/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0214\n",
            "Epoch 00316: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0214 - val_loss: 25.4094\n",
            "Epoch 317/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0208\n",
            "Epoch 00317: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0208 - val_loss: 25.4620\n",
            "Epoch 318/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0205\n",
            "Epoch 00318: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0205 - val_loss: 25.4822\n",
            "Epoch 319/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0201\n",
            "Epoch 00319: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0201 - val_loss: 25.4327\n",
            "Epoch 320/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0202\n",
            "Epoch 00320: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0202 - val_loss: 25.5698\n",
            "Epoch 321/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0201\n",
            "Epoch 00321: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0201 - val_loss: 25.6296\n",
            "Epoch 322/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0195\n",
            "Epoch 00322: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0195 - val_loss: 25.5395\n",
            "Epoch 323/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0198\n",
            "Epoch 00323: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0198 - val_loss: 25.5222\n",
            "Epoch 324/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0191\n",
            "Epoch 00324: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0191 - val_loss: 25.5485\n",
            "Epoch 325/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0193\n",
            "Epoch 00325: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0193 - val_loss: 25.6744\n",
            "Epoch 326/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0195\n",
            "Epoch 00326: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0195 - val_loss: 25.5395\n",
            "Epoch 327/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0193\n",
            "Epoch 00327: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0193 - val_loss: 25.4185\n",
            "Epoch 328/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0200\n",
            "Epoch 00328: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0200 - val_loss: 25.5999\n",
            "Epoch 329/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0193\n",
            "Epoch 00329: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0193 - val_loss: 25.5707\n",
            "Epoch 330/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0190\n",
            "Epoch 00330: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0190 - val_loss: 25.5525\n",
            "Epoch 331/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0190\n",
            "Epoch 00331: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0190 - val_loss: 25.5020\n",
            "Epoch 332/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0186\n",
            "Epoch 00332: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0186 - val_loss: 25.5862\n",
            "Epoch 333/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0185\n",
            "Epoch 00333: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0185 - val_loss: 25.7474\n",
            "Epoch 334/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0183\n",
            "Epoch 00334: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0183 - val_loss: 25.7070\n",
            "Epoch 335/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0178\n",
            "Epoch 00335: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0178 - val_loss: 25.6453\n",
            "Epoch 336/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0176\n",
            "Epoch 00336: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0176 - val_loss: 25.7187\n",
            "Epoch 337/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0178\n",
            "Epoch 00337: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0178 - val_loss: 25.7390\n",
            "Epoch 338/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0175\n",
            "Epoch 00338: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0175 - val_loss: 25.6926\n",
            "Epoch 339/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0177\n",
            "Epoch 00339: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0177 - val_loss: 25.6785\n",
            "Epoch 340/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0173\n",
            "Epoch 00340: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0173 - val_loss: 25.7247\n",
            "Epoch 341/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0171\n",
            "Epoch 00341: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0171 - val_loss: 25.7996\n",
            "Epoch 342/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0172\n",
            "Epoch 00342: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0172 - val_loss: 25.6815\n",
            "Epoch 343/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0180\n",
            "Epoch 00343: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0180 - val_loss: 26.3105\n",
            "Epoch 344/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0197\n",
            "Epoch 00344: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0197 - val_loss: 25.6415\n",
            "Epoch 345/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0184\n",
            "Epoch 00345: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0184 - val_loss: 26.1507\n",
            "Epoch 346/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0199\n",
            "Epoch 00346: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0199 - val_loss: 25.7140\n",
            "Epoch 347/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0215\n",
            "Epoch 00347: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0215 - val_loss: 26.1081\n",
            "Epoch 348/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0247\n",
            "Epoch 00348: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0247 - val_loss: 25.2527\n",
            "Epoch 349/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0231\n",
            "Epoch 00349: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0231 - val_loss: 25.4266\n",
            "Epoch 350/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0214\n",
            "Epoch 00350: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0214 - val_loss: 26.8788\n",
            "Epoch 351/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0254\n",
            "Epoch 00351: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0254 - val_loss: 25.6154\n",
            "Epoch 352/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0231\n",
            "Epoch 00352: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0231 - val_loss: 26.2060\n",
            "Epoch 353/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0233\n",
            "Epoch 00353: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0233 - val_loss: 25.9116\n",
            "Epoch 354/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0252\n",
            "Epoch 00354: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0252 - val_loss: 26.3848\n",
            "Epoch 355/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0286\n",
            "Epoch 00355: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0286 - val_loss: 26.0002\n",
            "Epoch 356/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0403\n",
            "Epoch 00356: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0403 - val_loss: 26.9831\n",
            "Epoch 357/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0670\n",
            "Epoch 00357: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0670 - val_loss: 26.9275\n",
            "Epoch 358/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1078\n",
            "Epoch 00358: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1078 - val_loss: 27.4081\n",
            "Epoch 359/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2073\n",
            "Epoch 00359: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2073 - val_loss: 27.5228\n",
            "Epoch 360/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7202\n",
            "Epoch 00360: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.7202 - val_loss: 29.3892\n",
            "Epoch 361/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 8.4937\n",
            "Epoch 00361: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 8.4937 - val_loss: 108.9692\n",
            "Epoch 362/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 20.3375\n",
            "Epoch 00362: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 20.3375 - val_loss: 36.4678\n",
            "Epoch 363/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 12.3176\n",
            "Epoch 00363: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 12.3176 - val_loss: 32.5158\n",
            "Epoch 364/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 7.7548\n",
            "Epoch 00364: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 7.7548 - val_loss: 25.6633\n",
            "Epoch 365/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 4.7936\n",
            "Epoch 00365: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 4.7936 - val_loss: 25.4712\n",
            "Epoch 366/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 3.0792\n",
            "Epoch 00366: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 3.0792 - val_loss: 22.9533\n",
            "Epoch 367/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 2.0057\n",
            "Epoch 00367: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 2.0057 - val_loss: 21.4386\n",
            "Epoch 368/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.3725\n",
            "Epoch 00368: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 1.3725 - val_loss: 22.3796\n",
            "Epoch 369/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.9232\n",
            "Epoch 00369: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.9232 - val_loss: 24.0226\n",
            "Epoch 370/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6512\n",
            "Epoch 00370: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.6512 - val_loss: 22.5896\n",
            "Epoch 371/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4577\n",
            "Epoch 00371: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.4577 - val_loss: 23.3821\n",
            "Epoch 372/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3436\n",
            "Epoch 00372: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.3436 - val_loss: 22.1584\n",
            "Epoch 373/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2633\n",
            "Epoch 00373: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2633 - val_loss: 21.6878\n",
            "Epoch 374/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2071\n",
            "Epoch 00374: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2071 - val_loss: 22.0642\n",
            "Epoch 375/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1716\n",
            "Epoch 00375: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1716 - val_loss: 22.1470\n",
            "Epoch 376/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1421\n",
            "Epoch 00376: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1421 - val_loss: 22.3904\n",
            "Epoch 377/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1204\n",
            "Epoch 00377: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1204 - val_loss: 22.2387\n",
            "Epoch 378/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1071\n",
            "Epoch 00378: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1071 - val_loss: 22.2848\n",
            "Epoch 379/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0954\n",
            "Epoch 00379: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0954 - val_loss: 22.4576\n",
            "Epoch 380/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0878\n",
            "Epoch 00380: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0878 - val_loss: 22.3823\n",
            "Epoch 381/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0818\n",
            "Epoch 00381: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0818 - val_loss: 22.5305\n",
            "Epoch 382/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0785\n",
            "Epoch 00382: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0785 - val_loss: 22.4554\n",
            "Epoch 383/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0738\n",
            "Epoch 00383: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0738 - val_loss: 22.6640\n",
            "Epoch 384/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0698\n",
            "Epoch 00384: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0698 - val_loss: 22.6607\n",
            "Epoch 385/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0658\n",
            "Epoch 00385: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0658 - val_loss: 22.6927\n",
            "Epoch 386/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0611\n",
            "Epoch 00386: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0611 - val_loss: 22.8915\n",
            "Epoch 387/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0588\n",
            "Epoch 00387: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0588 - val_loss: 22.7902\n",
            "Epoch 388/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0563\n",
            "Epoch 00388: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0563 - val_loss: 22.8261\n",
            "Epoch 389/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0548\n",
            "Epoch 00389: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0548 - val_loss: 22.8457\n",
            "Epoch 390/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0530\n",
            "Epoch 00390: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0530 - val_loss: 22.9778\n",
            "Epoch 391/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0512\n",
            "Epoch 00391: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0512 - val_loss: 23.0188\n",
            "Epoch 392/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0493\n",
            "Epoch 00392: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0493 - val_loss: 23.0462\n",
            "Epoch 393/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0492\n",
            "Epoch 00393: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0492 - val_loss: 23.1239\n",
            "Epoch 394/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0452\n",
            "Epoch 00394: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0452 - val_loss: 23.0631\n",
            "Epoch 395/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0440\n",
            "Epoch 00395: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0440 - val_loss: 23.2249\n",
            "Epoch 396/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0426\n",
            "Epoch 00396: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0426 - val_loss: 23.3047\n",
            "Epoch 397/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0418\n",
            "Epoch 00397: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0418 - val_loss: 23.2181\n",
            "Epoch 398/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0400\n",
            "Epoch 00398: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0400 - val_loss: 23.3132\n",
            "Epoch 399/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0384\n",
            "Epoch 00399: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0384 - val_loss: 23.4069\n",
            "Epoch 400/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0391\n",
            "Epoch 00400: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0391 - val_loss: 23.4117\n",
            "Epoch 401/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0367\n",
            "Epoch 00401: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0367 - val_loss: 23.3889\n",
            "Epoch 402/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0370\n",
            "Epoch 00402: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0370 - val_loss: 23.3781\n",
            "Epoch 403/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0347\n",
            "Epoch 00403: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0347 - val_loss: 23.3691\n",
            "Epoch 404/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0349\n",
            "Epoch 00404: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0349 - val_loss: 23.4110\n",
            "Epoch 405/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0337\n",
            "Epoch 00405: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0337 - val_loss: 23.5092\n",
            "Epoch 406/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0336\n",
            "Epoch 00406: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0336 - val_loss: 23.5925\n",
            "Epoch 407/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0316\n",
            "Epoch 00407: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0316 - val_loss: 23.5928\n",
            "Epoch 408/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0318\n",
            "Epoch 00408: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0318 - val_loss: 23.5096\n",
            "Epoch 409/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0314\n",
            "Epoch 00409: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0314 - val_loss: 23.5996\n",
            "Epoch 410/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0299\n",
            "Epoch 00410: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0299 - val_loss: 23.6568\n",
            "Epoch 411/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0295\n",
            "Epoch 00411: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0295 - val_loss: 23.6515\n",
            "Epoch 412/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0285\n",
            "Epoch 00412: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0285 - val_loss: 23.6600\n",
            "Epoch 413/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0284\n",
            "Epoch 00413: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0284 - val_loss: 23.7632\n",
            "Epoch 414/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0282\n",
            "Epoch 00414: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0282 - val_loss: 23.8119\n",
            "Epoch 415/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0274\n",
            "Epoch 00415: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0274 - val_loss: 23.8155\n",
            "Epoch 416/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0272\n",
            "Epoch 00416: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0272 - val_loss: 23.8752\n",
            "Epoch 417/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0270\n",
            "Epoch 00417: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0270 - val_loss: 23.9866\n",
            "Epoch 418/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0272\n",
            "Epoch 00418: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0272 - val_loss: 23.8990\n",
            "Epoch 419/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0263\n",
            "Epoch 00419: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0263 - val_loss: 23.8692\n",
            "Epoch 420/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0253\n",
            "Epoch 00420: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0253 - val_loss: 23.9567\n",
            "Epoch 421/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0247\n",
            "Epoch 00421: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0247 - val_loss: 23.9962\n",
            "Epoch 422/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0243\n",
            "Epoch 00422: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0243 - val_loss: 24.0433\n",
            "Epoch 423/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0242\n",
            "Epoch 00423: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0242 - val_loss: 24.0432\n",
            "Epoch 424/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0235\n",
            "Epoch 00424: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0235 - val_loss: 24.0642\n",
            "Epoch 425/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0235\n",
            "Epoch 00425: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0235 - val_loss: 24.0386\n",
            "Epoch 426/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0235\n",
            "Epoch 00426: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0235 - val_loss: 24.0731\n",
            "Epoch 427/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0225\n",
            "Epoch 00427: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0225 - val_loss: 24.1717\n",
            "Epoch 428/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0235\n",
            "Epoch 00428: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0235 - val_loss: 24.2044\n",
            "Epoch 429/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0226\n",
            "Epoch 00429: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0226 - val_loss: 24.2037\n",
            "Epoch 430/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0222\n",
            "Epoch 00430: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0222 - val_loss: 24.2786\n",
            "Epoch 431/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0213\n",
            "Epoch 00431: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0213 - val_loss: 24.2870\n",
            "Epoch 432/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0217\n",
            "Epoch 00432: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0217 - val_loss: 24.2714\n",
            "Epoch 433/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0211\n",
            "Epoch 00433: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0211 - val_loss: 24.3310\n",
            "Epoch 434/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0207\n",
            "Epoch 00434: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0207 - val_loss: 24.3996\n",
            "Epoch 435/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0207\n",
            "Epoch 00435: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0207 - val_loss: 24.3477\n",
            "Epoch 436/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0201\n",
            "Epoch 00436: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0201 - val_loss: 24.3354\n",
            "Epoch 437/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0196\n",
            "Epoch 00437: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0196 - val_loss: 24.4108\n",
            "Epoch 438/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0194\n",
            "Epoch 00438: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0194 - val_loss: 24.4888\n",
            "Epoch 439/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0192\n",
            "Epoch 00439: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0192 - val_loss: 24.5244\n",
            "Epoch 440/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0191\n",
            "Epoch 00440: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0191 - val_loss: 24.4959\n",
            "Epoch 441/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0192\n",
            "Epoch 00441: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0192 - val_loss: 24.4132\n",
            "Epoch 442/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0187\n",
            "Epoch 00442: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0187 - val_loss: 24.4765\n",
            "Epoch 443/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0183\n",
            "Epoch 00443: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0183 - val_loss: 24.5657\n",
            "Epoch 444/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0186\n",
            "Epoch 00444: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0186 - val_loss: 24.5820\n",
            "Epoch 445/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0181\n",
            "Epoch 00445: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0181 - val_loss: 24.5365\n",
            "Epoch 446/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0182\n",
            "Epoch 00446: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0182 - val_loss: 24.5786\n",
            "Epoch 447/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0179\n",
            "Epoch 00447: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0179 - val_loss: 24.6760\n",
            "Epoch 448/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0177\n",
            "Epoch 00448: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0177 - val_loss: 24.6487\n",
            "Epoch 449/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0173\n",
            "Epoch 00449: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0173 - val_loss: 24.5855\n",
            "Epoch 450/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0176\n",
            "Epoch 00450: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0176 - val_loss: 24.6572\n",
            "Epoch 451/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0170\n",
            "Epoch 00451: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0170 - val_loss: 24.7141\n",
            "Epoch 452/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0171\n",
            "Epoch 00452: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0171 - val_loss: 24.7658\n",
            "Epoch 453/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0164\n",
            "Epoch 00453: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0164 - val_loss: 24.8025\n",
            "Epoch 454/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0164\n",
            "Epoch 00454: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0164 - val_loss: 24.7739\n",
            "Epoch 455/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0164\n",
            "Epoch 00455: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0164 - val_loss: 24.7715\n",
            "Epoch 456/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0159\n",
            "Epoch 00456: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0159 - val_loss: 24.7793\n",
            "Epoch 457/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0166\n",
            "Epoch 00457: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0166 - val_loss: 24.7919\n",
            "Epoch 458/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0160\n",
            "Epoch 00458: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0160 - val_loss: 24.8317\n",
            "Epoch 459/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0218\n",
            "Epoch 00459: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0218 - val_loss: 24.9571\n",
            "Epoch 460/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0211\n",
            "Epoch 00460: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0211 - val_loss: 24.9183\n",
            "Epoch 461/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0182\n",
            "Epoch 00461: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0182 - val_loss: 24.9755\n",
            "Epoch 462/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0190\n",
            "Epoch 00462: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0190 - val_loss: 24.8051\n",
            "Epoch 463/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0169\n",
            "Epoch 00463: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0169 - val_loss: 24.8541\n",
            "Epoch 464/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0166\n",
            "Epoch 00464: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0166 - val_loss: 24.9479\n",
            "Epoch 465/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0162\n",
            "Epoch 00465: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0162 - val_loss: 24.9720\n",
            "Epoch 466/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0158\n",
            "Epoch 00466: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0158 - val_loss: 24.9319\n",
            "Epoch 467/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0152\n",
            "Epoch 00467: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0152 - val_loss: 24.8368\n",
            "Epoch 468/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0151\n",
            "Epoch 00468: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0151 - val_loss: 24.8507\n",
            "Epoch 469/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0150\n",
            "Epoch 00469: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0150 - val_loss: 24.8957\n",
            "Epoch 470/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0145\n",
            "Epoch 00470: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0145 - val_loss: 24.9537\n",
            "Epoch 471/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0143\n",
            "Epoch 00471: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0143 - val_loss: 25.0080\n",
            "Epoch 472/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0142\n",
            "Epoch 00472: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0142 - val_loss: 25.0040\n",
            "Epoch 473/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0139\n",
            "Epoch 00473: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0139 - val_loss: 24.9748\n",
            "Epoch 474/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0139\n",
            "Epoch 00474: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0139 - val_loss: 24.9982\n",
            "Epoch 475/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0133\n",
            "Epoch 00475: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0133 - val_loss: 25.0110\n",
            "Epoch 476/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0134\n",
            "Epoch 00476: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0134 - val_loss: 25.0735\n",
            "Epoch 477/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0136\n",
            "Epoch 00477: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0136 - val_loss: 25.1015\n",
            "Epoch 478/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0134\n",
            "Epoch 00478: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0134 - val_loss: 25.1340\n",
            "Epoch 479/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0129\n",
            "Epoch 00479: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0129 - val_loss: 25.1747\n",
            "Epoch 480/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0132\n",
            "Epoch 00480: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0132 - val_loss: 25.1730\n",
            "Epoch 481/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0127\n",
            "Epoch 00481: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0127 - val_loss: 25.2025\n",
            "Epoch 482/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0129\n",
            "Epoch 00482: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0129 - val_loss: 25.2102\n",
            "Epoch 483/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0128\n",
            "Epoch 00483: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0128 - val_loss: 25.2703\n",
            "Epoch 484/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0124\n",
            "Epoch 00484: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0124 - val_loss: 25.2865\n",
            "Epoch 485/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0124\n",
            "Epoch 00485: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0124 - val_loss: 25.3219\n",
            "Epoch 486/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0125\n",
            "Epoch 00486: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0125 - val_loss: 25.3402\n",
            "Epoch 487/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0124\n",
            "Epoch 00487: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0124 - val_loss: 25.3134\n",
            "Epoch 488/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0122\n",
            "Epoch 00488: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0122 - val_loss: 25.3154\n",
            "Epoch 489/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0121\n",
            "Epoch 00489: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0121 - val_loss: 25.3298\n",
            "Epoch 490/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0119\n",
            "Epoch 00490: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0119 - val_loss: 25.3804\n",
            "Epoch 491/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0118\n",
            "Epoch 00491: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0118 - val_loss: 25.4073\n",
            "Epoch 492/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0118\n",
            "Epoch 00492: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0118 - val_loss: 25.4172\n",
            "Epoch 493/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0118\n",
            "Epoch 00493: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0118 - val_loss: 25.4629\n",
            "Epoch 494/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0115\n",
            "Epoch 00494: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0115 - val_loss: 25.4925\n",
            "Epoch 495/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0115\n",
            "Epoch 00495: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0115 - val_loss: 25.4856\n",
            "Epoch 496/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0114\n",
            "Epoch 00496: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0114 - val_loss: 25.4723\n",
            "Epoch 497/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0114\n",
            "Epoch 00497: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0114 - val_loss: 25.5011\n",
            "Epoch 498/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0125\n",
            "Epoch 00498: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0125 - val_loss: 25.5223\n",
            "Epoch 499/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0138\n",
            "Epoch 00499: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0138 - val_loss: 25.6069\n",
            "Epoch 500/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0118\n",
            "Epoch 00500: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0118 - val_loss: 25.5980\n",
            "Epoch 501/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0112\n",
            "Epoch 00501: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0112 - val_loss: 25.5530\n",
            "Epoch 502/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0114\n",
            "Epoch 00502: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0114 - val_loss: 25.5093\n",
            "Epoch 503/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0109\n",
            "Epoch 00503: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0109 - val_loss: 25.4739\n",
            "Epoch 504/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0108\n",
            "Epoch 00504: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0108 - val_loss: 25.5098\n",
            "Epoch 505/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0107\n",
            "Epoch 00505: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0107 - val_loss: 25.5697\n",
            "Epoch 506/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0105\n",
            "Epoch 00506: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0105 - val_loss: 25.5897\n",
            "Epoch 507/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0104\n",
            "Epoch 00507: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0104 - val_loss: 25.6045\n",
            "Epoch 508/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0104\n",
            "Epoch 00508: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0104 - val_loss: 25.6063\n",
            "Epoch 509/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0105\n",
            "Epoch 00509: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0105 - val_loss: 25.6328\n",
            "Epoch 510/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0104\n",
            "Epoch 00510: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0104 - val_loss: 25.6707\n",
            "Epoch 511/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0101\n",
            "Epoch 00511: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0101 - val_loss: 25.7001\n",
            "Epoch 512/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0101\n",
            "Epoch 00512: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0101 - val_loss: 25.7194\n",
            "Epoch 513/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0101\n",
            "Epoch 00513: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0101 - val_loss: 25.7182\n",
            "Epoch 514/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0100\n",
            "Epoch 00514: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0100 - val_loss: 25.7098\n",
            "Epoch 515/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0099\n",
            "Epoch 00515: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0099 - val_loss: 25.7182\n",
            "Epoch 516/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0097\n",
            "Epoch 00516: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0097 - val_loss: 25.7146\n",
            "Epoch 517/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0098\n",
            "Epoch 00517: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0098 - val_loss: 25.7402\n",
            "Epoch 518/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0097\n",
            "Epoch 00518: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0097 - val_loss: 25.7689\n",
            "Epoch 519/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0098\n",
            "Epoch 00519: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0098 - val_loss: 25.7517\n",
            "Epoch 520/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0096\n",
            "Epoch 00520: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0096 - val_loss: 25.7238\n",
            "Epoch 521/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0095\n",
            "Epoch 00521: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0095 - val_loss: 25.7734\n",
            "Epoch 522/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0095\n",
            "Epoch 00522: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0095 - val_loss: 25.8865\n",
            "Epoch 523/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0094\n",
            "Epoch 00523: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0094 - val_loss: 25.9034\n",
            "Epoch 524/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0093\n",
            "Epoch 00524: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0093 - val_loss: 25.8600\n",
            "Epoch 525/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0095\n",
            "Epoch 00525: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0095 - val_loss: 25.8618\n",
            "Epoch 526/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0094\n",
            "Epoch 00526: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0094 - val_loss: 25.8755\n",
            "Epoch 527/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0092\n",
            "Epoch 00527: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0092 - val_loss: 25.8930\n",
            "Epoch 528/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0094\n",
            "Epoch 00528: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0094 - val_loss: 25.8722\n",
            "Epoch 529/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0092\n",
            "Epoch 00529: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0092 - val_loss: 25.9203\n",
            "Epoch 530/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0092\n",
            "Epoch 00530: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0092 - val_loss: 25.9426\n",
            "Epoch 531/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0090\n",
            "Epoch 00531: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0090 - val_loss: 25.9332\n",
            "Epoch 532/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0090\n",
            "Epoch 00532: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0090 - val_loss: 25.9307\n",
            "Epoch 533/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0092\n",
            "Epoch 00533: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0092 - val_loss: 25.9415\n",
            "Epoch 534/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0088\n",
            "Epoch 00534: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0088 - val_loss: 25.8906\n",
            "Epoch 535/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0089\n",
            "Epoch 00535: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0089 - val_loss: 25.9254\n",
            "Epoch 536/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0087\n",
            "Epoch 00536: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0087 - val_loss: 25.9553\n",
            "Epoch 537/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0086\n",
            "Epoch 00537: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0086 - val_loss: 25.9853\n",
            "Epoch 538/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0086\n",
            "Epoch 00538: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0086 - val_loss: 26.0162\n",
            "Epoch 539/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0087\n",
            "Epoch 00539: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0087 - val_loss: 26.0261\n",
            "Epoch 540/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0084\n",
            "Epoch 00540: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0084 - val_loss: 26.0235\n",
            "Epoch 541/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0086\n",
            "Epoch 00541: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0086 - val_loss: 26.0747\n",
            "Epoch 542/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0085\n",
            "Epoch 00542: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0085 - val_loss: 26.0678\n",
            "Epoch 543/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0084\n",
            "Epoch 00543: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0084 - val_loss: 26.0608\n",
            "Epoch 544/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0083\n",
            "Epoch 00544: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0083 - val_loss: 26.0830\n",
            "Epoch 545/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0083\n",
            "Epoch 00545: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0083 - val_loss: 26.0691\n",
            "Epoch 546/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0082\n",
            "Epoch 00546: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0082 - val_loss: 26.0787\n",
            "Epoch 547/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0082\n",
            "Epoch 00547: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0082 - val_loss: 26.1190\n",
            "Epoch 548/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0081\n",
            "Epoch 00548: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0081 - val_loss: 26.1482\n",
            "Epoch 549/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0081\n",
            "Epoch 00549: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0081 - val_loss: 26.1638\n",
            "Epoch 550/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0080\n",
            "Epoch 00550: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0080 - val_loss: 26.2139\n",
            "Epoch 551/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0080\n",
            "Epoch 00551: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0080 - val_loss: 26.1975\n",
            "Epoch 552/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0078\n",
            "Epoch 00552: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0078 - val_loss: 26.2143\n",
            "Epoch 553/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0079\n",
            "Epoch 00553: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0079 - val_loss: 26.2425\n",
            "Epoch 554/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0079\n",
            "Epoch 00554: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0079 - val_loss: 26.2231\n",
            "Epoch 555/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0079\n",
            "Epoch 00555: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0079 - val_loss: 26.2435\n",
            "Epoch 556/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0078\n",
            "Epoch 00556: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0078 - val_loss: 26.2042\n",
            "Epoch 557/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0079\n",
            "Epoch 00557: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0079 - val_loss: 26.2067\n",
            "Epoch 558/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0077\n",
            "Epoch 00558: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0077 - val_loss: 26.2624\n",
            "Epoch 559/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0078\n",
            "Epoch 00559: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0078 - val_loss: 26.2380\n",
            "Epoch 560/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0076\n",
            "Epoch 00560: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0076 - val_loss: 26.2328\n",
            "Epoch 561/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0075\n",
            "Epoch 00561: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0075 - val_loss: 26.2986\n",
            "Epoch 562/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0077\n",
            "Epoch 00562: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0077 - val_loss: 26.3271\n",
            "Epoch 563/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0075\n",
            "Epoch 00563: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0075 - val_loss: 26.3065\n",
            "Epoch 564/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0078\n",
            "Epoch 00564: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0078 - val_loss: 26.3431\n",
            "Epoch 565/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0077\n",
            "Epoch 00565: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0077 - val_loss: 26.3698\n",
            "Epoch 566/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0077\n",
            "Epoch 00566: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0077 - val_loss: 26.3570\n",
            "Epoch 567/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0075\n",
            "Epoch 00567: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0075 - val_loss: 26.3434\n",
            "Epoch 568/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0073\n",
            "Epoch 00568: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0073 - val_loss: 26.3436\n",
            "Epoch 569/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0073\n",
            "Epoch 00569: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0073 - val_loss: 26.3534\n",
            "Epoch 570/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0073\n",
            "Epoch 00570: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0073 - val_loss: 26.3837\n",
            "Epoch 571/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0072\n",
            "Epoch 00571: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0072 - val_loss: 26.4014\n",
            "Epoch 572/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0071\n",
            "Epoch 00572: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0071 - val_loss: 26.4218\n",
            "Epoch 573/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0072\n",
            "Epoch 00573: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0072 - val_loss: 26.4513\n",
            "Epoch 574/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0071\n",
            "Epoch 00574: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0071 - val_loss: 26.4594\n",
            "Epoch 575/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0070\n",
            "Epoch 00575: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0070 - val_loss: 26.4778\n",
            "Epoch 576/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0070\n",
            "Epoch 00576: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0070 - val_loss: 26.4932\n",
            "Epoch 577/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0069\n",
            "Epoch 00577: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0069 - val_loss: 26.5088\n",
            "Epoch 578/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0070\n",
            "Epoch 00578: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0070 - val_loss: 26.5050\n",
            "Epoch 579/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0070\n",
            "Epoch 00579: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0070 - val_loss: 26.5162\n",
            "Epoch 580/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0069\n",
            "Epoch 00580: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0069 - val_loss: 26.5362\n",
            "Epoch 581/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0068\n",
            "Epoch 00581: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0068 - val_loss: 26.5228\n",
            "Epoch 582/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0069\n",
            "Epoch 00582: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0069 - val_loss: 26.5643\n",
            "Epoch 583/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0069\n",
            "Epoch 00583: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0069 - val_loss: 26.5896\n",
            "Epoch 584/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0069\n",
            "Epoch 00584: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0069 - val_loss: 26.6391\n",
            "Epoch 585/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0070\n",
            "Epoch 00585: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0070 - val_loss: 26.6502\n",
            "Epoch 586/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 00586: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0067 - val_loss: 26.6046\n",
            "Epoch 587/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0068\n",
            "Epoch 00587: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0068 - val_loss: 26.6232\n",
            "Epoch 588/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0068\n",
            "Epoch 00588: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0068 - val_loss: 26.6252\n",
            "Epoch 589/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0066\n",
            "Epoch 00589: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0066 - val_loss: 26.6270\n",
            "Epoch 590/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0065\n",
            "Epoch 00590: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0065 - val_loss: 26.6715\n",
            "Epoch 591/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0066\n",
            "Epoch 00591: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0066 - val_loss: 26.7236\n",
            "Epoch 592/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0065\n",
            "Epoch 00592: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0065 - val_loss: 26.7235\n",
            "Epoch 593/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0064\n",
            "Epoch 00593: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0064 - val_loss: 26.7387\n",
            "Epoch 594/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0066\n",
            "Epoch 00594: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0066 - val_loss: 26.6868\n",
            "Epoch 595/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0064\n",
            "Epoch 00595: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0064 - val_loss: 26.6752\n",
            "Epoch 596/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0064\n",
            "Epoch 00596: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0064 - val_loss: 26.6772\n",
            "Epoch 597/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0066\n",
            "Epoch 00597: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0066 - val_loss: 26.7445\n",
            "Epoch 598/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0064\n",
            "Epoch 00598: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0064 - val_loss: 26.7672\n",
            "Epoch 599/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0066\n",
            "Epoch 00599: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0066 - val_loss: 26.7639\n",
            "Epoch 600/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0070\n",
            "Epoch 00600: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0070 - val_loss: 26.9906\n",
            "Epoch 601/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0235\n",
            "Epoch 00601: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0235 - val_loss: 27.1350\n",
            "Epoch 602/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1991\n",
            "Epoch 00602: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1991 - val_loss: 28.0605\n",
            "Epoch 603/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7617\n",
            "Epoch 00603: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.7617 - val_loss: 31.1800\n",
            "Epoch 604/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 2.1852\n",
            "Epoch 00604: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 2.1852 - val_loss: 30.6875\n",
            "Epoch 605/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 4.0880\n",
            "Epoch 00605: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 4.0880 - val_loss: 29.9740\n",
            "Epoch 606/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 4.9776\n",
            "Epoch 00606: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 4.9776 - val_loss: 29.3533\n",
            "Epoch 607/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 3.5067\n",
            "Epoch 00607: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 3.5067 - val_loss: 25.4782\n",
            "Epoch 608/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 2.4352\n",
            "Epoch 00608: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 2.4352 - val_loss: 23.9465\n",
            "Epoch 609/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.8010\n",
            "Epoch 00609: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 1.8010 - val_loss: 24.1023\n",
            "Epoch 610/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.1872\n",
            "Epoch 00610: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 1.1872 - val_loss: 23.0792\n",
            "Epoch 611/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7677\n",
            "Epoch 00611: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.7677 - val_loss: 23.4188\n",
            "Epoch 612/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4735\n",
            "Epoch 00612: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.4735 - val_loss: 23.8906\n",
            "Epoch 613/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3538\n",
            "Epoch 00613: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.3538 - val_loss: 23.1245\n",
            "Epoch 614/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2362\n",
            "Epoch 00614: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2362 - val_loss: 23.3149\n",
            "Epoch 615/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1650\n",
            "Epoch 00615: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1650 - val_loss: 22.4641\n",
            "Epoch 616/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1368\n",
            "Epoch 00616: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1368 - val_loss: 22.8681\n",
            "Epoch 617/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1028\n",
            "Epoch 00617: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1028 - val_loss: 23.4125\n",
            "Epoch 618/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0731\n",
            "Epoch 00618: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0731 - val_loss: 23.2388\n",
            "Epoch 619/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0598\n",
            "Epoch 00619: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0598 - val_loss: 23.2429\n",
            "Epoch 620/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0467\n",
            "Epoch 00620: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0467 - val_loss: 23.4659\n",
            "Epoch 621/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0386\n",
            "Epoch 00621: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0386 - val_loss: 23.6256\n",
            "Epoch 622/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0342\n",
            "Epoch 00622: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0342 - val_loss: 23.5305\n",
            "Epoch 623/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0314\n",
            "Epoch 00623: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0314 - val_loss: 23.4764\n",
            "Epoch 624/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0304\n",
            "Epoch 00624: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0304 - val_loss: 23.5294\n",
            "Epoch 625/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0273\n",
            "Epoch 00625: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0273 - val_loss: 23.6608\n",
            "Epoch 626/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0245\n",
            "Epoch 00626: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0245 - val_loss: 23.7700\n",
            "Epoch 627/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0231\n",
            "Epoch 00627: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0231 - val_loss: 23.7738\n",
            "Epoch 628/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0215\n",
            "Epoch 00628: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0215 - val_loss: 23.8154\n",
            "Epoch 629/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0219\n",
            "Epoch 00629: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0219 - val_loss: 23.9012\n",
            "Epoch 630/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0201\n",
            "Epoch 00630: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0201 - val_loss: 23.9254\n",
            "Epoch 631/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0190\n",
            "Epoch 00631: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0190 - val_loss: 23.9533\n",
            "Epoch 632/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0185\n",
            "Epoch 00632: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0185 - val_loss: 23.9498\n",
            "Epoch 633/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0188\n",
            "Epoch 00633: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0188 - val_loss: 24.0128\n",
            "Epoch 634/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0173\n",
            "Epoch 00634: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0173 - val_loss: 24.0814\n",
            "Epoch 635/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0174\n",
            "Epoch 00635: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0174 - val_loss: 24.1053\n",
            "Epoch 636/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0162\n",
            "Epoch 00636: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0162 - val_loss: 24.1160\n",
            "Epoch 637/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0156\n",
            "Epoch 00637: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0156 - val_loss: 24.0951\n",
            "Epoch 638/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0150\n",
            "Epoch 00638: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0150 - val_loss: 24.1316\n",
            "Epoch 639/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0148\n",
            "Epoch 00639: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0148 - val_loss: 24.2021\n",
            "Epoch 640/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0148\n",
            "Epoch 00640: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0148 - val_loss: 24.1993\n",
            "Epoch 641/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0144\n",
            "Epoch 00641: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0144 - val_loss: 24.2110\n",
            "Epoch 642/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0138\n",
            "Epoch 00642: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0138 - val_loss: 24.2378\n",
            "Epoch 643/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0133\n",
            "Epoch 00643: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0133 - val_loss: 24.2250\n",
            "Epoch 644/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0134\n",
            "Epoch 00644: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0134 - val_loss: 24.2793\n",
            "Epoch 645/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0130\n",
            "Epoch 00645: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0130 - val_loss: 24.2844\n",
            "Epoch 646/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0128\n",
            "Epoch 00646: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0128 - val_loss: 24.3142\n",
            "Epoch 647/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0124\n",
            "Epoch 00647: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0124 - val_loss: 24.4840\n",
            "Epoch 648/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0139\n",
            "Epoch 00648: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0139 - val_loss: 24.3936\n",
            "Epoch 649/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0124\n",
            "Epoch 00649: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0124 - val_loss: 24.3146\n",
            "Epoch 650/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0119\n",
            "Epoch 00650: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0119 - val_loss: 24.3734\n",
            "Epoch 651/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0125\n",
            "Epoch 00651: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0125 - val_loss: 24.5236\n",
            "Epoch 652/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0117\n",
            "Epoch 00652: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0117 - val_loss: 24.6414\n",
            "Epoch 653/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0115\n",
            "Epoch 00653: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0115 - val_loss: 24.6703\n",
            "Epoch 654/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0116\n",
            "Epoch 00654: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0116 - val_loss: 24.5905\n",
            "Epoch 655/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0112\n",
            "Epoch 00655: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0112 - val_loss: 24.5407\n",
            "Epoch 656/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0110\n",
            "Epoch 00656: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0110 - val_loss: 24.5352\n",
            "Epoch 657/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0107\n",
            "Epoch 00657: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0107 - val_loss: 24.5193\n",
            "Epoch 658/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0117\n",
            "Epoch 00658: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0117 - val_loss: 24.5446\n",
            "Epoch 659/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0102\n",
            "Epoch 00659: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0102 - val_loss: 24.6159\n",
            "Epoch 660/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0108\n",
            "Epoch 00660: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0108 - val_loss: 24.6107\n",
            "Epoch 661/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0103\n",
            "Epoch 00661: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0103 - val_loss: 24.6836\n",
            "Epoch 662/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0098\n",
            "Epoch 00662: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0098 - val_loss: 24.7941\n",
            "Epoch 663/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0097\n",
            "Epoch 00663: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0097 - val_loss: 24.8142\n",
            "Epoch 664/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0101\n",
            "Epoch 00664: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0101 - val_loss: 24.7831\n",
            "Epoch 665/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0098\n",
            "Epoch 00665: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0098 - val_loss: 24.7731\n",
            "Epoch 666/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0093\n",
            "Epoch 00666: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0093 - val_loss: 24.8417\n",
            "Epoch 667/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0096\n",
            "Epoch 00667: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0096 - val_loss: 24.9027\n",
            "Epoch 668/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0095\n",
            "Epoch 00668: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0095 - val_loss: 24.9295\n",
            "Epoch 669/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0089\n",
            "Epoch 00669: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0089 - val_loss: 24.9340\n",
            "Epoch 670/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0092\n",
            "Epoch 00670: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0092 - val_loss: 24.9128\n",
            "Epoch 671/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0089\n",
            "Epoch 00671: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0089 - val_loss: 24.8883\n",
            "Epoch 672/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0096\n",
            "Epoch 00672: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0096 - val_loss: 24.9211\n",
            "Epoch 673/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0094\n",
            "Epoch 00673: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0094 - val_loss: 25.0364\n",
            "Epoch 674/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0090\n",
            "Epoch 00674: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0090 - val_loss: 25.1099\n",
            "Epoch 675/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0091\n",
            "Epoch 00675: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0091 - val_loss: 25.0615\n",
            "Epoch 676/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0087\n",
            "Epoch 00676: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0087 - val_loss: 25.0189\n",
            "Epoch 677/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0093\n",
            "Epoch 00677: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0093 - val_loss: 25.0171\n",
            "Epoch 678/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0087\n",
            "Epoch 00678: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0087 - val_loss: 25.0344\n",
            "Epoch 679/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0082\n",
            "Epoch 00679: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0082 - val_loss: 25.0310\n",
            "Epoch 680/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0082\n",
            "Epoch 00680: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0082 - val_loss: 25.0731\n",
            "Epoch 681/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0083\n",
            "Epoch 00681: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0083 - val_loss: 25.0249\n",
            "Epoch 682/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0084\n",
            "Epoch 00682: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0084 - val_loss: 25.1024\n",
            "Epoch 683/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0083\n",
            "Epoch 00683: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0083 - val_loss: 25.1636\n",
            "Epoch 684/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0078\n",
            "Epoch 00684: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0078 - val_loss: 25.1598\n",
            "Epoch 685/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0080\n",
            "Epoch 00685: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0080 - val_loss: 25.1980\n",
            "Epoch 686/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0080\n",
            "Epoch 00686: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0080 - val_loss: 25.1312\n",
            "Epoch 687/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0079\n",
            "Epoch 00687: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0079 - val_loss: 25.1536\n",
            "Epoch 688/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0078\n",
            "Epoch 00688: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0078 - val_loss: 25.1786\n",
            "Epoch 689/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0081\n",
            "Epoch 00689: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0081 - val_loss: 25.1855\n",
            "Epoch 690/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0077\n",
            "Epoch 00690: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0077 - val_loss: 25.1934\n",
            "Epoch 691/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0079\n",
            "Epoch 00691: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0079 - val_loss: 25.1499\n",
            "Epoch 692/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0075\n",
            "Epoch 00692: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0075 - val_loss: 25.1222\n",
            "Epoch 693/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0073\n",
            "Epoch 00693: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0073 - val_loss: 25.2075\n",
            "Epoch 694/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0073\n",
            "Epoch 00694: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0073 - val_loss: 25.2260\n",
            "Epoch 695/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0073\n",
            "Epoch 00695: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0073 - val_loss: 25.1930\n",
            "Epoch 696/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0069\n",
            "Epoch 00696: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0069 - val_loss: 25.2233\n",
            "Epoch 697/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0069\n",
            "Epoch 00697: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0069 - val_loss: 25.2676\n",
            "Epoch 698/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0068\n",
            "Epoch 00698: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0068 - val_loss: 25.2988\n",
            "Epoch 699/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0067\n",
            "Epoch 00699: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0067 - val_loss: 25.3319\n",
            "Epoch 700/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0066\n",
            "Epoch 00700: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0066 - val_loss: 25.3496\n",
            "Epoch 701/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0069\n",
            "Epoch 00701: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0069 - val_loss: 25.3504\n",
            "Epoch 702/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0068\n",
            "Epoch 00702: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0068 - val_loss: 25.3694\n",
            "Epoch 703/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0065\n",
            "Epoch 00703: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0065 - val_loss: 25.4233\n",
            "Epoch 704/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0065\n",
            "Epoch 00704: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0065 - val_loss: 25.4200\n",
            "Epoch 705/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0068\n",
            "Epoch 00705: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0068 - val_loss: 25.5277\n",
            "Epoch 706/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0064\n",
            "Epoch 00706: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0064 - val_loss: 25.5787\n",
            "Epoch 707/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0066\n",
            "Epoch 00707: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0066 - val_loss: 25.5917\n",
            "Epoch 708/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0065\n",
            "Epoch 00708: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0065 - val_loss: 25.5802\n",
            "Epoch 709/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0064\n",
            "Epoch 00709: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0064 - val_loss: 25.5116\n",
            "Epoch 710/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0063\n",
            "Epoch 00710: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0063 - val_loss: 25.4788\n",
            "Epoch 711/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0062\n",
            "Epoch 00711: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0062 - val_loss: 25.4646\n",
            "Epoch 712/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0062\n",
            "Epoch 00712: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0062 - val_loss: 25.4559\n",
            "Epoch 713/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0063\n",
            "Epoch 00713: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0063 - val_loss: 25.4945\n",
            "Epoch 714/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0064\n",
            "Epoch 00714: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0064 - val_loss: 25.5099\n",
            "Epoch 715/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0062\n",
            "Epoch 00715: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0062 - val_loss: 25.4955\n",
            "Epoch 716/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0061\n",
            "Epoch 00716: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0061 - val_loss: 25.5171\n",
            "Epoch 717/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0059\n",
            "Epoch 00717: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0059 - val_loss: 25.5644\n",
            "Epoch 718/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0061\n",
            "Epoch 00718: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0061 - val_loss: 25.5412\n",
            "Epoch 719/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0060\n",
            "Epoch 00719: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0060 - val_loss: 25.5457\n",
            "Epoch 720/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0058\n",
            "Epoch 00720: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0058 - val_loss: 25.6112\n",
            "Epoch 721/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0058\n",
            "Epoch 00721: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0058 - val_loss: 25.6629\n",
            "Epoch 722/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0059\n",
            "Epoch 00722: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0059 - val_loss: 25.6728\n",
            "Epoch 723/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0059\n",
            "Epoch 00723: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0059 - val_loss: 25.6527\n",
            "Epoch 724/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0059\n",
            "Epoch 00724: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0059 - val_loss: 25.6598\n",
            "Epoch 725/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0058\n",
            "Epoch 00725: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0058 - val_loss: 25.7001\n",
            "Epoch 726/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0059\n",
            "Epoch 00726: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0059 - val_loss: 25.6872\n",
            "Epoch 727/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0055\n",
            "Epoch 00727: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0055 - val_loss: 25.6773\n",
            "Epoch 728/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0056\n",
            "Epoch 00728: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0056 - val_loss: 25.6709\n",
            "Epoch 729/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0055\n",
            "Epoch 00729: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0055 - val_loss: 25.6871\n",
            "Epoch 730/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0054\n",
            "Epoch 00730: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0054 - val_loss: 25.7269\n",
            "Epoch 731/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0056\n",
            "Epoch 00731: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0056 - val_loss: 25.7366\n",
            "Epoch 732/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0055\n",
            "Epoch 00732: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0055 - val_loss: 25.7649\n",
            "Epoch 733/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0054\n",
            "Epoch 00733: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0054 - val_loss: 25.7747\n",
            "Epoch 734/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0054\n",
            "Epoch 00734: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0054 - val_loss: 25.7748\n",
            "Epoch 735/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0055\n",
            "Epoch 00735: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0055 - val_loss: 25.7838\n",
            "Epoch 736/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0054\n",
            "Epoch 00736: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0054 - val_loss: 25.7857\n",
            "Epoch 737/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0053\n",
            "Epoch 00737: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0053 - val_loss: 25.7669\n",
            "Epoch 738/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0054\n",
            "Epoch 00738: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0054 - val_loss: 25.7610\n",
            "Epoch 739/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0054\n",
            "Epoch 00739: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0054 - val_loss: 25.7941\n",
            "Epoch 740/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0053\n",
            "Epoch 00740: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0053 - val_loss: 25.8406\n",
            "Epoch 741/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0052\n",
            "Epoch 00741: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0052 - val_loss: 25.8209\n",
            "Epoch 742/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0051\n",
            "Epoch 00742: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0051 - val_loss: 25.8140\n",
            "Epoch 743/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0051\n",
            "Epoch 00743: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0051 - val_loss: 25.8185\n",
            "Epoch 744/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0052\n",
            "Epoch 00744: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0052 - val_loss: 25.8282\n",
            "Epoch 745/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0052\n",
            "Epoch 00745: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0052 - val_loss: 25.8388\n",
            "Epoch 746/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0051\n",
            "Epoch 00746: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0051 - val_loss: 25.8779\n",
            "Epoch 747/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0051\n",
            "Epoch 00747: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0051 - val_loss: 25.9192\n",
            "Epoch 748/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0050\n",
            "Epoch 00748: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0050 - val_loss: 25.9582\n",
            "Epoch 749/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0050\n",
            "Epoch 00749: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0050 - val_loss: 25.9993\n",
            "Epoch 750/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0051\n",
            "Epoch 00750: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0051 - val_loss: 25.9491\n",
            "Epoch 751/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0050\n",
            "Epoch 00751: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0050 - val_loss: 25.9059\n",
            "Epoch 752/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0050\n",
            "Epoch 00752: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0050 - val_loss: 25.9153\n",
            "Epoch 753/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0049\n",
            "Epoch 00753: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0049 - val_loss: 25.9571\n",
            "Epoch 754/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0050\n",
            "Epoch 00754: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0050 - val_loss: 25.9967\n",
            "Epoch 755/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0049\n",
            "Epoch 00755: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0049 - val_loss: 26.0125\n",
            "Epoch 756/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0049\n",
            "Epoch 00756: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0049 - val_loss: 26.0131\n",
            "Epoch 757/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0048\n",
            "Epoch 00757: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0048 - val_loss: 26.0220\n",
            "Epoch 758/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0047\n",
            "Epoch 00758: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0047 - val_loss: 26.0376\n",
            "Epoch 759/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0048\n",
            "Epoch 00759: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0048 - val_loss: 26.0655\n",
            "Epoch 760/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0048\n",
            "Epoch 00760: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0048 - val_loss: 26.0624\n",
            "Epoch 761/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0047\n",
            "Epoch 00761: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0047 - val_loss: 26.0612\n",
            "Epoch 762/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0046\n",
            "Epoch 00762: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0046 - val_loss: 26.0738\n",
            "Epoch 763/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0046\n",
            "Epoch 00763: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0046 - val_loss: 26.1027\n",
            "Epoch 764/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0046\n",
            "Epoch 00764: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0046 - val_loss: 26.1509\n",
            "Epoch 765/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0047\n",
            "Epoch 00765: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0047 - val_loss: 26.1403\n",
            "Epoch 766/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0046\n",
            "Epoch 00766: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0046 - val_loss: 26.1392\n",
            "Epoch 767/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0046\n",
            "Epoch 00767: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0046 - val_loss: 26.1403\n",
            "Epoch 768/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0045\n",
            "Epoch 00768: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0045 - val_loss: 26.1594\n",
            "Epoch 769/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00769: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.1598\n",
            "Epoch 770/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0046\n",
            "Epoch 00770: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0046 - val_loss: 26.1776\n",
            "Epoch 771/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0045\n",
            "Epoch 00771: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0045 - val_loss: 26.1842\n",
            "Epoch 772/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0045\n",
            "Epoch 00772: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0045 - val_loss: 26.1714\n",
            "Epoch 773/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0047\n",
            "Epoch 00773: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0047 - val_loss: 26.1497\n",
            "Epoch 774/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00774: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.1642\n",
            "Epoch 775/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0045\n",
            "Epoch 00775: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0045 - val_loss: 26.2142\n",
            "Epoch 776/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00776: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.2452\n",
            "Epoch 777/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00777: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.2428\n",
            "Epoch 778/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00778: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.2513\n",
            "Epoch 779/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00779: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.2943\n",
            "Epoch 780/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00780: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.3320\n",
            "Epoch 781/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00781: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.3366\n",
            "Epoch 782/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 00782: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0043 - val_loss: 26.3260\n",
            "Epoch 783/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 00783: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0043 - val_loss: 26.3462\n",
            "Epoch 784/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0042\n",
            "Epoch 00784: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0042 - val_loss: 26.3541\n",
            "Epoch 785/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00785: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.3529\n",
            "Epoch 786/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 00786: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0043 - val_loss: 26.3398\n",
            "Epoch 787/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00787: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.3725\n",
            "Epoch 788/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 00788: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0043 - val_loss: 26.3352\n",
            "Epoch 789/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0042\n",
            "Epoch 00789: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0042 - val_loss: 26.3207\n",
            "Epoch 790/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 00790: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0043 - val_loss: 26.3324\n",
            "Epoch 791/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 00791: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0043 - val_loss: 26.3878\n",
            "Epoch 792/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 00792: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0043 - val_loss: 26.3560\n",
            "Epoch 793/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 00793: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0043 - val_loss: 26.3417\n",
            "Epoch 794/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0042\n",
            "Epoch 00794: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0042 - val_loss: 26.3186\n",
            "Epoch 795/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 00795: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0043 - val_loss: 26.4171\n",
            "Epoch 796/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0051\n",
            "Epoch 00796: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0051 - val_loss: 26.5210\n",
            "Epoch 797/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0096\n",
            "Epoch 00797: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0096 - val_loss: 26.4260\n",
            "Epoch 798/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0129\n",
            "Epoch 00798: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0129 - val_loss: 26.2976\n",
            "Epoch 799/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0222\n",
            "Epoch 00799: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0222 - val_loss: 28.0987\n",
            "Epoch 800/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0429\n",
            "Epoch 00800: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0429 - val_loss: 26.2961\n",
            "Epoch 801/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0916\n",
            "Epoch 00801: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0916 - val_loss: 26.7999\n",
            "Epoch 802/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3129\n",
            "Epoch 00802: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.3129 - val_loss: 28.0438\n",
            "Epoch 803/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6003\n",
            "Epoch 00803: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.6003 - val_loss: 31.6025\n",
            "Epoch 804/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.5937\n",
            "Epoch 00804: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 1.5937 - val_loss: 32.6880\n",
            "Epoch 805/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 2.9115\n",
            "Epoch 00805: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 2.9115 - val_loss: 30.6488\n",
            "Epoch 806/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 3.2476\n",
            "Epoch 00806: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 3.2476 - val_loss: 30.8310\n",
            "Epoch 807/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 3.1535\n",
            "Epoch 00807: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 3.1535 - val_loss: 26.4303\n",
            "Epoch 808/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 2.2172\n",
            "Epoch 00808: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 2.2172 - val_loss: 31.4312\n",
            "Epoch 809/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.4884\n",
            "Epoch 00809: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 1.4884 - val_loss: 25.2005\n",
            "Epoch 810/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 1.0939\n",
            "Epoch 00810: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 1.0939 - val_loss: 25.2721\n",
            "Epoch 811/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7340\n",
            "Epoch 00811: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.7340 - val_loss: 26.0115\n",
            "Epoch 812/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4596\n",
            "Epoch 00812: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.4596 - val_loss: 25.0864\n",
            "Epoch 813/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3195\n",
            "Epoch 00813: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.3195 - val_loss: 23.9510\n",
            "Epoch 814/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2112\n",
            "Epoch 00814: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.2112 - val_loss: 24.2668\n",
            "Epoch 815/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1632\n",
            "Epoch 00815: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1632 - val_loss: 23.8603\n",
            "Epoch 816/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1028\n",
            "Epoch 00816: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.1028 - val_loss: 23.8421\n",
            "Epoch 817/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0760\n",
            "Epoch 00817: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0760 - val_loss: 24.0900\n",
            "Epoch 818/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0575\n",
            "Epoch 00818: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0575 - val_loss: 24.1360\n",
            "Epoch 819/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0440\n",
            "Epoch 00819: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0440 - val_loss: 24.1451\n",
            "Epoch 820/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0349\n",
            "Epoch 00820: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0349 - val_loss: 24.0552\n",
            "Epoch 821/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0319\n",
            "Epoch 00821: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0319 - val_loss: 24.1700\n",
            "Epoch 822/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0304\n",
            "Epoch 00822: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0304 - val_loss: 24.2212\n",
            "Epoch 823/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0248\n",
            "Epoch 00823: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0248 - val_loss: 24.2012\n",
            "Epoch 824/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0204\n",
            "Epoch 00824: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0204 - val_loss: 24.1836\n",
            "Epoch 825/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0209\n",
            "Epoch 00825: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0209 - val_loss: 24.2516\n",
            "Epoch 826/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0181\n",
            "Epoch 00826: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0181 - val_loss: 24.3723\n",
            "Epoch 827/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0178\n",
            "Epoch 00827: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0178 - val_loss: 24.5448\n",
            "Epoch 828/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0162\n",
            "Epoch 00828: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0162 - val_loss: 24.5283\n",
            "Epoch 829/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0155\n",
            "Epoch 00829: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0155 - val_loss: 24.5887\n",
            "Epoch 830/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0140\n",
            "Epoch 00830: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0140 - val_loss: 24.6075\n",
            "Epoch 831/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0130\n",
            "Epoch 00831: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0130 - val_loss: 24.6774\n",
            "Epoch 832/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0131\n",
            "Epoch 00832: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0131 - val_loss: 24.6166\n",
            "Epoch 833/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0123\n",
            "Epoch 00833: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0123 - val_loss: 24.6049\n",
            "Epoch 834/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0122\n",
            "Epoch 00834: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0122 - val_loss: 24.6968\n",
            "Epoch 835/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0129\n",
            "Epoch 00835: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0129 - val_loss: 24.7786\n",
            "Epoch 836/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0108\n",
            "Epoch 00836: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0108 - val_loss: 24.7831\n",
            "Epoch 837/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0108\n",
            "Epoch 00837: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0108 - val_loss: 24.7547\n",
            "Epoch 838/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0104\n",
            "Epoch 00838: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0104 - val_loss: 24.7177\n",
            "Epoch 839/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0102\n",
            "Epoch 00839: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0102 - val_loss: 24.7312\n",
            "Epoch 840/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0094\n",
            "Epoch 00840: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0094 - val_loss: 24.8277\n",
            "Epoch 841/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0090\n",
            "Epoch 00841: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0090 - val_loss: 24.9183\n",
            "Epoch 842/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0095\n",
            "Epoch 00842: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0095 - val_loss: 24.9183\n",
            "Epoch 843/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0093\n",
            "Epoch 00843: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0093 - val_loss: 24.9197\n",
            "Epoch 844/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0095\n",
            "Epoch 00844: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0095 - val_loss: 25.0507\n",
            "Epoch 845/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0087\n",
            "Epoch 00845: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0087 - val_loss: 25.0794\n",
            "Epoch 846/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0087\n",
            "Epoch 00846: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0087 - val_loss: 25.0880\n",
            "Epoch 847/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0083\n",
            "Epoch 00847: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0083 - val_loss: 25.0892\n",
            "Epoch 848/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0081\n",
            "Epoch 00848: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0081 - val_loss: 25.0512\n",
            "Epoch 849/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0086\n",
            "Epoch 00849: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0086 - val_loss: 25.0355\n",
            "Epoch 850/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0087\n",
            "Epoch 00850: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0087 - val_loss: 25.0705\n",
            "Epoch 851/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0080\n",
            "Epoch 00851: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0080 - val_loss: 25.1536\n",
            "Epoch 852/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0081\n",
            "Epoch 00852: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0081 - val_loss: 25.2070\n",
            "Epoch 853/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0079\n",
            "Epoch 00853: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0079 - val_loss: 25.2261\n",
            "Epoch 854/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0078\n",
            "Epoch 00854: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0078 - val_loss: 25.2361\n",
            "Epoch 855/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0078\n",
            "Epoch 00855: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0078 - val_loss: 25.2462\n",
            "Epoch 856/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0072\n",
            "Epoch 00856: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0072 - val_loss: 25.2742\n",
            "Epoch 857/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0073\n",
            "Epoch 00857: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0073 - val_loss: 25.3302\n",
            "Epoch 858/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0072\n",
            "Epoch 00858: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0072 - val_loss: 25.3757\n",
            "Epoch 859/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0073\n",
            "Epoch 00859: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0073 - val_loss: 25.3908\n",
            "Epoch 860/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0068\n",
            "Epoch 00860: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0068 - val_loss: 25.3763\n",
            "Epoch 861/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0068\n",
            "Epoch 00861: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0068 - val_loss: 25.3795\n",
            "Epoch 862/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0065\n",
            "Epoch 00862: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0065 - val_loss: 25.3952\n",
            "Epoch 863/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0068\n",
            "Epoch 00863: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0068 - val_loss: 25.4360\n",
            "Epoch 864/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0065\n",
            "Epoch 00864: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0065 - val_loss: 25.4526\n",
            "Epoch 865/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0065\n",
            "Epoch 00865: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0065 - val_loss: 25.4628\n",
            "Epoch 866/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0064\n",
            "Epoch 00866: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0064 - val_loss: 25.4800\n",
            "Epoch 867/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0062\n",
            "Epoch 00867: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0062 - val_loss: 25.4920\n",
            "Epoch 868/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0062\n",
            "Epoch 00868: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0062 - val_loss: 25.5125\n",
            "Epoch 869/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0062\n",
            "Epoch 00869: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0062 - val_loss: 25.5401\n",
            "Epoch 870/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0061\n",
            "Epoch 00870: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0061 - val_loss: 25.5745\n",
            "Epoch 871/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0062\n",
            "Epoch 00871: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0062 - val_loss: 25.5673\n",
            "Epoch 872/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0059\n",
            "Epoch 00872: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0059 - val_loss: 25.5643\n",
            "Epoch 873/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0062\n",
            "Epoch 00873: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0062 - val_loss: 25.5787\n",
            "Epoch 874/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0060\n",
            "Epoch 00874: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0060 - val_loss: 25.6109\n",
            "Epoch 875/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0061\n",
            "Epoch 00875: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0061 - val_loss: 25.6322\n",
            "Epoch 876/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0058\n",
            "Epoch 00876: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0058 - val_loss: 25.6411\n",
            "Epoch 877/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0061\n",
            "Epoch 00877: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0061 - val_loss: 25.6622\n",
            "Epoch 878/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0059\n",
            "Epoch 00878: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0059 - val_loss: 25.7272\n",
            "Epoch 879/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0068\n",
            "Epoch 00879: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0068 - val_loss: 25.7242\n",
            "Epoch 880/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0062\n",
            "Epoch 00880: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0062 - val_loss: 25.7231\n",
            "Epoch 881/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0058\n",
            "Epoch 00881: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0058 - val_loss: 25.7262\n",
            "Epoch 882/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0056\n",
            "Epoch 00882: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0056 - val_loss: 25.7685\n",
            "Epoch 883/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0054\n",
            "Epoch 00883: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0054 - val_loss: 25.8273\n",
            "Epoch 884/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0053\n",
            "Epoch 00884: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0053 - val_loss: 25.8505\n",
            "Epoch 885/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0054\n",
            "Epoch 00885: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0054 - val_loss: 25.8669\n",
            "Epoch 886/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0056\n",
            "Epoch 00886: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0056 - val_loss: 25.8515\n",
            "Epoch 887/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0054\n",
            "Epoch 00887: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0054 - val_loss: 25.8224\n",
            "Epoch 888/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0052\n",
            "Epoch 00888: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0052 - val_loss: 25.8076\n",
            "Epoch 889/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0052\n",
            "Epoch 00889: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0052 - val_loss: 25.8253\n",
            "Epoch 890/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0051\n",
            "Epoch 00890: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0051 - val_loss: 25.8470\n",
            "Epoch 891/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0052\n",
            "Epoch 00891: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0052 - val_loss: 25.8584\n",
            "Epoch 892/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0051\n",
            "Epoch 00892: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0051 - val_loss: 25.8707\n",
            "Epoch 893/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0050\n",
            "Epoch 00893: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0050 - val_loss: 25.8767\n",
            "Epoch 894/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0050\n",
            "Epoch 00894: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0050 - val_loss: 25.9031\n",
            "Epoch 895/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0050\n",
            "Epoch 00895: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0050 - val_loss: 25.9357\n",
            "Epoch 896/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0050\n",
            "Epoch 00896: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0050 - val_loss: 25.9768\n",
            "Epoch 897/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0049\n",
            "Epoch 00897: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0049 - val_loss: 25.9699\n",
            "Epoch 898/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0048\n",
            "Epoch 00898: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0048 - val_loss: 25.9927\n",
            "Epoch 899/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0049\n",
            "Epoch 00899: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0049 - val_loss: 26.0231\n",
            "Epoch 900/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0050\n",
            "Epoch 00900: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0050 - val_loss: 26.0405\n",
            "Epoch 901/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0048\n",
            "Epoch 00901: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0048 - val_loss: 25.9863\n",
            "Epoch 902/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0050\n",
            "Epoch 00902: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0050 - val_loss: 25.9528\n",
            "Epoch 903/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0047\n",
            "Epoch 00903: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0047 - val_loss: 25.9809\n",
            "Epoch 904/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0047\n",
            "Epoch 00904: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0047 - val_loss: 25.9916\n",
            "Epoch 905/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0046\n",
            "Epoch 00905: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0046 - val_loss: 26.0131\n",
            "Epoch 906/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0047\n",
            "Epoch 00906: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0047 - val_loss: 26.0894\n",
            "Epoch 907/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0047\n",
            "Epoch 00907: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0047 - val_loss: 26.1326\n",
            "Epoch 908/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0045\n",
            "Epoch 00908: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0045 - val_loss: 26.1530\n",
            "Epoch 909/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0045\n",
            "Epoch 00909: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0045 - val_loss: 26.1719\n",
            "Epoch 910/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0045\n",
            "Epoch 00910: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0045 - val_loss: 26.1768\n",
            "Epoch 911/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0045\n",
            "Epoch 00911: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0045 - val_loss: 26.1740\n",
            "Epoch 912/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00912: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.1826\n",
            "Epoch 913/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00913: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.1999\n",
            "Epoch 914/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00914: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.2034\n",
            "Epoch 915/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00915: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.1879\n",
            "Epoch 916/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00916: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.1958\n",
            "Epoch 917/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00917: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.1915\n",
            "Epoch 918/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0042\n",
            "Epoch 00918: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0042 - val_loss: 26.1999\n",
            "Epoch 919/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00919: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.2139\n",
            "Epoch 920/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0046\n",
            "Epoch 00920: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0046 - val_loss: 26.2486\n",
            "Epoch 921/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 00921: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0043 - val_loss: 26.2810\n",
            "Epoch 922/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 00922: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0044 - val_loss: 26.2872\n",
            "Epoch 923/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 00923: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0043 - val_loss: 26.2861\n",
            "Epoch 924/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 00924: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0043 - val_loss: 26.3004\n",
            "Epoch 925/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 00925: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0043 - val_loss: 26.2871\n",
            "Epoch 926/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0042\n",
            "Epoch 00926: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0042 - val_loss: 26.2956\n",
            "Epoch 927/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0042\n",
            "Epoch 00927: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0042 - val_loss: 26.3388\n",
            "Epoch 928/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0041\n",
            "Epoch 00928: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0041 - val_loss: 26.3493\n",
            "Epoch 929/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0046\n",
            "Epoch 00929: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0046 - val_loss: 26.3104\n",
            "Epoch 930/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0041\n",
            "Epoch 00930: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0041 - val_loss: 26.2667\n",
            "Epoch 931/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 00931: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0043 - val_loss: 26.2625\n",
            "Epoch 932/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0042\n",
            "Epoch 00932: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0042 - val_loss: 26.3085\n",
            "Epoch 933/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0042\n",
            "Epoch 00933: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0042 - val_loss: 26.3813\n",
            "Epoch 934/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0042\n",
            "Epoch 00934: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0042 - val_loss: 26.4327\n",
            "Epoch 935/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0041\n",
            "Epoch 00935: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0041 - val_loss: 26.4247\n",
            "Epoch 936/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0040\n",
            "Epoch 00936: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0040 - val_loss: 26.4519\n",
            "Epoch 937/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0040\n",
            "Epoch 00937: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0040 - val_loss: 26.4676\n",
            "Epoch 938/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0040\n",
            "Epoch 00938: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0040 - val_loss: 26.5055\n",
            "Epoch 939/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0040\n",
            "Epoch 00939: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0040 - val_loss: 26.5085\n",
            "Epoch 940/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0040\n",
            "Epoch 00940: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0040 - val_loss: 26.5063\n",
            "Epoch 941/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0040\n",
            "Epoch 00941: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0040 - val_loss: 26.5262\n",
            "Epoch 942/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0040\n",
            "Epoch 00942: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0040 - val_loss: 26.5731\n",
            "Epoch 943/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0040\n",
            "Epoch 00943: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0040 - val_loss: 26.5612\n",
            "Epoch 944/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0039\n",
            "Epoch 00944: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0039 - val_loss: 26.5501\n",
            "Epoch 945/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0039\n",
            "Epoch 00945: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0039 - val_loss: 26.5430\n",
            "Epoch 946/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0038\n",
            "Epoch 00946: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0038 - val_loss: 26.5364\n",
            "Epoch 947/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0038\n",
            "Epoch 00947: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0038 - val_loss: 26.5389\n",
            "Epoch 948/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0039\n",
            "Epoch 00948: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0039 - val_loss: 26.5647\n",
            "Epoch 949/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0038\n",
            "Epoch 00949: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0038 - val_loss: 26.5740\n",
            "Epoch 950/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0038\n",
            "Epoch 00950: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0038 - val_loss: 26.5573\n",
            "Epoch 951/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0037\n",
            "Epoch 00951: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0037 - val_loss: 26.5341\n",
            "Epoch 952/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0036\n",
            "Epoch 00952: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0036 - val_loss: 26.5588\n",
            "Epoch 953/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0038\n",
            "Epoch 00953: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0038 - val_loss: 26.5711\n",
            "Epoch 954/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0037\n",
            "Epoch 00954: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0037 - val_loss: 26.5701\n",
            "Epoch 955/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0036\n",
            "Epoch 00955: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0036 - val_loss: 26.5655\n",
            "Epoch 956/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0037\n",
            "Epoch 00956: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0037 - val_loss: 26.5817\n",
            "Epoch 957/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0037\n",
            "Epoch 00957: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0037 - val_loss: 26.5868\n",
            "Epoch 958/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0037\n",
            "Epoch 00958: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0037 - val_loss: 26.5874\n",
            "Epoch 959/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0040\n",
            "Epoch 00959: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0040 - val_loss: 26.6001\n",
            "Epoch 960/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0038\n",
            "Epoch 00960: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0038 - val_loss: 26.6518\n",
            "Epoch 961/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0040\n",
            "Epoch 00961: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0040 - val_loss: 26.6475\n",
            "Epoch 962/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0038\n",
            "Epoch 00962: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0038 - val_loss: 26.6163\n",
            "Epoch 963/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0037\n",
            "Epoch 00963: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0037 - val_loss: 26.6070\n",
            "Epoch 964/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0038\n",
            "Epoch 00964: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0038 - val_loss: 26.6393\n",
            "Epoch 965/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0037\n",
            "Epoch 00965: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0037 - val_loss: 26.6520\n",
            "Epoch 966/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0036\n",
            "Epoch 00966: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0036 - val_loss: 26.6567\n",
            "Epoch 967/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0036\n",
            "Epoch 00967: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0036 - val_loss: 26.6706\n",
            "Epoch 968/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0037\n",
            "Epoch 00968: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0037 - val_loss: 26.7130\n",
            "Epoch 969/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0035\n",
            "Epoch 00969: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0035 - val_loss: 26.7442\n",
            "Epoch 970/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0037\n",
            "Epoch 00970: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0037 - val_loss: 26.7486\n",
            "Epoch 971/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0035\n",
            "Epoch 00971: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0035 - val_loss: 26.7477\n",
            "Epoch 972/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0037\n",
            "Epoch 00972: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0037 - val_loss: 26.7625\n",
            "Epoch 973/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0035\n",
            "Epoch 00973: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0035 - val_loss: 26.8200\n",
            "Epoch 974/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0039\n",
            "Epoch 00974: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0039 - val_loss: 26.8151\n",
            "Epoch 975/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0036\n",
            "Epoch 00975: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0036 - val_loss: 26.7945\n",
            "Epoch 976/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0035\n",
            "Epoch 00976: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0035 - val_loss: 26.7734\n",
            "Epoch 977/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0036\n",
            "Epoch 00977: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0036 - val_loss: 26.7670\n",
            "Epoch 978/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0034\n",
            "Epoch 00978: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0034 - val_loss: 26.8331\n",
            "Epoch 979/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0036\n",
            "Epoch 00979: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0036 - val_loss: 26.8577\n",
            "Epoch 980/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0035\n",
            "Epoch 00980: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0035 - val_loss: 26.8754\n",
            "Epoch 981/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0034\n",
            "Epoch 00981: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0034 - val_loss: 26.8739\n",
            "Epoch 982/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0034\n",
            "Epoch 00982: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0034 - val_loss: 26.8961\n",
            "Epoch 983/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0034\n",
            "Epoch 00983: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0034 - val_loss: 26.9274\n",
            "Epoch 984/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0034\n",
            "Epoch 00984: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0034 - val_loss: 26.9292\n",
            "Epoch 985/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0033\n",
            "Epoch 00985: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0033 - val_loss: 26.9282\n",
            "Epoch 986/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0033\n",
            "Epoch 00986: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0033 - val_loss: 26.9316\n",
            "Epoch 987/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0033\n",
            "Epoch 00987: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0033 - val_loss: 26.9469\n",
            "Epoch 988/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0033\n",
            "Epoch 00988: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0033 - val_loss: 26.9712\n",
            "Epoch 989/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0033\n",
            "Epoch 00989: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0033 - val_loss: 26.9791\n",
            "Epoch 990/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0033\n",
            "Epoch 00990: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0033 - val_loss: 26.9679\n",
            "Epoch 991/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0034\n",
            "Epoch 00991: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0034 - val_loss: 26.9467\n",
            "Epoch 992/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0033\n",
            "Epoch 00992: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0033 - val_loss: 26.9759\n",
            "Epoch 993/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0032\n",
            "Epoch 00993: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0032 - val_loss: 26.9795\n",
            "Epoch 994/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0033\n",
            "Epoch 00994: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0033 - val_loss: 26.9829\n",
            "Epoch 995/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0032\n",
            "Epoch 00995: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0032 - val_loss: 26.9996\n",
            "Epoch 996/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0034\n",
            "Epoch 00996: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0034 - val_loss: 26.9981\n",
            "Epoch 997/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0032\n",
            "Epoch 00997: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0032 - val_loss: 27.0110\n",
            "Epoch 998/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0033\n",
            "Epoch 00998: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0033 - val_loss: 26.9958\n",
            "Epoch 999/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0032\n",
            "Epoch 00999: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0032 - val_loss: 27.0067\n",
            "Epoch 1000/1000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0033\n",
            "Epoch 01000: val_loss did not improve from 21.03862\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.0033 - val_loss: 27.0349\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH4bfN63KFZe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e81f249-1a6d-4a9d-aa97-af3fdbf5ac7e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'loss': [107.21981048583984, 106.8874740600586], 'val_loss': [107.4009780883789, 108.79151916503906]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3ZSB4Tvtff8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d221f3a7-119a-4fd7-93dd-96dd63ab2a0b"
      },
      "source": [
        "\n",
        "\n",
        "# load the saved best model weights\n",
        "act_model.load_weights(filepath)\n",
        "\n",
        "# predict outputs on validation images\n",
        "prediction = act_model.predict(valid_img)\n",
        "\n",
        "# use CTC decoder\n",
        "out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
        "                               greedy=True)[0][0])\n",
        "\n",
        "# see the results\n",
        "i = 0\n",
        "for x in out:\n",
        "    print(\"original_text =  \", valid_orig_txt[i])\n",
        "    print(\"predicted text = \", end='')\n",
        "    for p in x:\n",
        "        if int(p) != -1:\n",
        "            print(char_list[int(p)], end='')\n",
        "    print('\\n')\n",
        "    i += 1"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "original_text =   ลดความเหนื่อยล้าด้วย\n",
            "predicted text = สรควานเนือยล้าลวย\n",
            "\n",
            "original_text =   มีพระบรมราชโองการ ในพระบาทสมเด็จ\n",
            "predicted text = มีเรรหามศาฬโองกาง ไเระบสมเตี่ง\n",
            "\n",
            "original_text =   หัวใจสีดำ\n",
            "predicted text = หัวใจสีดำ\n",
            "\n",
            "original_text =   เวลานั้น ไม่มีใครรู้ว่า  ไอ้ด่าง  กินคนไปกี่คนแล้ว\n",
            "predicted text = เวลานั้น ไม่มีใครร้ว่า  ไอ้ด่าง  ก็ินคนไปที่คนแล้ว\n",
            "\n",
            "original_text =   ขออนุญาตลูกค้าที่มาทานแล้วนะ\n",
            "predicted text = ขออนุูญาตลูกค้าที่มาทานแล้วนะ\n",
            "\n",
            "original_text =   10 นาทีผ่านไป จากเสียงปืนที่ดังเป็นระยะ..เริ่มเงียบ\n",
            "predicted text = 10 นาทีผ่านไป จากเสียงปืนที่ตด้งเป็นระย..เรืมเงียบ\n",
            "\n",
            "original_text =   ไม่อาจ\n",
            "predicted text = ไม่อาจ\n",
            "\n",
            "original_text =   ยอมรับว่าการปิดถนนปล้นครั้งนี้\n",
            "predicted text = ยอมรับว่าการปิดถนนปล้นครั้งนี้\n",
            "\n",
            "original_text =   ฉายา\n",
            "predicted text = E\n",
            "\n",
            "original_text =   ผู้กว่้างขวางคนดัง\n",
            "predicted text = ผู้ กว้างขวางคนดัง\n",
            "\n",
            "original_text =   แต่นายวิโรจน์ได้เสียชีวิตก่อนคดีจะจบ\n",
            "predicted text = แต่นายวิโรจน์ได้เสียชีวิตก่อนคตีงะจบ\n",
            "\n",
            "original_text =   จ.พระนครศรีอยุธยา\n",
            "predicted text = จ พระนครศรือยุธยา\n",
            "\n",
            "original_text =   ให้ได้รับความคุ้มครอง การปฏบัติที่เหมาะสม\n",
            "predicted text = ให้ได้รับความคุ้มครอง การปฏบัติที่เหมาะสม\n",
            "\n",
            "original_text =   ติดเชื้อ 1,320 ราย\n",
            "predicted text = ผู้ติดเชื้อ 1 320 ราย\n",
            "\n",
            "original_text =   แดน๑๐\n",
            "predicted text = Sธอ\n",
            "\n",
            "original_text =   หนังสือพิมพ์สมัยนั้น ได้ลงเรื่องราวของ\n",
            "predicted text = หนังสือพิมพ์สมัยนั้น ได้ลงเรื่องราวของ\n",
            "\n",
            "original_text =   แผนโหด วิธีเหี้ยม\n",
            "predicted text = ผนโหด วิธีเหี้ยม\n",
            "\n",
            "original_text =   เมื่อก่อนท่านเคยเล่าว่าเคยเป็นถ้ำพระปัจเจก\n",
            "predicted text = เมื่อก่อนก่านเคยเล่าว่าเคยเป็นด้ำพระปัจเงก\n",
            "\n",
            "original_text =   กรุณาโปรดเกล้า ฯ ให้กรมสาธารณสุขจัดส่งแพทย์ ส่งยาและคำ\n",
            "predicted text = กณไปรคศล่า  ไห้กวมสางรณสุาวัเส่ยแหพน้ ส่ยาและ่ำ\n",
            "\n",
            "original_text =   มันดูธรรมดามากเลยอะ แต่ว่า มันละลายในปากไปเลยอะ\n",
            "predicted text = มันดูรรรมดามากเลยอะแต่วามันละลายในปากไปลยอะ\n",
            "\n",
            "original_text =   รวม 70 ล้าน\n",
            "predicted text = รวม70 ล้าน\n",
            "\n",
            "original_text =   ปล้นและฆ่าเจ้าทรัพย์ร้านทอง,ฯลฯ\n",
            "predicted text = คทนนนเรน\n",
            "\n",
            "original_text =   คือ ร้านแรกอะปิดเร็วที่สุด แล้วก็มาร้านนี้\n",
            "predicted text = คือ ร้านแรกอะปิดเร็วที่สุด แล้วก็มาร้านนี้\n",
            "\n",
            "original_text =   เขาถึงตัดสินใจกระโดดออกมา ไม่หนีก็ตาย\n",
            "predicted text = เขาถึงตัดสินใจกระโดดออกมา ไม่หนีก็ตาย\n",
            "\n",
            "original_text =   สุเทพโชว์คอนเสิร์ต\n",
            "predicted text = สุเทพโชว์คอนเสิร์ต\n",
            "\n",
            "original_text =   หลังต้องทนทรมานนาน 1 สัปดาห์\n",
            "predicted text = หลังต้องทนทรมานนาน 1 สัปดาห์\n",
            "\n",
            "original_text =   แต่วันนี้หลังโควิด เหมือน เหมือน ไม่ต้องจอง\n",
            "predicted text = แด่วันนี้หลังโควิด เหมือนเหมือนไม่ต้องจอง\n",
            "\n",
            "original_text =   แล้วคุณล่ะ คิดว่ามันเคยมีอยู่จริงหรือไม่\n",
            "predicted text = แล้วคุณล่ะ คิดว่ามันเคยมีอยู่จริงหรือไม่\n",
            "\n",
            "original_text =   ปัจจุบัน ครูบาบุญชุ่ม ได้เข้าปฏิบัติธรรม\n",
            "predicted text = ปจจุบัน ครูบาบุญชุ่ม ได้เข้าปฏบัติธรรม\n",
            "\n",
            "original_text =   กลัวข้าวไม่พอ\n",
            "predicted text = กลัานขั้าวไม่พอ\n",
            "\n",
            "original_text =   3.การจารกรรมจาก CIA\n",
            "predicted text = 3.การจาระกรรมจาก CIA\n",
            "\n",
            "original_text =   การพาคนไปเที่ยว!\n",
            "predicted text = การพาคนไปเที่ยว!\n",
            "\n",
            "original_text =   ผู้ติดเชื้อ 581 ราย\n",
            "predicted text = ผู้ติดเชื้อ 531 ราย\n",
            "\n",
            "original_text =   จีน ไทย เกาหลีใต้ ญี่ปุ่น ไต้หวัน ฮ่องกง มาเก๊า อเมริกา เวียดนาม สิงคโปร์\n",
            "predicted text = จ ทนย เกาหลีใ้อญีปุน ไตพวัน ฮ่องกง มเก๊า อเมริกา วียดนาม สิงคโปร์\n",
            "\n",
            "original_text =   นี่ตำรวจ..เจ้าหน้าที่แสดงตัว\n",
            "predicted text = นี่ต่ำรวจ..เจ้าหน้าที่แสดงตัว\n",
            "\n",
            "original_text =   เรือนจำกลางบางขวาง\n",
            "predicted text = รืรนร์งรชมรรง\n",
            "\n",
            "original_text =   ผู้เชี่ยวชาญทั้งคู่สันนิษฐานว่า กัปตันหันหัวกลับที่ปีนัง\n",
            "predicted text = ผู้เชี่ยวชาญทั้งคู่สันนิรฐานว่า กัปตันหันหัวกลับที่ปีนัง\n",
            "\n",
            "original_text =   ที่รัก\n",
            "predicted text = ีรั\n",
            "\n",
            "original_text =   คดีดัง\n",
            "predicted text = คดีดัง\n",
            "\n",
            "original_text =   1 ในผู้บาดเจ็บสาหัส คือ เสี่ยแหย สมชัย ฤกษ์วรารักษ์\n",
            "predicted text = 1ในผู้บาดเจ็บสาหัส คือ  เสี่ยแหย  สมชัย ฤก์วรารัก์\n",
            "\n",
            "original_text =   ใครจะแพ้\n",
            "predicted text = ใครจะแพ้\n",
            "\n",
            "original_text =   ส่วนตัว ยังไม่ปฏิบัติเยอะ ท่านว่านะ\n",
            "predicted text = ส่วนตัว ยังไม่ปฏิบัติเยอะท่านว่านะ\n",
            "\n",
            "original_text =   ยังติดสินว่าเขาโง่ด้วยเกรด\n",
            "predicted text = ยังต้ดสินวาเขาโงด้วยเกรด\n",
            "\n",
            "original_text =   ซึ่งถือเป็นการปฏิบัติการค้นหาเครื่องบินที่สูญหาย\n",
            "predicted text = ซึ่งถือเป็ปฏิบัติการการค้นหาเครื่องบินที่สุญหาย\n",
            "\n",
            "original_text =   ยอมรับว่าการปิดถนนปล้นครั้งนี้\n",
            "predicted text = ยอมรับว่าการปิดถนนปล้นครั้งนี้\n",
            "\n",
            "original_text =   มองไกลๆ จะเสียวๆ นิดหนึ่งเหมือนเป็นเสืออยู่\n",
            "predicted text = มองไกลๆ จะเสียวๆ นิดหนึ่งเหมือนเป็นเสืออยู่\n",
            "\n",
            "original_text =   เรือจากจีน\n",
            "predicted text = เรือจารจน\n",
            "\n",
            "original_text =   โอ้โหด เกลี้ยง\n",
            "predicted text = โอ้โหเกสี้ยง\n",
            "\n",
            "original_text =   แกคือแบบ ถ้าร้านไม่ดังจริงนะคะ\n",
            "predicted text = แกคือแบบ ถ้าร้านไม่ดังจริงนะคะ\n",
            "\n",
            "original_text =   หากเธอจากไป ก็คงไม่ ถึงตาย\n",
            "predicted text = ตาาเธอจาคไป ก็คงไม่ ถึงตาย\n",
            "\n",
            "original_text =   เช่น\n",
            "predicted text = ัน\n",
            "\n",
            "original_text =   ติดเชื้อ\n",
            "predicted text = ธิดเเร้อ\n",
            "\n",
            "original_text =   มันจะเค็มขึ้นมาอีกระดับนึง\n",
            "predicted text = มันจะเค็มขึ้นมาอีกระดับนึง\n",
            "\n",
            "original_text =   ครั้งหนึ่งสุเทพเคยให้สัมภาษณ์เรื่องราวในชีวิต\n",
            "predicted text = ครั้งหนึ่งสุเกพเคยให้สัมภาษณ์เรื่องราวในชีวิต\n",
            "\n",
            "original_text =   เป็นต้นเหตุของเพลิงไหม้\n",
            "predicted text = เป็นต้นเหตุของเพลิงไหม้\n",
            "\n",
            "original_text =   ความนุ่มนวล\n",
            "predicted text = ความบนุ่มนรวล\n",
            "\n",
            "original_text =   31 ธ.ค. 2019 จีนรายงาน WHO\n",
            "predicted text = 31 ธ.ค 2019 จีนรายงาน WH0\n",
            "\n",
            "original_text =   ก็ราวๆนี้แหละครับ\n",
            "predicted text = ก็ราวๆ นี้แหละครับ\n",
            "\n",
            "original_text =   ไข้หวัดสเปนระบาด\n",
            "predicted text = ไช้หวัดสเปนรนาด\n",
            "\n",
            "original_text =   ดำเนินคดีกับบริษัทของ น ส พสิษฐ์ หรือ ซินแสโชกุน\n",
            "predicted text = ถำเนินคดีกับบริษักของ น ส. พสินฐ์ หรือ ซินแสโชกุน\n",
            "\n",
            "original_text =   มีสปอนเซอร์ด้วย\n",
            "predicted text = มีสปอนเชอร์ด้วย\n",
            "\n",
            "original_text =   อาจจะกลับมาระบาดอีกครั้ง!\n",
            "predicted text = อาจกลับมาระบาดอีกครั้ง!\n",
            "\n",
            "original_text =   เกิดอะไรขึ้นกับ\n",
            "predicted text = เกิดอะไรยึ้นกัน\n",
            "\n",
            "original_text =   พวกเขาถูก ลอยแพ\n",
            "predicted text = พวกเขาฤุก ลอยuพ\n",
            "\n",
            "original_text =   1  ปมการเมืองระดับประเทศ แข่งขันกันดุเดือด\n",
            "predicted text = 1 ปมการเมืองระดับประเทศ เซข่งยันกันดูเดือด\n",
            "\n",
            "original_text =   โรตีจริงๆเป็นชื่อย่อ\n",
            "predicted text = โรตีจริงๆ เป็นชื่อย่อ\n",
            "\n",
            "original_text =   ทุกอย่าง\n",
            "predicted text = ุกอย่าง\n",
            "\n",
            "original_text =   แต่กลับไม่มีบัตรสมาชิกอะไรให้เลย\n",
            "predicted text = แต่กลับไม่มีบัตรสมาชิกอะไรให้เลย\n",
            "\n",
            "original_text =   และมารู้ทีหลังว่า\n",
            "predicted text = และมารู้ทีหลังวา\n",
            "\n",
            "original_text =   พแนกศุขาภิบาล\n",
            "predicted text = พแนกศู มดิบล\n",
            "\n",
            "original_text =   ย้อนกลับไปเมื่อเดือนสิงหาคมปี 2540\n",
            "predicted text = ย้อนกลับไปเมื่อเดือนสิงหาคมปี 2540\n",
            "\n",
            "original_text =   จะให้ส่วนลด 1,000 บาท\n",
            "predicted text = จะให้ส่วนลด 1,000 บาท\n",
            "\n",
            "original_text =   ยอมรับว่าการปิดถนนปล้นครั้งนี้\n",
            "predicted text = ยอมรับว่าการปิดถนนปล้นครั้งี้\n",
            "\n",
            "original_text =   23 พ.ย. ปีเดียวกัน  กมล เสมอเหมือน  อดีต ส ส อ่างทอง\n",
            "predicted text = 23 พย. ีเดียวกัน  ามล เสมอเหมือน  อดีต สส อ่างทอง\n",
            "\n",
            "original_text =   ในชุดนักศึกษา ท่อนล่างเปลือยเปล่า\n",
            "predicted text = ในซุดนักศึกษา ท่อนล่างเปลือยเปล่า\n",
            "\n",
            "original_text =   MEMORY FOAM\n",
            "predicted text = MEMORY AE\n",
            "\n",
            "original_text =   โคตรจระเข้\n",
            "predicted text = คตรจระเข้\n",
            "\n",
            "original_text =   คือหมด เค้าก็ไม่ขาย\n",
            "predicted text = คือหมด เค้จก็ไม่ขาย\n",
            "\n",
            "original_text =   Synda\n",
            "predicted text = S\n",
            "\n",
            "original_text =   ใช้ สมอง แค่นั้น\n",
            "predicted text = ใ้ สมอง   .ค่น้น\n",
            "\n",
            "original_text =   มุมดี ๆ ที่ไม่ควรพลาด\n",
            "predicted text = มูมิ  ไีมคอธเลาดิ\n",
            "\n",
            "original_text =   เรียกคืนสติกลับมา\n",
            "predicted text = รียกคืนสติกลับมา\n",
            "\n",
            "original_text =   ส้อมฉีกดิ๊ๆ\n",
            "predicted text = ล้อมีกดิ้๊\n",
            "\n",
            "original_text =   จากนั้นมีชายคนหนึ่งลงจากรถ\n",
            "predicted text = จากนั้นมีชายคนหนึ่งลงจากรถ\n",
            "\n",
            "original_text =   แต่เราเป็นคนชอบไขมัน\n",
            "predicted text = แต่เราเป็นคนชอบไขมัน\n",
            "\n",
            "original_text =   เจ้าของฉายา  โกโบริน  โดยเขาเขียนเรื่องราวทั้งหมดไว้\n",
            "predicted text = ค้าของจายา  โกโบริน  โดยเขาเขียนเรื่องราวทั้งหมดไว้\n",
            "\n",
            "original_text =   23 มิถุนายน 2561 ไม่มีใครคาดคิดว่า\n",
            "predicted text = 23 มิถนายน 2561 ไม่มีใครคาดคิดว่า\n",
            "\n",
            "original_text =   ญาติผู้ตายถึงกับบุกไปกระโดดถีบไอ้เป๋\n",
            "predicted text = ญาติผู้ตายถึงกับบุกไปกระโดดดีบไอ้เป๋\n",
            "\n",
            "original_text =   ดูจากพฤติการณ์แล้ว\n",
            "predicted text = ดูจากพฤติการณ์แล้ว\n",
            "\n",
            "original_text =   และมันกลับมาอีกครั้ง...ในเดือนตุลาคม 2507\n",
            "predicted text = และมันกลับมาอีกครั้ง. . ในเดือนตลาคม 2507\n",
            "\n",
            "original_text =   และค่าตอบแทนที่จำเป็นและสมควรจากรัฐ\n",
            "predicted text = และค่าตอบแทนที่จำเป็นและสมควรจากรัฐ\n",
            "\n",
            "original_text =   ก่อนวันที่มันจะสายไป\n",
            "predicted text = ัอ.รแคัน  มขไป\n",
            "\n",
            "original_text =   26\n",
            "predicted text = 23\n",
            "\n",
            "original_text =   InFRARED\n",
            "predicted text = 30\n",
            "\n",
            "original_text =   สั่งปรับบริษัท เวลท์เอเวอร์ จำกัด\n",
            "predicted text = สั่งปรับบริษัท เวลท์เอเวอร์ จำกัด\n",
            "\n",
            "original_text =   ไม่มีอนาคตเพราะเลขบนห้อง\n",
            "predicted text = ไม่มือนาคตเพฟราะเลขบนห้อง \n",
            "\n",
            "original_text =   นี่ๆๆ อยู่นี่นะๆ เผื่อใครไม่เห็น\n",
            "predicted text = นี่ง์าฮยู่นี่นะ เผื่อใครไม่เห็น\n",
            "\n",
            "original_text =   2563\n",
            "predicted text = 2563\n",
            "\n",
            "original_text =   คดีดัง\n",
            "predicted text = ค้ง\n",
            "\n",
            "original_text =   จากการสอบสวนทราบว่า ได้มีกลุ่มคนติดต่อ วางแผน\n",
            "predicted text = จากกรสอบสวนทรานว่า ได้มีกลุ่มคนติดต่อ วางแผน\n",
            "\n",
            "original_text =   InFRARED\n",
            "predicted text = IคA3\n",
            "\n",
            "original_text =   แพทย์สามารถตรวจเรือได้ทุกลำ\n",
            "predicted text = เหขรหร่สอามารรัรรยวงริอปต้ยุกลำ\n",
            "\n",
            "original_text =   ในนิตยสารการท่องเที่ยว อ.ส.ท.\n",
            "predicted text = ในนิตยสารการท่องเที่ยว อ.ส.ท.\n",
            "\n",
            "original_text =   ประธานหอการค้าจังหวัดอ่างทองและเป็นผู้กว้างขวางในวงการค้าไม้\n",
            "predicted text = โระสานหอการด้าจังหวัดอ่างทองและป็นผู้กว้างขวางในวงการด้าข้\n",
            "\n",
            "original_text =   เขตร์ท้องที่อำเภอนางเลิ้งชั่วคราว เพราะฉนั้น การปลูกป้องกันไข้ทรพิษ\n",
            "predicted text = หคนทองที่อ็เภอน.ลิ รข้่งวาว พรรวนี้ กรปคาปัองกันไ้รขน\n",
            "\n",
            "original_text =   คนร้ายไม่ต่ำกว่า 6 คน ถล่มด้วยอาวุธวงครามนานาชนิด\n",
            "predicted text = คนร้ายไม่ต่ากว่า 6 คน ถล่มด้วยอาวุธสงครามนานาชปิด\n",
            "\n",
            "original_text =   เห็นมั้ย ซุปอร่อย\n",
            "predicted text = เห็นมั้ย ซูปอร่อย\n",
            "\n",
            "original_text =   24 ก.ค.31 เสี่ยแหยถูกลอบฆ่าอีกครั้งด้วยระเยิดเครย์มอร์\n",
            "predicted text = 24 ก.ค. 31 เสียแหยถูกลอบฆ่าอีกครั้งด้วยระเบิดเคลย์มอร์\n",
            "\n",
            "original_text =   พร้อมอาวุธครบมือ ไปขอรับตัว นช. ระทม ที่กองปราบปราม\n",
            "predicted text = พร้อมอาวุธครบมือ ไปขอรับตัว นช ระทม ที่กองปราบปราม\n",
            "\n",
            "original_text =   ดูจากพฤติการณ์แล้ว\n",
            "predicted text = ดูจากพฤติการณ์แล้ว\n",
            "\n",
            "original_text =   ขอบคุณภาพ\n",
            "predicted text = ขอบคุณภาพ\n",
            "\n",
            "original_text =   ขับรถปิกอัพสีเทาดำมาวนเวียนหน้าศาล\n",
            "predicted text = ขับรถปิกอัพสี่เทาดำมาวนเวียนหน้าศาล\n",
            "\n",
            "original_text =   รหัสเรียกขาน นคร45 มูลนิธิร่วมกตัญญู\n",
            "predicted text = รหัสเรียกขานนคร5 มูลนิธิร่วมกตัญญ\n",
            "\n",
            "original_text =   เชื้อกาฬโรค สมัย ร.5\n",
            "predicted text = เชื้อกาฬโรค สมัย ร.5\n",
            "\n",
            "original_text =   ภาพที่เห็นตอนแรกคือ ช็อกเลย\n",
            "predicted text = กาพที่เห็นตอนแรศคือ ช์อกเลย\n",
            "\n",
            "original_text =   อุปกรณ์บางอย่าง เลื่อยลูกกรงหนา 4 หุนจนสามารถง้างได้\n",
            "predicted text = โดยมีพยานได้ยินเสียงง้างเหล็กราวตี 3 คาดว่าได้ตรียน\n",
            "\n",
            "original_text =   บ้านคอลงเดื่อ น้ำตกเหวนรก คลองหนองแก้ว\n",
            "predicted text = บ้านคลองเดื่อ น้ำตกเหวนรก คลองหนองแก้ว\n",
            "\n",
            "original_text =   คุณลุงอยากให้พีชอีทแหลกมากินปะครับ\n",
            "predicted text = คุณลุงอยาทให้พีชอีทแหลกมากินปะครับ\n",
            "\n",
            "original_text =   จีน ไทย เกาหลีใต้ ญี่ปุ่น ไต้หวัน ฮ่องกง มาเก๊า อเมริกา\n",
            "predicted text = จีน มทย เัาหลีใต้ ญปุัน ไต้หวัน ฮมองกงา   เกท๊า ฮเพรา\n",
            "\n",
            "original_text =   อาจจะตายบนเครื่องบินไปก่อนหน้านั้นแล้ว\n",
            "predicted text = อางจะตายบมเครื่องไปกือบน้าบินเล้อ\n",
            "\n",
            "original_text =   เพราะคนที่รักมากคนหนึ่ง..แต่งงานกับคนอื่น\n",
            "predicted text = เพราะคนที่รักมากคนหนึ่ง. แต่งงานกับคนอื่น\n",
            "\n",
            "original_text =   กว่า 221 ชั่วโมงคนไทยและชาวโลก ต่างเอาใจช่วย\n",
            "predicted text = กว่า 22 ชั่วโมงคนไทยและชาวโลก ต่างเองใจช่วย\n",
            "\n",
            "original_text =   เสียชีวิตอย่างสงบภายในบ้านพัก\n",
            "predicted text = เสียชีวิตอย่างสงบภายในบ้านพัก\n",
            "\n",
            "original_text =   ใครจะคิดว่า  คุกที่แข็งแกร่งที่สุดในประเทศ  จะถูก  นช ระทม\n",
            "predicted text = ใครจะคิดว่า  จูกที่เ์็งเกร่งทีสุดในประเศ จะูก นซระาม\n",
            "\n",
            "original_text =   ใช่\n",
            "predicted text = น้ำ่\n",
            "\n",
            "original_text =   ประกาศมาณวันที่ ๒๔ ตุลาคม พระพุทธศักราช ๒๔๖๑\n",
            "predicted text = ประาหนรณวันที หส ศุลเคน พพะเูตรศักร ๒ฟ..\n",
            "\n",
            "original_text =   ด้านสุขภาพโดยเฉพาะเลยค่ะ\n",
            "predicted text = ด้านสุขภาพโดยเฉพาะเลยค่ะ\n",
            "\n",
            "original_text =   ร้อย เรื่องราว\n",
            "predicted text = ร้อย เรื่อบราว\n",
            "\n",
            "original_text =   แต่ซุปร้านเนี้ย มันกินกับข้าว แล้วมันอร่อย\n",
            "predicted text = แต่ซุปร้านเนี้ย มันกินกัข้าว แล้วมันอร่อย\n",
            "\n",
            "original_text =   น้ำดื่มบริการ\n",
            "predicted text = ำดื่งบริร\n",
            "\n",
            "original_text =   เต้ามีพลังงานอินฟราเรดค่ะ\n",
            "predicted text = เค้ามีพลังงานอินฟราเรดค่ะ\n",
            "\n",
            "original_text =   หากมีการไฮแจ็คโดยบุคคลอื่น\n",
            "predicted text = หากมีการไฮแจ็คโดยบุคคลอื่น\n",
            "\n",
            "original_text =   มีอีกร้านนึง\n",
            "predicted text = มีอีกร้านนึง\n",
            "\n",
            "original_text =   โดยสวมบทเป็นพลเมืองดีแกล้งโทรเข้ามาที่\n",
            "predicted text = โดยสวมบกเป็นพลเมืองดีเกล้งโทรเข้ามาี่\n",
            "\n",
            "original_text =   ดูจากพฤติการณ์แล้ว\n",
            "predicted text = ดูจากพฤติการณ์แล้ว\n",
            "\n",
            "original_text =   พงศธร กิจเวช\n",
            "predicted text = พงศิธร กิจเวช\n",
            "\n",
            "original_text =   หรือ รักแร้โต\n",
            "predicted text = หรือ ริ้กเร้โต\n",
            "\n",
            "original_text =   ตอนนั้นสมพงษ์อ้างว่าเก็บเงินและทรัพย์สินได้มากมาย\n",
            "predicted text = ตอนนั้นสมพงษ้อ้างว่าเก็บเงินและรัพยสินได้มากบาย\n",
            "\n",
            "original_text =   คืนกลับ\n",
            "predicted text = คืนลลับ\n",
            "\n",
            "original_text =   ไม่เคยเกิดขึ้นมาก่อน\n",
            "predicted text = ไม่เคยเกิดขึ้นมาถ่อน.\n",
            "\n",
            "original_text =   ความหนาแน่นสูงมาก\n",
            "predicted text = ชะะว\n",
            "\n",
            "original_text =   ดูจากพฤติการณ์แล้ว\n",
            "predicted text = ดูจากพถติถารณ์แล้ว\n",
            "\n",
            "original_text =   อ้าว พี่คะ ปิดแล้วหรอ\n",
            "predicted text = อ้าว พี่คะปิดแล้วหรอ\n",
            "\n",
            "original_text =   โดยมีทีมระเบิด 2 คน และกลุ่มคนที่วางแผน\n",
            "predicted text = โดยมีทีมระเบิด 2 คน และกลุ่มคนที่วางแผน\n",
            "\n",
            "original_text =   เมื่อไปตรวจสอบจึงได้รู้ว่า\n",
            "predicted text = เมื่อไปตรวจสอบจึงได้รู้ว่า\n",
            "\n",
            "original_text =   29 มกราคม มีผู้เสียชีวิต 131 ราย\n",
            "predicted text = 29 มกราคม มีผู้เสียชีวิต 131 ราย\n",
            "\n",
            "original_text =   ผู้ต้องสงสัย คือชายที่มีเนื้องอกบริเวณหน้าอก ที่เท้าอาจจะพิการ\n",
            "predicted text = ผู้องสงสัย คือชายที่ีเนืองอกนริเวณหน้าอก ที่ท้อาจจะพิการ\n",
            "\n",
            "original_text =   ที่จริงแล้ว\n",
            "predicted text = ที่จรงนรู้\n",
            "\n",
            "original_text =   ที่ผ่านมา\n",
            "predicted text = ทีพ่านมา\n",
            "\n",
            "original_text =   โดยมีชื่ออย่างเป็นทางการว่า 2019-nCoV\n",
            "predicted text = โดยมีชื่ออย่างเป็นทางการวา 2019 -nC61.\n",
            "\n",
            "original_text =   จากนั้นได้ขับหลบหนี\n",
            "predicted text = จากนั้นได้ขับหลบหนี\n",
            "\n",
            "original_text =   อย่าปล่อยให้มันเงียบงัน\n",
            "predicted text = อย่าปล่อยมันให้เงียบงัน\n",
            "\n",
            "original_text =   ต่อมาตำรวจขยายผล สั่งอายัดเงินและทรัพย์สินอื่นๆ\n",
            "predicted text = ต่อมา ตำรวจขยายผล ส่งอายัดเงินและกรัพย์สินอื่นๆ\n",
            "\n",
            "original_text =   ข้อมูลจากหนังสือ\n",
            "predicted text = ข้อมูลจากหนังสือ\n",
            "\n",
            "original_text =   แต่ก็ขอบคุณเธอ ไม่อย่างนั้นก็คงไม่ได้แต่งงาน\n",
            "predicted text = แต่ก็ขอบคุณเธอ ไม่อย่างนั้นก็คงไม่ได้แต่งงาน\n",
            "\n",
            "original_text =   ความหนาแน่นสูงมาก\n",
            "predicted text = ้นาน\n",
            "\n",
            "original_text =   เพราะเกรงว่าถัยจะมาถึงตัว กระทั่งเข้าสู่วัยชรา\n",
            "predicted text = เพราะเกรงว่าถัยจะมาถึงตัว กระทั่งเข้าสู่วัยชรา\n",
            "\n",
            "original_text =   และก็เป็นอีกครั้งที่มีข่าวลือว่าเห็น  หีบสมบัติ\n",
            "predicted text = และก็เป็นอีกครั้งที่มีข่าวลือว่าเห็น ศีบสมนัติ\n",
            "\n",
            "original_text =   31\n",
            "predicted text = 3 \n",
            "\n",
            "original_text =   ก็เลย เป็นคนไม่กินซุปเลย\n",
            "predicted text = ก็เลย เป็นคนไม่กินซุปเลย\n",
            "\n",
            "original_text =   สุเทพ วงศ์กำแหง ตำนานเพลงลูกกรุงผู้ยิ่งใหญ่\n",
            "predicted text = สูเทพ วงส์กำแหง ตำนานเพลงลูกกรุงผู้ฮิ่งใหญ่\n",
            "\n",
            "original_text =   เมื่อช่วงต้นเดือนเมษายน ปี 2560\n",
            "predicted text = เมื่อช่วงต้นเดือนมษายน ปี 2560\n",
            "\n",
            "original_text =   BANGKWANG CENTRAL PRISON\n",
            "predicted text = G  T n\n",
            "\n",
            "original_text =   ทรัพย์สินมีค่าทั้งหมดถูกกวาดใส่ถุงปุ๋ยก่อน ก่อนพวกมันจะหายตัว\n",
            "predicted text = ทรัยร์สินมีจ่าทิงหมดถูกกวาดไส่กุงปูย ก่อนพวกมันจะหายตัว\n",
            "\n",
            "original_text =   แล้วเอากล้องไปจ่ออย่างงี้ ลุงแกจะสับยังไงวะ\n",
            "predicted text = แล้วเอาทล้องไปจ่ออย่างขี้ ลุงแกจะสับไก่ยังไงวะ\n",
            "\n",
            "original_text =   ถูกรัดคอด้วยผ้าขี้ริ้ว ข้างตัวพบมีดปอกผลไม้ 1 เ่ลม\n",
            "predicted text = ถูกรัดคอด้วยผ้าขี้ริ้ว ข้างตัวพบมีดปอกผลไม้ 1 เล่ม\n",
            "\n",
            "original_text =   ภายในมีลูกปรายกว่า 700 เม็ด\n",
            "predicted text = ภายในมีลูกปรายกว่า 700 เม็ด\n",
            "\n",
            "original_text =   แค่เพียงมนุษย์\n",
            "predicted text = แค่เพียงมนุษย์\n",
            "\n",
            "original_text =   ต้องพบสมบัติเป็นทองคำแน่ๆ\n",
            "predicted text = ต้องพบสมบัติเป็นทองคำแน่ๆ\n",
            "\n",
            "original_text =   MH370\n",
            "predicted text = 50\n",
            "\n",
            "original_text =   กมล เสมอเหมือน\n",
            "predicted text = กมล เสมอเหมือน\n",
            "\n",
            "original_text =   แต่ว่าเรามีจัดโปรโมชั่นมาหลายครั้ง\n",
            "predicted text = แต่ว่าเรามีจัดโปรโมชั่นมาหลายครั้ง\n",
            "\n",
            "original_text =   จำลองเหตุการณ์\n",
            "predicted text = จำาลองเหตุาารา์ \n",
            "\n",
            "original_text =   มีคนบอกว่า เป็นร้านที่ ต้องจองบัตรคิวเลย\n",
            "predicted text = มีคนบอก่าง เป็นร้านที่ ต้องจองบัตรควเลย\n",
            "\n",
            "original_text =   ที่เคยก่อคดีปล้นอุกอาจ ฆ่าตำรวจมาแล้ว\n",
            "predicted text = ที่เคยก่อคดีปล้นอกอาจ ฆ่าตำรวจมาแล้ว\n",
            "\n",
            "original_text =   3 ล้านบาท\n",
            "predicted text = 3 ล้านบาท\n",
            "\n",
            "original_text =   เบื้องหลังการจับกุม คือตำรวจได้ส่งมือดี\n",
            "predicted text = เปื้องหลังการจับกุม คือตำารวจได้ส่งมีอดี\n",
            "\n",
            "original_text =   ตอนนั้นผมเรียนเพาะช่างไปเจอสาวคนหนึ่งบยรถเมล์\n",
            "predicted text = ตอนนั้นผมเรียนเพาะซ่างไปเจอสาวคนหนึ่งบนรถเมล์\n",
            "\n",
            "original_text =   19 ต.ค. 27 เสี่ยแหย ถูกมือปืนถล่มด้วย M16 จนรถพรุน\n",
            "predicted text = 19 ต ค 27 เสี่ยแหย ถูกมือปินถล่มด้วย M16 จนรถพรูน\n",
            "\n",
            "original_text =   หัวใจเป็นหนึ่ง\n",
            "predicted text = หัวใจ็นหนี่ง\n",
            "\n",
            "original_text =   ทีมนายปลอดประสพ สุรัสวดี ในฐานะอธิบดีกรมป่าไม้ ในขณะนั้น\n",
            "predicted text = กีมนายปลอดประสพ สูรัสวดี ในฐาน ฮธิบดีกรม่าไม้ ในขณน้น\n",
            "\n",
            "original_text =   ครอบครัว ดีผิว กำลังขับรถเข้ากรุงเทพฯ\n",
            "predicted text = ครอบครัว  ดีผิว  กำลังขับรถเข้ากรุงเทพๆ\n",
            "\n",
            "original_text =   ทางหนีทีไล่ของคนร้ายเป็นอย่างดี\n",
            "predicted text = ทางหนีทีไล่ของคนร้ายเป็นอย่าังดี\n",
            "\n",
            "original_text =   กัปตันและผู้ช่วยฯ จะต้องแจ้งเตือน\n",
            "predicted text = กัปตันและผู้ช่วยฯ จะต้องแจ้งเตือน\n",
            "\n",
            "original_text =   ก่อนเกิดเหตุ  เสี่ยแหย  เดินทางมาศาลพร้อมทีมคุ้มกัน\n",
            "predicted text = ก่อนเกิดเหตุ  เสี่ยแหย  เดินทางมาศาลพร้อมทีมคุ้มกัน\n",
            "\n",
            "original_text =   แน่นหนามาก เดินไฟฟ้าไว้ตลอด\n",
            "predicted text = แน่นหนามาก เดินไฟฟ้าไว้ตลอด\n",
            "\n",
            "original_text =   เพราะจำนนด้วยหลักฐาน คือ ปืนอาก้า พร้อนกระสุน\n",
            "predicted text = เพราะจำนนด้วยหลักฐาน คือ ป็นอาท้ พร้อมกระสุน\n",
            "\n",
            "original_text =   แต่พอมารอบนี้\n",
            "predicted text = แต่พอมารอบนี้\n",
            "\n",
            "original_text =   หลายประเทศรับข่าวสารดังกล่าว จึงใช้มาตรการเข้ม\n",
            "predicted text = หลายประเทศรับข่าวสารดังกล่าว จึงใช้มาตรการเข้ม\n",
            "\n",
            "original_text =   ที่วัยรุ่นเชียงใหม่ทุกคนต้องไปสัมผัส\n",
            "predicted text = ที่วัยรุ่นเชียงใหม่ทุกคนต้องไปสัมผัส\n",
            "\n",
            "original_text =   ในขณะที่ฝูงชนจำนวนมากมาดักรอที่โรงหนัง โห่ร้อง\n",
            "predicted text = ในขณะที่ฝูงชนจำนวนมากมาดักรอที่โรงหนัง โห่ร้อง\n",
            "\n",
            "original_text =   แก้ปัญหาได้ เรียนรู้เป็น เขาก็ไม่มีอนาคต\n",
            "predicted text = แกัปิหาได้ เรียนรู้เป็น เขาก็ไม่มีอนาคต\n",
            "\n",
            "original_text =   หือ นุ่มมาก\n",
            "predicted text = หือ ปู่มมาก\n",
            "\n",
            "original_text =   เพราะเห็นจำเลยคนหนึ่งไปนั่งบริเวณม้านั่งบริเวณมุขหน้าศาล\n",
            "predicted text = เพราะเห็นจำเลยคมหนึ่ไปนั่งบริเวณม้านั่งบริเวณบุขหน้าศาล\n",
            "\n",
            "original_text =   คือเค้าไปไกลอีกขั้นล่ะนะ\n",
            "predicted text = คือเค้าไปไกลอีกขั้นส่ะนะ\n",
            "\n",
            "original_text =   คนใจร้าย...\n",
            "predicted text = คนจร้าย...\n",
            "\n",
            "original_text =   เมื่อขุดอยู่ครึ่งวัน..ก็ไม่พบอะไร\n",
            "predicted text = เมื่อขุดอยู่ครึ่งวัน  ก็ไม่พบอะไร\n",
            "\n",
            "original_text =   ผู้รักษากฎหมาย\n",
            "predicted text = ผู้ยรรบบริ้าย\n",
            "\n",
            "original_text =   ใต้ท้องรถตรงคนขับเป็นหลุมลึก 1 ฟุต เก้าอี้ขาดกระจุย\n",
            "predicted text = ใต้องรถตรงคนขันเป็นหลุมลึก 1 พุต เก้าอีขาถกระจุว\n",
            "\n",
            "original_text =   ในที่สุดจึงต้องจัดทีมไล่ล่า!\n",
            "predicted text = ในที่สุดจีงต้องจัดทีมไล่ล่า!\n",
            "\n",
            "original_text =   วันที่ 1 มกราคม 2020 สาธารณสุขจีนรู้ถึงการระบาด\n",
            "predicted text = วันที่ 1 มกราคม 2020 สาธารณสุยจีนรู้ถึงการระบาด\n",
            "\n",
            "original_text =   ใช่ว่า เราจะไปบอกไปสอนใครหรอก\n",
            "predicted text = ใช่ว่า เราจะไปบอกไปสอนใครหรอก\n",
            "\n",
            "original_text =   เราขอท้าพี่พีช\n",
            "predicted text = เราขอท้าพี่พีช\n",
            "\n",
            "original_text =   ในข้อหาจ้างวานฆ่านางปัทมา\n",
            "predicted text = ในข้อหาจ้างวานฆ่านางปัทมา\n",
            "\n",
            "original_text =   โดยได้เล่าเหตุการณ์วันนั้นให้ฟังว่า..\n",
            "predicted text = โดยได้เล่าเหตุการณ์วันนั้นให้ฟังว่า.\n",
            "\n",
            "original_text =   Earn $15 to $25 per week\n",
            "predicted text = Saาก.S5a .s2soecees\n",
            "\n",
            "original_text =   นี้ร้านที่ 2 นะคะ ร้านแดนข้าวมันไก่\n",
            "predicted text = น้ร้านที่2 นะคะร้านแดนข้าวมันไก่\n",
            "\n",
            "original_text =   ความคิดคนเริ่มจะสั้น\n",
            "predicted text = ววมลิดคนเรี่มจะส้น\n",
            "\n",
            "original_text =   2.สินค้าปริศนาใต้ท้องเครื่อง\n",
            "predicted text = 2.สินค้าปริศนาใต้ท้องเครื่อง\n",
            "\n",
            "original_text =   และก็เป็นอีกครั้งที่มีข่าวลือว่าเห็น  หีบสมบัติ\n",
            "predicted text = และก็เป็นอีกครั้งที่มีข่าวลือว่าเห็น  หืบสมบัติ\n",
            "\n",
            "original_text =   ระเบิดมีลูกปลาย แรงอัดระเบิด\n",
            "predicted text = ระเบิดมีลูกปลาย แรงอัดระเบิด\n",
            "\n",
            "original_text =   มันเป็นกองศพ อยู่ตรงนั้นเป็นร้อยศพ\n",
            "predicted text = มันเป็นกองศพ อยู่ตรงนั้นเป็นร้อยศพ\n",
            "\n",
            "original_text =   นักวิชาการอิสระ\n",
            "predicted text = นักวิชาการอสระ\n",
            "\n",
            "original_text =   ลดความเหนื่อยล้าด้วย\n",
            "predicted text = ลดความเนนื่อยล้าด้วย\n",
            "\n",
            "original_text =   สรุปก็คือ ธีมวันนี้เราก็เลยจัดเป็นวันแบบ\n",
            "predicted text = สรูปก็คือ รีมวันนี้เราก็เลยจัดปินวัแบบ\n",
            "\n",
            "original_text =   เสียงพระครูบาบุญชุ่ม ญาณสํวโร เกจิชื่อดังแดนเหนือ\n",
            "predicted text = เสียงพระครูบามุญช่ม ญาณส่วโร เกจิี่อดังแดเหนือ\n",
            "\n",
            "original_text =   ในปี 2018 ไซมอน ฮาร์ดี นักบินอาวุโสของโบอิ้ง 777\n",
            "predicted text = ในปี 2018 โซมอน ราร์ดี นักบินอาวุโสของโบอิ้ง 777\n",
            "\n",
            "original_text =   เคยเป็นลูกน้อง อดีต รมต. หลบหนี มาตลอด\n",
            "predicted text = เคยเป็นลูกน้องอดีต รมต  หลบหนีมาตลอด\n",
            "\n",
            "original_text =   หลัง  นักโทษหาย  นายวิวิทย์ จตุปาริสุทธิ์\n",
            "predicted text = หลัง  นักโทษหาย  นายวิวิทย์ จตุปาริสุทธ์\n",
            "\n",
            "original_text =   สมัครได้ทุกวัน    เวลา 8 00-10 00น  สมัครก่อนทำก่อน\n",
            "predicted text = นกุงิน้กวu .ew s ut e ud  wuntaun\n",
            "\n",
            "original_text =   สุเทพ วงศ์กำแหง ตำนานเพลงลูกกรุง\n",
            "predicted text = สุเกพ วงศ์กำแหง ตำนานเพลงลูกกรุง\n",
            "\n",
            "original_text =   เวลผ่านไป 40 นาที เครื่องบินโบอิ้ง 777-200ER\n",
            "predicted text = เวลาผ่านไป 40 นาที เครื่องบินโบอิ้ง 777-200E\n",
            "\n",
            "original_text =   ลดความตึงเครียด\n",
            "predicted text = ลดควาปดงเครีอด\n",
            "\n",
            "original_text =   โดยมีการขุดถ้ำลงไป 3 ชั้น\n",
            "predicted text = โดยมีการขุดถ้ำลงไป 3 ชั้น\n",
            "\n",
            "original_text =   ผมเริ่มขับตั้งแต่ปี 2532\n",
            "predicted text = ผมเริ่มขับตั้งแต่ปี 2532\n",
            "\n",
            "original_text =   จนน้ำมันหมดแล้วดิ่งลงน้ำในลักษณะควงสว่าน\n",
            "predicted text = จนน้ำมันหมดแล้วดิ่งลงน้ำในลักษณะควงสว่าน\n",
            "\n",
            "original_text =   เออ เราล็อกไก่ๆ\n",
            "predicted text = เออ เราล็อกไก่ๆ\n",
            "\n",
            "original_text =   ออสเตรเลีย เนปาล ฝรั่งเศส มาเลเซีย แคนาดา\n",
            "predicted text = จงสเตลเีนย 8เมปาล ฝมังกล น เกาสเีน 9เทมกา\n",
            "\n",
            "original_text =   ทางบาดแผล\n",
            "predicted text = ทาบาดเผผล\n",
            "\n",
            "original_text =   เลือดผู้ตายได้ไหลออกจาก\n",
            "predicted text = เลือดผู้ตายได้ไหลออกจาก\n",
            "\n",
            "original_text =   27\n",
            "predicted text = 22\n",
            "\n",
            "original_text =   จ พระนครศรีอยุธยา\n",
            "predicted text = จ พระนครศรีอยุธยา\n",
            "\n",
            "original_text =   ก็บวกเลเวลขึ้นมา จากปกตินิดนึง\n",
            "predicted text = ก็บวกเลเวลขึ้นมา จากปกตินิดนึง\n",
            "\n",
            "original_text =   ปิดกั้น ใส่กุญแจล็อกตลอด\n",
            "predicted text = ปืดกั้น ใส่กุญแจล็อกตลอด\n",
            "\n",
            "original_text =   ทรัพย์สิน เป็นนาฬิกา 15 เรือน กล้องถ่ายรูป 3 ตัว\n",
            "predicted text = ทรัพย์สิน เป็นนาฬิกา 15 เรือน กล้องถ่ายรูป 3 ตัว\n",
            "\n",
            "original_text =   เป็นสถานที่สมควรแก่การปฏิบัติธรรม\n",
            "predicted text = เป็นสถานที่สมควรแก่การปฏิบัติธรรม\n",
            "\n",
            "original_text =   ทั้งหมดนัดรวมตัวกันที่  อโคจร  แห่งหนึ่ง\n",
            "predicted text = ทั้งหมดนัดรวมตัวกันที่ อโคจร แห่งหนึ่ง\n",
            "\n",
            "original_text =   ผู้หญิงมักตกเป็นเหยื่อ\n",
            "predicted text = ผู้หิงมักตภเป็นเหรื่อ่\n",
            "\n",
            "original_text =   คืออาคาร 1 และ อาคาร 2\n",
            "predicted text = คืออาคาร 1 และ อาคาร 2\n",
            "\n",
            "original_text =   บริษัทของซินแสโชกุน\n",
            "predicted text = นริษทของซินแสโชถุน\n",
            "\n",
            "original_text =   วางแผนละเอียดรอบคอบ\n",
            "predicted text = วางแผนละเอียดรอบคอบ\n",
            "\n",
            "original_text =   เพราะอยากให้ลัดดาแลนด์เป็นสมบัติของเมืองเชียงใหม่\n",
            "predicted text = เพราะวยากใหลัดดาแลนด์เป็นสมบัติของเมืองเชียงใหม่\n",
            "\n",
            "original_text =   สาเหตุหนึ่งเพราะเจ้าหน้าที่ไม่มีเครื่องมือสื่อสาร\n",
            "predicted text = สาเหตหนึ่งพรงะเจ้าวม้าที่ไมมีเครื่องมือสื่อสาร\n",
            "\n",
            "original_text =   พร้อมอาวุธครบมือ ไปขอรับตัว นช. ระทม ที่กองปราบปราม\n",
            "predicted text = พร้อมอาวธครบมือ ไปขอรับตัว นช ระกม ที่กองปรามปราม\n",
            "\n",
            "original_text =   หลากทฤษฎี\n",
            "predicted text = หลากกฤปฆฎี\n",
            "\n",
            "original_text =   ร.ต.ท.เชาวรินธร์ ให้สัมภาษณ์หลังพบรางรถไฟ\n",
            "predicted text = ร.ต. .เชาวรินธร์ ให้สัมภาษณ์หลังพบรางรถไฟ\n",
            "\n",
            "original_text =   เมื่ออาตมาเป็นเณรเคยไปกราบท่าน\n",
            "predicted text = มื่ออาฒมาเป็นเณรเคยไปกราบท่าน\n",
            "\n",
            "original_text =   เป็นเหตุร้ายแรงที่สุด\n",
            "predicted text = เป็นเหตุร้ายแรงที่สูล\n",
            "\n",
            "original_text =   สิ่งที่ นช.ระทม ทิ้งไว้คือรอยเท้า\n",
            "predicted text = สั่งที่ นช.ระทม ที้งไว้คือรอยเท้า\n",
            "\n",
            "original_text =   อ่อนล้า\n",
            "predicted text = ออนลั\n",
            "\n",
            "original_text =   อ่อนล้า\n",
            "predicted text = อ่อนั\n",
            "\n",
            "original_text =   cialadvantages  Excellent income. Any\n",
            "predicted text = wnleorcraneyes e eelenr tneoone. On\n",
            "\n",
            "original_text =   เพื่อเป็นการลงโทษตามระเบียบของเรือนจำ\n",
            "predicted text = เพื่อเป็นการลงโทษตามระเบียบของเรือนจำ\n",
            "\n",
            "original_text =   รมว ยุติธรรม (ขณะนั้น) กล่าว\n",
            "predicted text = รมว. ยุติธรรม (ขณะนั้น) กล่าว\n",
            "\n",
            "original_text =   สวัสดีครับ\n",
            "predicted text = สวัสดีครับ\n",
            "\n",
            "original_text =   ออสเตรเลีย เนปาล ฝรั่งเศส มาเลเซีย แคนาดา กัมพูชา ศรีลังกา เยอรมนี ยูเออี\n",
            "predicted text = สีา เงราว เรา มเยีา ปยเตา มเใพ เวีโรา ไโย าฮ่\n",
            "\n",
            "original_text =   InFRARED\n",
            "predicted text = IอRูE2\n",
            "\n",
            "original_text =   DESIGN\n",
            "predicted text = GSGG\n",
            "\n",
            "original_text =   วันข้าวมันไก่แห่งชาติ\n",
            "predicted text = ว้นข้าอมันไที่เเฮวชาติ\n",
            "\n",
            "original_text =   ชาวบ้านที่มุงดูถึงกับผงะ\n",
            "predicted text = ชาวบ้านที่มุงดูถึงกับผงะ\n",
            "\n",
            "original_text =   ทฤษสมคบคิด MH370\n",
            "predicted text = ทฤษฎีสมคบคิด MH370\n",
            "\n",
            "original_text =   ผู้ติดเชื้อ 9,776 รวย\n",
            "predicted text = ผู้ติดเชื้อ 9 776 ราย\n",
            "\n",
            "original_text =   และมารู้ทีหลังว่า\n",
            "predicted text = และมารู้ทีหลังว่า\n",
            "\n",
            "original_text =   NOCNOC.com\n",
            "predicted text = NOCNOC.COกก\n",
            "\n",
            "original_text =   นี่คือทฤษฎี(สมคบคิด)\n",
            "predicted text = นี่คือทฤษฎี สมตบศิด\n",
            "\n",
            "original_text =   แต่หากอยากไปเที่ยวญี่ปุ่นก็ต้องอัปเกรด\n",
            "predicted text = แต่หากอยากไปเที่ยวญี่ปุ่นก็ต้องอัปเกรด\n",
            "\n",
            "original_text =   โทรหาดิ๊ โทรหาๆ\n",
            "predicted text = โกรหาดิ๊โทรหาๆ\n",
            "\n",
            "original_text =   จากนั้นมีชายคนหนึ่งลงจากรถ\n",
            "predicted text = จากนั้นมีชายคนหนึ่งลงจากรถ\n",
            "\n",
            "original_text =   แต่คนก็จะบอกผมว่า แล้วไงล่ะ\n",
            "predicted text = แต่คนก็จะบอกกับผมว่า แล้วไงละ\n",
            "\n",
            "original_text =   LADDALAND\n",
            "predicted text = AONOGLNN0\n",
            "\n",
            "original_text =   เพลงประทับบใจ\n",
            "predicted text = เพลงประทับใจ\n",
            "\n",
            "original_text =   ขอบคุณ\n",
            "predicted text = อบคุรณน\n",
            "\n",
            "original_text =   คุณลุงเค้าเป็นแฟนคลับ Bearhug นะ บอกเลย\n",
            "predicted text = คุณลงเค้าเป็นแหนคลับ Bearhาuo นะ บอกเลย\n",
            "\n",
            "original_text =   งานวิจัยระดับโลก\n",
            "predicted text = านวิจัยระดับโลก\n",
            "\n",
            "original_text =   ทอนซิลอักเสบ\n",
            "predicted text = เอนขลอิักเสบ\n",
            "\n",
            "original_text =   ผู้เชี่ยวชาญด้านจระเข้ ระบุว่า\n",
            "predicted text = ผู้เชี่ยวชาญด้านจระเข้ ระนว่า\n",
            "\n",
            "original_text =   แต่เกิดจากแผงวงจรควบคุมไฟฟ้า\n",
            "predicted text = แต่เกิดจากแผงวงจรควบคุมไฟฟ้า\n",
            "\n",
            "original_text =   เราก็รู้\n",
            "predicted text = ิ้อ\n",
            "\n",
            "original_text =   เจ้าของให้รางวัลมา 350 บาท\n",
            "predicted text = เจ้าของให้รางวัลมา 350 บาท\n",
            "\n",
            "original_text =   เค้าก็เลยบอก โอเค งั้นเปิดก็ได้\n",
            "predicted text = เค้าก็เลยบอก โอเค รันเปิดกไได้\n",
            "\n",
            "original_text =   ครั้งนี้ถึงกับใช้ระเบิดเปิดปากถ้ำ ซึ่งคนที่ลงมือคือ\n",
            "predicted text = ครั้งนี้ึงกับใช้ระเบิดเปิดปากด้ำ ซึ่งคนที่ลงมือคือ\n",
            "\n",
            "original_text =   อีกครั้งเป็นการแหกคุกที่ร้อยเอ็ด ครั้งนั้นเป็นความบกพร่อง\n",
            "predicted text = อีกครั้งเป็นกรแหกคุกท่ร้อยเอ็ด ครั้งนั้นเป็นความบาหรฮง\n",
            "\n",
            "original_text =   16 มกราคม รมว สาธารณสุขญี่ปุ่นยอมรับ\n",
            "predicted text = 16 มกราคม รมว.สาธารณสุขญี่ปุ่นยอมรับ\n",
            "\n",
            "original_text =   เฮ้ยวันนี้วันที่เท่าไหร่ พรุ่งนี้ลุ้นหวยเปล่า\n",
            "predicted text = เฮ้ย วันนี้วันที่เท่าไหร่ พรุู่งนี้ลุ้นหวยเปล่า\n",
            "\n",
            "original_text =   ไอ้จิ๊บ ไผ่เขียว สารภาพในเวลาต่อมา\n",
            "predicted text = ไอ้จิ๊บ ไผ่เขียว สารภาพในเวลาต่อม่า\n",
            "\n",
            "original_text =   ต่อมาแพทย์ชันสูตรระบุว่า เป็นไปได้ 2 กรณีคือ\n",
            "predicted text = ต่อมาแพทย์ชันสูตรระบุว่า เป็นไปได้ 2 กรณีคือ\n",
            "\n",
            "original_text =   หลังการตายของพยาน ทำให้ผู้ต้องหาอีกคนซึ่งเป็นมือระเบิด\n",
            "predicted text = หลังกาะตายของพยาน ทำให้ผู้ต้องหาอีกคนซึ่งเป็นมือระเบิด\n",
            "\n",
            "original_text =   ที่เหลือเป็นรถหรูและทรัพย์สินมีค่าอื่นๆ\n",
            "predicted text = ที่เหลื่อเป็นรถหรูและครัพย์สินมีคาอื่นๆ\n",
            "\n",
            "original_text =   14 เมษายน 2560\n",
            "predicted text = 14 เมษายน 2560\n",
            "\n",
            "original_text =   เรือนจำกลางบางขวาง\n",
            "predicted text = รือร์รรรรง\n",
            "\n",
            "original_text =   หรือพาไปเที่ยวญี่ปุ่น ฮ่องกง\n",
            "predicted text = หรือพาไปเที่ยวญี่ปุ่น ฮ่องกง\n",
            "\n",
            "original_text =   ชื่อเต็มคือ อะไร\n",
            "predicted text = ชื่อเต็มคืออะไร\n",
            "\n",
            "original_text =   Wuhan, China\n",
            "predicted text = uาan.Cาtna\n",
            "\n",
            "original_text =   เปิดมาแล้วกี่ปีคะ\n",
            "predicted text = เปิดมาแล้วกี่ปีคะ\n",
            "\n",
            "original_text =   เสียงพระครูบาบุญชุ่ม ญาณสํวโร เกจิชื่อดังแดนเหนือ\n",
            "predicted text = เสียงพระครูบามุญซุ่ม ญาณส่วโร กจิชื่อดังแดนเหนือ\n",
            "\n",
            "original_text =   มีนายตำรวจอีก 3 คน ทนายความและน้องชาย\n",
            "predicted text = มีนายตำรวจอีก 3 คน ทนายความและน้องชาย\n",
            "\n",
            "original_text =   อย่าท้อใจ\n",
            "predicted text = ้ีย้อสทรร\n",
            "\n",
            "original_text =   ร่วมกันกู้ยืมเงินที่เป็นการฉ้อโกงประชาชน\n",
            "predicted text = ร่วมกันกู้ยืมเงินที่เป็นการฉ้อโกงประชาชน\n",
            "\n",
            "original_text =   จากการสอบสวนพยาน ระบุว่า เห็นทีมสังหารมีด้วยกัน 3 คน\n",
            "predicted text = จากการสอบสวนพยาน ระบุว่า เห็นทีมสังหารมีด้วยกัน 3 คน\n",
            "\n",
            "original_text =   xinhua thai\n",
            "predicted text = ทhนa cาa่\n",
            "\n",
            "original_text =   คราวนี้ขอส่วนแบ่ง 1 ใน 3 หากขุดพบ  อภิมหาสมบัติ\n",
            "predicted text = คราวนี้ขอส่วนแบ่ง 1 ใน 3 หากขุดพบ  อภิมหาสมบัติ\n",
            "\n",
            "original_text =   ถ้าจบอย่างนี้\n",
            "predicted text = ถ้าจบอย่างบ\n",
            "\n",
            "original_text =   ดาวเทียมตรวจสอบถ้ำลิเจีย พบว่า  ไม่มีอะไร...\n",
            "predicted text = ตาวเทียมตรวจสอบถ้ำลิเจีย พบว่า ไม่มีอะไร\n",
            "\n",
            "original_text =   มันทุกอย่างเลย\n",
            "predicted text = มันทุกอย่างเลย\n",
            "\n",
            "original_text =   มาเลยๆ\n",
            "predicted text = บร\n",
            "\n",
            "original_text =   สาเหตุจริงมาจากเรื่องเลี้ยวปาดหน้ากัน\n",
            "predicted text = สาเหตุจริงมาจากเรื่องเล้ยวปาดหน้ากัน\n",
            "\n",
            "original_text =   เวลา 00.40 น.\n",
            "predicted text = เวลา 00 40 น.\n",
            "\n",
            "original_text =   จนเวลาเที่ยงคืนได้ไปเจอศพผู้เสียชีวิต 1 ราย\n",
            "predicted text = จนเวล่าเที่ยงคื่นได้ไปเธือศพผู้เสี่ยซีวิต 1 ราย\n",
            "\n",
            "original_text =   ทั้งที่พยานมีความสำคัญยิ่งต่อการพิสูจน์ความจริง\n",
            "predicted text = ทั้งที่พยานมีความสำคัญยิ่งต่อการพิสูจน์ความจริง\n",
            "\n",
            "original_text =   เกิดเหตุระเบิดขึ้นหน้าศาลจังหวัดนครราชสีมา\n",
            "predicted text = เกิดเหตุระเบิดขึ้นหน้าศาลจังหวัดนครราชสีมา\n",
            "\n",
            "original_text =   แถลงยืนยันว่าเป็นชิ้นส่วนของ MH370 จริง\n",
            "predicted text = แถลงยืนยันว่าเป็นชิ้นส่วนของ MH370 จริง\n",
            "\n",
            "original_text =   การจับกุมครั้งนี้ คนร้ายให้การรับสารภาพ\n",
            "predicted text = การจับกุมครั้งนี้ คนร้ายให้การรับสารภาพ\n",
            "\n",
            "original_text =   คือฝ่ายติดตามชี้เป้า และ ฝ่ายวางระเบิด\n",
            "predicted text = คือฝ่ายติดตามชี้เป้า และ ฝ่ายวางระมีด\n",
            "\n",
            "original_text =   ยังไงเราก็เฉยไป\n",
            "predicted text = ยังไงเราก็เฉยไป\n",
            "\n",
            "original_text =   น้องโตมี่ หรือ ด ช โภคิน ดีผิด อายุ 12 ปี\n",
            "predicted text = น้องโตมี่ หรือ ด ช โฤคิน ดีผิว อายุ 12 ปี\n",
            "\n",
            "original_text =   ไอ้จิ๊บ มีพี่น้อง 3 คน\n",
            "predicted text = ไอ้จิ๊บ มีพื่น้อง 3 คน\n",
            "\n",
            "original_text =   มีการปรับฮวงจุ้ยให้จนสำเร็จ\n",
            "predicted text = มีการปรับฮวงจ้ยให้จนส่เร็จ\n",
            "\n",
            "original_text =   ก่อนที่มันจะสายไป\n",
            "predicted text = ก่อนรันที่มันละส   \n",
            "\n",
            "original_text =   2.ปมสังหารผู้กว้างขวางวงการค้าไม้อีกคน\n",
            "predicted text = 2.ปมสังหารผู้กว้างขวางวงการค้าไม้อีกคน\n",
            "\n",
            "original_text =   หลังหนีออกมาได้\n",
            "predicted text = หลังหนีออกมาได้\n",
            "\n",
            "original_text =   สินค้าขายดีสำหรับ ห้องนอน ทั้งหมด\n",
            "predicted text = เนพ แ๑นน....\n",
            "\n",
            "original_text =   ส่วนอีกเพลงคือ เสียสละรัก เพราะเป้นรักฝังใจ\n",
            "predicted text = ส่วนอีกเพลงคือ เสียสละรัก  เพราะเป็นรักผังใจ\n",
            "\n",
            "original_text =   ที่คนไทนและชาวพม่าเคารพนับถือบอกกับทุกคนให้มีหวัง\n",
            "predicted text = ที่นใทยและซาวพม่าเคารพนับถือบอกกับทุกคนให้มีหวัง\n",
            "\n",
            "original_text =   เจ้าของป้าย เค้าคงไม่มาสนับสนุนหรอก\n",
            "predicted text = เจ้าของป้าย เค้าคงไม่มาสนับสุนหรอก\n",
            "\n",
            "original_text =   หากมีอาการป่วยต้องแจ้งให้แพทย์ทราบที\n",
            "predicted text = หากมิอเทารป่ยยร้่องนจง์งใรันดนย์รราบพัยต์\n",
            "\n",
            "original_text =   สาเหตุหนึ่งเพราะเจ้าหน้าที่ไม่มีเครื่องมือสื่อสาร\n",
            "predicted text = ูเสสน ประเงีเน้าขี่ไน็ดรื่องมืสื่อสาร\n",
            "\n",
            "original_text =   ว่าเราจะไม่ทน\n",
            "predicted text = ว่าเราจะไม่หน\n",
            "\n",
            "original_text =   คือ บริษัทของซินแสโชกุนเป็นเงิน..\n",
            "predicted text = คือ บริษัทของซินแสโชกุนเป็นเงิน.\n",
            "\n",
            "original_text =   TEXI-METER\n",
            "predicted text = แ  uGea\n",
            "\n",
            "original_text =   ซินด้าเป็นเจ้าเดียวในไทย\n",
            "predicted text = ซินด้าเป็นเจ้าเดียวในไทย\n",
            "\n",
            "original_text =   การติดต่อ\n",
            "predicted text = การตดต่อ\n",
            "\n",
            "original_text =   ที่นี่เป็นที่สุดของเชียงใหม่เลยใช่มั้ยคะ ข้าวมันไก่\n",
            "predicted text = ที่นี่เป็นที่สุดของเชียงใหม่เลยใช่มั้ยคะ ข้าวมันไก่\n",
            "\n",
            "original_text =   แต่สิ่งสำคัญที่อยากจะบอกก็คือ\n",
            "predicted text = แต่สิ่งสำคัญที่อยากจะบอกก็คือ\n",
            "\n",
            "original_text =   ฟิลิปปินส์ ฟินแลนด์\n",
            "predicted text = สsบu. S ผooous\n",
            "\n",
            "original_text =   ที่จะจัดการป้องกันไม่ให้โรคเช่นนั้นแหร่หลาย\n",
            "predicted text = เียรักธรมัองกันบ ไห ไยคลเซน นันยหวพลาน\n",
            "\n",
            "original_text =   อภิมหาสมบัติถ้ำลิเจีย\n",
            "predicted text = อกิมหาสมบัติถ้ลเจิย\n",
            "\n",
            "original_text =   ทั้งหมดนัดรวมตัวกันที่  อโคจร  แห่งหนึ่ง\n",
            "predicted text = ทั้งหมดนัดรวมตัวกันที่ อโคจร  เแห่งหนึ่ง\n",
            "\n",
            "original_text =   MH370\n",
            "predicted text = ร0\n",
            "\n",
            "original_text =   ปัจจุบัน ครูบาบุญชุ่ม ได้เข้าปฏิบัติธรรม\n",
            "predicted text = ปจจุบัน ครูบาบุญชุ่ม ได้เข้าปฏิบัติธรรม\n",
            "\n",
            "original_text =   คิดต่าง\n",
            "predicted text = คืิต่าง\n",
            "\n",
            "original_text =   ปาฏิหาริย์วาจาสิทธิ์\n",
            "predicted text = ปาฏิหาริย์วาจาสิทธิ้\n",
            "\n",
            "original_text =   ที่ผ่านมา โอกาสนักโทษหลบหนี\n",
            "predicted text = ที่ผ่านมา โอกาสนักโทษหลบหนี\n",
            "\n",
            "original_text =   ปล้นและฆ่าเจ้าทรัพย์ร้านทอง,ฯลฯ\n",
            "predicted text = คนนนอนนรนทรนางทรัมรนงสอา\n",
            "\n",
            "original_text =   มีการตั้งข้อสงสัยว่ากลุ่มคนยร้ายอาจจะเป็น กลุ่มคอมมิวนิสต์\n",
            "predicted text = มีการดั้งข้อสงสัยว่ากลุ่มคนร้ายอาจจะเป็น กลุ่มคอมมวนิสต์\n",
            "\n",
            "original_text =   ออสเตรเลีย เนปาล ฝรั่งเศส\n",
            "predicted text = อรสเหรสีย เเนมปาล 1 ฝรังเสส\n",
            "\n",
            "original_text =   MEMORY FOAM\n",
            "predicted text = MENOP FOAM\n",
            "\n",
            "original_text =   ความจริงผมมีครูหลายคนที่เมตตา\n",
            "predicted text = ความจริงผมมีครูหลายคนที่เบตตา\n",
            "\n",
            "original_text =   แม้ฉันเจ็บ เพราะไว้ใจ ให้เธอแค่ไหน ที่เธอผิดไป\n",
            "predicted text = เม้จันเจ็น เพราะไวาใจ ให้เธ้อแค่เหน ที่เธอผิดไป\n",
            "\n",
            "original_text =   ตอนเป็นทหารอากาศมาหลงรักลูกเจ้านาย\n",
            "predicted text = ตอนเป็นกหารอากาศมาหลงรักลูกเจ้านาย\n",
            "\n",
            "original_text =   ไ ต อ ดำรง อินทปันตี ผู้กำกับ สภ เมืองนนทบุรี กล่าวว่า\n",
            "predicted text = พต อ ดำรง อ็นทปันตี ผู้กำกับ สก เมืองนนกบุรี กล่าวว่า\n",
            "\n",
            "original_text =   ที่ไหนได้  มันไกลกันมาก ได้แต่เขียนจดหมาย\n",
            "predicted text = ที่ไหนได้. มันไกลกันมาก ได้แต่เขียนจดหมาย\n",
            "\n",
            "original_text =   เคล็ดลับอยู่ที่ข้าวกับซุป กับน้ำจิ้ม\n",
            "predicted text = เคล็ดลับอยู่ที่ข้าวกับผุป กับน้าจิ้ม\n",
            "\n",
            "original_text =   ในที่สุดชีวิตของ ไอ้จิ๊บ ไผ่เขียว ก็ถูกพิพากษา\n",
            "predicted text = ในที่สุดชีวิตของ  จิ่ 1ผ่เขียวู ก็ดูกพิพากษา\n",
            "\n",
            "original_text =   จากนั้นกราบพระครูบาเสร็จ จะลงจากเขา\n",
            "predicted text = จากนันกราบพระครูบาเสรจ จะลงจาคเขา\n",
            "\n",
            "original_text =   ที่เราจะร่วมกันเปลี่ยนแปลงระบบการศกษาไทย\n",
            "predicted text = ที่ราระร่วบกานปลี่ยนแปลงระบบาารศิกษาไทย\n",
            "\n",
            "original_text =   ขอบคุณคลิปเสียง\n",
            "predicted text = ขอบคุณคลิปเสียง\n",
            "\n",
            "original_text =   นี่ นี่คือ ชื่อ\n",
            "predicted text = น่น่คือชื่อ\n",
            "\n",
            "original_text =   ใน อ ท่าใหม่ เกี่ยวโยงซุ้มมือปืน ซึ่งนายสนิท\n",
            "predicted text = ใน อ ท่าใหม่ เกี่ยวโยงซุ้มมือปืน ซึ่งนายสนิท\n",
            "\n",
            "original_text =   เมื่อสำนานถึงอัยการกลับมีความเห็น  สั่งไม่ฟ้อง\n",
            "predicted text = เมื่อสำนวนถึงอัยการกลับมีความเห็น  สั่งไป่ผ้อง\n",
            "\n",
            "original_text =   เพราะมันเป็นเนื้อน่องไงแก\n",
            "predicted text = เพราะมันเป็นเนื้อน่องไงแ\n",
            "\n",
            "original_text =   เมื่อวัดความยาวตั้งแต่หัวถึงหางพบว่ามีความยาว 9 ศอก หรือ 4 เมตร 25 เซนติเมตร\n",
            "predicted text = เมื่อวัดความยาวตั้งแต่หัวถึงหาง\n",
            "\n",
            "original_text =   ลูกศิษย์ของครูบาบุญชุ่ม\n",
            "predicted text = สูกศิษยของครูบาบุญชุ่ม\n",
            "\n",
            "original_text =   ในระหว่างทำแผนประกอบคำรับสารภาพนั้น ตำรวจได้มอบหมาย\n",
            "predicted text = เระหว่างทำแผนประกอบคำรับสาราพนั้น ตำรวจได้บอบหมาย\n",
            "\n",
            "original_text =   การปล้นครั้งนี้เริ่มจากการพูดคุยกันในป่า\n",
            "predicted text = การปล้นครั้งนี้เริ่มต้นจากการพูดคุยกันในป่า\n",
            "\n",
            "original_text =   ส่วนคำกล่าวขานที่ว่า\n",
            "predicted text = ส่วนคำกล่าวขานที่ว่า\n",
            "\n",
            "original_text =   จากการค้าไม้\n",
            "predicted text = จากการค้าไม้\n",
            "\n",
            "original_text =   ประชากร\n",
            "predicted text = ปรชหาาร\n",
            "\n",
            "original_text =   ข้าวที่เขาใช้ทำ หม้อใหญ่ๆ วันละ 4-5 หม้อ\n",
            "predicted text = ข้าวที่เขาใช้ำ หมัอใหญ่ๆวันละ3 ร หม้อ\n",
            "\n",
            "original_text =   ช่วงเที่ยง วันที่ 22 พ ย  2529 กลุ่มชายฉกรรจ์ไม่ต่ำกว่า 7 คน\n",
            "predicted text = วงเที่ยง วันที่ 22 พ ย 2529 กลุ่มชายฉกรรจไม่ต่ากว่า 1 คน\n",
            "\n",
            "original_text =   คดีนี้ไม่มีพยาน แต่ก็เชื่อว่ามี\n",
            "predicted text = ถคดีนี้ไม่มีพยาน แต่ก็เชื่อว่ามี\n",
            "\n",
            "original_text =   6 ก.ย. 2540 เกิดเหตุระเบิดรถเบนซ์คันหนึ่ง\n",
            "predicted text = 6 กย. 2540 กิดเหรระปิดรดเมเหซีจับหมี่ง\n",
            "\n",
            "original_text =   16 มกราคม รมว.สาธารณสุขญี่ปุ่นยอมรับ\n",
            "predicted text = 16 มกราคม รมว สาธารณสุขญี่ป่นยอมรับ\n",
            "\n",
            "original_text =   ต้องฟอนต์แบบนี้\n",
            "predicted text = ต้องฟอนตแบบนี้\n",
            "\n",
            "original_text =   อยากให้ผู้กว้างขวางนี้ไปพิสูจนูความจริง\n",
            "predicted text = อยาทให้ผู้กว้างขวางนี้ไปพิสูจน์ความจริง\n",
            "\n",
            "original_text =   เรื่องเล่า\n",
            "predicted text = เรืองล\n",
            "\n",
            "original_text =   ซินแสโชกุน เคยอ้างตัวว่าเป็นหมอดู\n",
            "predicted text = ซินแสโชกุน เคยอ้างตัวว่าเป็นหมอดู\n",
            "\n",
            "original_text =   ปิดวาจา 3 ปี 3 เดือน 3 วัน\n",
            "predicted text = ปิดวาจา 3 ปี 3 เดือน 3 วัน\n",
            "\n",
            "original_text =   รวมตัวกันเพราะมีปัญหาอะไรบางอย่าง\n",
            "predicted text = รวมตัวกันเพราะมีปัญหาอไรบางอยาง\n",
            "\n",
            "original_text =   เพียงแต่สถานที่มันเป็นลักษณะป่า\n",
            "predicted text = เพียงแต่สถานที่มันเป็นลักษณะป่า\n",
            "\n",
            "original_text =   ถ้ำลิเจีย  อาจมีขุมทองนับพันตัน\n",
            "predicted text = ถู้ำลิเจีย  อาจมีขุมหองนับพันตัน\n",
            "\n",
            "original_text =   30 มกราคม WHO ประกาศสถานการณ์ฉุกเฉินด้านสาธารณสุข\n",
            "predicted text = 30 มกราคม 1H0 ประกาศสถานการาน์ฉุกเจินด้านสารารณสูว\n",
            "\n",
            "original_text =   เมื่อเจอขอนไม้ใหญ่ขวางถนนจึงจำต้องหยุดรถ\n",
            "predicted text = เมื่อเจอขอนไม้หญขวางถนนจึงจำต้องหยุดรถ\n",
            "\n",
            "original_text =   และค่าตอบแทนที่จำเป็นและสมควรจากรัฐ\n",
            "predicted text = และค่าตอบแทนที่จำเป็นและสมควรจากรัฐ\n",
            "\n",
            "original_text =   ติดเกรด A เลยนะ\n",
            "predicted text = ติดเกรด 4 เลยนะ\n",
            "\n",
            "original_text =   หากสมัครสมาชิกด้วยเงิน 9,730 บาท\n",
            "predicted text = หากสมัครสมาชิกด้วยเงิน 9,730 บาท\n",
            "\n",
            "original_text =   วันที่ความเป็นธรรมทอแสง...\n",
            "predicted text = วันงทีควมวืนรวบาอเสง...\n",
            "\n",
            "original_text =   ที่ไร้มนุษยธรรม\n",
            "predicted text = ที่ไร้มนษยธรรม\n",
            "\n",
            "original_text =   ตอนนั้นสมพงษ์อ้างว่าเก็บเงินและทรัพย์สินได้มากมาย\n",
            "predicted text = ตอนน้สมพงษอ้างว่าเก็บเงินและทรัพย่สินได้มากบาย\n",
            "\n",
            "original_text =   สังหาร\n",
            "predicted text = สังหาระ\n",
            "\n",
            "original_text =   ยอมรับว่าการปิดถนนปล้นครั้งนี้\n",
            "predicted text = ยอมรับว่าการปิดถนนปล้นคร้งี้\n",
            "\n",
            "original_text =   ถ้าใครมาเชียงใหม่ ทุกคนส่วนมากจะไปร้านคาเฟ่ใช่ปะ\n",
            "predicted text = ด้าใครมาชียงใหม่ทูกคนส่วนมากจะไปร้านศาเ่ใปะ\n",
            "\n",
            "original_text =   2563\n",
            "predicted text = 2563\n",
            "\n",
            "original_text =   คนลามคน\n",
            "predicted text = คนสามคน\n",
            "\n",
            "original_text =   นี่ แฟนคลับทั้งครอบครัว\n",
            "predicted text = นี่ แฟนคลับทั้งครอบครัว\n",
            "\n",
            "original_text =   ชายชราคนนี้อ้างว่าทำธุรกิจส่งข้าวสาร\n",
            "predicted text = ชายชราคนนื้อ้างว่าทำธูรกิจส่งข้าวสาร์\n",
            "\n",
            "original_text =   7 นายสมชาติ ตั้งจิตเพียรวิทย์ ทนายความ\n",
            "predicted text = 7.นายสมชาติ ตั้งจิตเพียรวิทย์ ทนายความ\n",
            "\n",
            "original_text =   ของเราเนี่ยค่ะ ให้ถูกต้องตามหลัก\n",
            "predicted text = ของเราเนี่ยคะ ให้ถูคต้องตามหลัก\n",
            "\n",
            "original_text =   ที่ผ่านมา เราทำประโยชน์ สังคมสงเคราะห์\n",
            "predicted text = ที่ผ่านมา เราท่าประโยชน์ สังคมสงเคราะห์\n",
            "\n",
            "original_text =   ในแต่ละชั้นมีประตูกระจกสูง 1 75 เมตร\n",
            "predicted text = ในแต่ละชั้นมีประตูกระจกสูง 1 75 เมตร\n",
            "\n",
            "original_text =   อีกคนนึงมานอนทีหลัง\n",
            "predicted text = อีกคนนึงมานอนทีหลัง\n",
            "\n",
            "original_text =   แต่ตอนนั้นผมไม่สนใจ\n",
            "predicted text = แต่ตอนนั้นผมไม่สนใจ\n",
            "\n",
            "original_text =   กลับกลายเป็นคำที่ทำให้เรานึกถึงเรื่องผี\n",
            "predicted text = กลับกลายเป็นคำที่ทำให้เรานึกถึงเรื่องผี\n",
            "\n",
            "original_text =   วันที่ 5 - 6 พฤษภาคม พ.ศ. 2561 ณ ThaiPBS\n",
            "predicted text = วนที่ ร 6 พภษาาคน พ.ศ. 2ซส ณ หลเยรร\n",
            "\n",
            "original_text =   จากโทษประหารศาลลดโทษเหลือจำคุกตลอดชีวิต\n",
            "predicted text = จากโทษประหารศาลลดโทษเหลือตำาคกตลอดชีวิต\n",
            "\n",
            "original_text =   เฮ้ย กินปนกันแล้วอร่อย\n",
            "predicted text = เอ้ย กินปนกันแล้วอร่อย\n",
            "\n",
            "original_text =   ได้รางวัลตอบแทนมากมาย\n",
            "predicted text = ได้รางวัลตอบแทนมากมาย\n",
            "\n",
            "original_text =   ร่วมงานเลี้ยงอาหารผู้สูงอายุอำเภอเชียงแสน\n",
            "predicted text = จ่านเสิ้ยงอาหาจูสงอายุวำเดอเจีรงสน\n",
            "\n",
            "original_text =   เพราะที่นั่นคือ  บ้านเกิด  ของกัปตันซาฮารี\n",
            "predicted text = เพราะที่นั่นคือ  บ้านเกิด  ของกปตันซาฮารี\n",
            "\n",
            "original_text =   เงิน 8,000 บาท สมัยปี 2507 เป็นเงินที่มากโข\n",
            "predicted text = เงิน 8,000 บาท สมัยปี 2507 เป็นเงินที่มากโข\n",
            "\n",
            "original_text =   ไล่ล่า!\n",
            "predicted text = ไร รั\n",
            "\n",
            "original_text =   ลดความเหนื่อยล้า\n",
            "predicted text = ลอคคอาปพีเครีอด\n",
            "\n",
            "original_text =   โดยไม่แบ่งเชื้อชาติ\n",
            "predicted text = โดยไม่แบ่งเชื้อชาติ\n",
            "\n",
            "original_text =   เมื่อผู้ตายมาถึง ซื้อตั๋ว แถว ง  ไอ้เป๋ ได้ตามเข้ามาในโรงหนัง\n",
            "predicted text = เมื่อผ้ายมาถึง ซือตั้ว แถว ง ไอ้เป ได้ตามเข้ามาในโรงหนัง\n",
            "\n",
            "original_text =   ไวรัสโคโรน่าสายพันธุ์ใหม่\n",
            "predicted text = ไวรัสโคโรน่าสายพันรุ์ใหม่\n",
            "\n",
            "original_text =   หลังจากนั้น ราว 1 สัปดาห์ ตำรวจได้ตามตะครุบ\n",
            "predicted text = หลังจากนั้น ราว 1 สัปดาห์ ตำรวจได้ตามตะครุบ\n",
            "\n",
            "original_text =   เศษชิ้นส่วนระเบิดกระจัดกระจาย แต่เชื่อว่าหมายเอาชีวิตเดียว\n",
            "predicted text = ศษช้เส่วนระเิดกระจัดกระจาย แต่เชื่อว่าหมายเอาชีวิตเดียว\n",
            "\n",
            "original_text =   ร้านโกยี\n",
            "predicted text = ร้านโกยี\n",
            "\n",
            "original_text =   แอบคิดว่า เค้าหยิ่ง\n",
            "predicted text = เอบคิดว่า เค้าหยี่ง\n",
            "\n",
            "original_text =   พัฒนาโดยองค์กรนาซ่าค่ะ\n",
            "predicted text = พัฒมนาโดยองค์กครนาซ่าค่ะ\n",
            "\n",
            "original_text =   นั้นคือหินแร่ Tourmaline นะคะ\n",
            "predicted text = นั้นคือหินแร่ อurmatne นะคะ\n",
            "\n",
            "original_text =   อ้าว พี่คะ ปิดแล้วหรอ\n",
            "predicted text = อ้าว พี่คะ ปิดแล้วหรอ\n",
            "\n",
            "original_text =   ให้วันเวลาสร้างเราขึ้นใหม่\n",
            "predicted text = ใหวันเวลาสร้างเราขึ้นใหม่\n",
            "\n",
            "original_text =   เค้าบอก ตักแต่พอทาน ไม่พอก็เติมเลย\n",
            "predicted text = เค้าบอกว่า ตักแต่พอทาน ไม่พอก็เติมเลย\n",
            "\n",
            "original_text =   ชุดจู่โจมได้ย่องขึ้นชั้น5\n",
            "predicted text = ชุดจู่โจมได้ย่องขึ้นชั้น 5\n",
            "\n",
            "original_text =   นี่เองอาจเป็นคำตอบว่าทำไม\n",
            "predicted text = นี่เองอาจเป็นคำตอบว่าทำไม\n",
            "\n",
            "original_text =   คนไทยตาย\n",
            "predicted text = คนไทยตาย\n",
            "\n",
            "original_text =   ปิดแล้ว\n",
            "predicted text = ปิดแล้ว\n",
            "\n",
            "original_text =   นอกจาก\n",
            "predicted text = นอกาก\n",
            "\n",
            "original_text =   ช่วงที่โดนขังเดี่ยวได้แอบใช้มีดโกน หรือ มีดเหลาดินสอ\n",
            "predicted text = ช่วงทีโดนขังเดี่ยวได้แอบใช้มีดโกน หรือ มีดเหลาดินสอ\n",
            "\n",
            "original_text =   ถูกมือปืนควบ จยย  และ รถเก๋งตามถล่ม\n",
            "predicted text = ถูกมือปืนควบ จยย. และ รถเก่งตามถล่ม\n",
            "\n",
            "original_text =   ไวรัสอู่ฮั่น\n",
            "predicted text = ไวรัสอู่อัื่น\n",
            "\n",
            "original_text =   เมื่อวัดความยาวตั้งแต่หัวถึงหาง\n",
            "predicted text = เมื่อวัดความยาวตั้งแต่หัวถึงหาง\n",
            "\n",
            "original_text =   2.จ.ส.ต. โชคชัย ภู่พุ่ม สภ.อ.วิเศษชัยชาญ\n",
            "predicted text = 2.จ.ส ต โชคชัย ภู่พุ่ม สก.อ. วิเศษชัยชาญ\n",
            "\n",
            "original_text =   บ้านหนองแหน สวนป่าเขาไม้แก่น และบ้านซับบอน\n",
            "predicted text = ข้านหนองแหน สวนป่าเขาไม้แก่น และบ้านชับบอน\n",
            "\n",
            "original_text =   กัปตันและผู้ช่วยฯ จะต้องแจ้งเตือน\n",
            "predicted text = กัปตันและผู้ช่วยฯ จะต้องแจ้งเตือน\n",
            "\n",
            "original_text =   กักตัวบนเกาะ 9 วัน\n",
            "predicted text = กักตัวบนเกาะ 9 วัน\n",
            "\n",
            "original_text =   three seven zero\n",
            "predicted text = เารอรฮงอยกยหด\n",
            "\n",
            "original_text =   ให้เข้ากับสรีระของเราด้วย\n",
            "predicted text = ให้เข้ากันสรีระของเราด้วย\n",
            "\n",
            "original_text =   นอกจากนี้ ยังตั้งข้อสังเกตด้วยว่า\n",
            "predicted text = นอกจากนี้ ยังตั้งข้อสังเกตด้วยว่า\n",
            "\n",
            "original_text =   และทุกๆ อย่างลง\n",
            "predicted text = แเละทุกๆิอย่างลง\n",
            "\n",
            "original_text =   พบปอดอักเสบ\n",
            "predicted text = บปอดอั้กเสบ\n",
            "\n",
            "original_text =   คุณนายลัดดาทำประโยชน์ให้คนเชียงใหม่มาก\n",
            "predicted text = คุณนายลัดดาทำประโยชน์ให้คนเชียงใหม่มาก\n",
            "\n",
            "original_text =   แจ้งความนี้\n",
            "predicted text = แคงดควรี\n",
            "\n",
            "original_text =   ถือเป็นการติดเชื้อนอกประเทศจีนเป็นรายแรก\n",
            "predicted text = ถือเป็นการติดเชือนอกประเทสจีนเป็นรายเรก\n",
            "\n",
            "original_text =   3 นาที\n",
            "predicted text = \n",
            "\n",
            "original_text =   เรื่องอภิมหาสมบัติกองทัพญี่ปุ่น\n",
            "predicted text = เรื่องอภิมหาสมบัติกองทัพญี่ปุ่น\n",
            "\n",
            "original_text =   กระทั่งตามไปถึงสถานที่ ที่มันใช้กบดานอยู่\n",
            "predicted text = กระทั่งตามไปถึงสถานที่ ที่ันใช้กบดานอยู่\n",
            "\n",
            "original_text =   ในพื้นที่ อ.ไทรโยค อ.ทองผาภูมิ หรือ อ.สังขละบุรี\n",
            "predicted text = ในพื้นที่ อ. ไทรโยค อ.กองผาถูมิ หรือ อ.สังขละบูริ\n",
            "\n",
            "original_text =   คลื่นวิทยุ FM97.5 ร่วมด้วยช่วยกัน\n",
            "predicted text = คลลื่นวิทยูุ ร่.5 ร่วมด้วยช่อยกัน\n",
            "\n",
            "original_text =   ระเบิดลูกแรกทำให้ไอ้ด่าง รู้ตัว และพยายามจะหนี\n",
            "predicted text = ระเบิดลูกแรกทำให้ ไอ้ด่าง รู้ตัว และพยายามจะหนี.\n",
            "\n",
            "original_text =   รถยนต์ของกลาง\n",
            "predicted text = งณAแงึงแอใกล \n",
            "\n",
            "original_text =   ดูด้วยกล้อง จะเห็นรึเปล่าเนี่ย\n",
            "predicted text = ดูด้วยกล้อง จะเห็นรืีเปล่าเนี่ย\n",
            "\n",
            "original_text =   มหาสมุทรอินเดียว\n",
            "predicted text = มหาสมุกรอนคีย \n",
            "\n",
            "original_text =   และกำหนดให้วันที่ 10 พฤษภาคมของทุกปี\n",
            "predicted text = และกำหนดให้วันที 10 พฤษาาคมยองทุกปี\n",
            "\n",
            "original_text =   อย่างเงี้ยหรอ\n",
            "predicted text = อย่างี้ยหรอ\n",
            "\n",
            "original_text =   January 27, 2020\n",
            "predicted text = anuan27,2020\n",
            "\n",
            "original_text =   ยืนยันข่าวร้าย\n",
            "predicted text = ยนยันขาวร้าย\n",
            "\n",
            "original_text =   ต่อมาวันที่ 13 มิถุนายน 2546 ได้มีประกาศราชกิจจาฯใช้\n",
            "predicted text = ต่อมาวับกี่ 13 มิถุนาย0 2546 ไดปีประาาศราชกิจจาหใล้า\n",
            "\n",
            "original_text =   แต่ซุปร้านเนี้ย มันกินกับข้าว แล้วมันอร่อย\n",
            "predicted text = แต่ซุปร้านเนี้ยมันกินกับข้าว แล้วมันอร่อย\n",
            "\n",
            "original_text =   อายุประมาณ 30 ปี รูปร่างเตี้ย\n",
            "predicted text = อายุประมาณ 30 ปี รปร่างเตี้ย\n",
            "\n",
            "original_text =   แค่เพียงมนุษย์\n",
            "predicted text = แค่เพียงมนุษย์\n",
            "\n",
            "original_text =   เกลี้ยงๆ\n",
            "predicted text = กล้ยงๆ\n",
            "\n",
            "original_text =   รถสองแถว ถูกปล้นเรียงรายทุกคัน ไม่เว้น\n",
            "predicted text = รถสองแถว ถูกปล้นเรียงรายทุกคัน ไม่เว้น.\n",
            "\n",
            "original_text =   พบกับที่นอน Memory Foam\n",
            "predicted text = พบกับที่นอน Memory Foaทา\n",
            "\n",
            "original_text =   ที่ยังไม่รู้ชะตากรรม\n",
            "predicted text = ที่ยงไม่รู้ซะตาลรรม\n",
            "\n",
            "original_text =   กลุ่มชายฉกรรจ์ออกลายโจรปล้นทรัพย์สินนักท่องเที่ยว\n",
            "predicted text = กลุ่มชายจกรรจ้ออกลายโจรปล้นทรัพย์สินนักท่องเที่ยว\n",
            "\n",
            "original_text =   เมื่อได้ลิ้มลองเนื้อมนุษย์แล้ว จะหากินอยู่เรื่อยๆ\n",
            "predicted text = เมื่อได้ลิ้มลองเนื้อมนุรย์แล้ว จะหากินอยู่เร่อยๆ\n",
            "\n",
            "original_text =   หรือว่า เคล็ดลับมันคือ ข้าววะ\n",
            "predicted text = หรือว่า เคล็ดลับมันคือ ข้าววะ\n",
            "\n",
            "original_text =   จากนั้นให้ขอขมา ที่เคยทำผิดกับสิ่งที่มองไม่เห็น\n",
            "predicted text = จากนั้นให้ขอขมา ที่เคยทำผิดกับสิ่งที่มองไม่เห็น\n",
            "\n",
            "original_text =   รู้ข้อมูลของนายสมพงษ์เป็นอย่างดี\n",
            "predicted text = รู้ข้อมูลของนายสมพงษ์เป็นอย่างดต\n",
            "\n",
            "original_text =   NOCNOC.COM\n",
            "predicted text = NOCNOC.COM\n",
            "\n",
            "original_text =   มีการแบ่งออกเป็น 3 ประเภท\n",
            "predicted text = มีการเบ่งออกเป็น 3 ประเภห\n",
            "\n",
            "original_text =   แล้วเราจะทำยังไง\n",
            "predicted text = เเลวหราจะาำายั\n",
            "\n",
            "original_text =   ใช่คนเชียงใหม่เค้ากินกันแค่นี้\n",
            "predicted text = ใช่ คนเชียงใหม่เค้ากินกันแค่\n",
            "\n",
            "original_text =   ณ ถ้ำเมืองแก็ด รัฐฉาน ประเทศเมียนมา\n",
            "predicted text = ณ ถ้ำเมืองแก็ด รัฐจาน ประเทศเมียนมา\n",
            "\n",
            "original_text =   ผู้ใดละเมิด ถูกปรับ 2,000 บาท หรือจำขังไม่เกิน 6 เดือน\n",
            "predicted text = ขปดคละม้ด คูกปวัน 20า นา หรือง้ายั์ร์เกิน  ทือ\n",
            "\n",
            "original_text =   ปกติการป้องกันของเรือนจำ\n",
            "predicted text = ปกติการป้องกันของเรือนจำ\n",
            "\n",
            "original_text =   ให้วันเวลาสร้างเราขึ้นใหม่\n",
            "predicted text = วงเตลาสร้ราขึ้นใหม่\n",
            "\n",
            "original_text =   หากหาสมาชิกเพิ่มได้\n",
            "predicted text = หากหาสมาชิกเพิ่มได้ \n",
            "\n",
            "original_text =   เพราะไม่มีใครบ้าขุดดินลึกถึง 6 เมตร\n",
            "predicted text = พราะไม่มีเครบ้ายุดดินลีกถีง6์เมตร\n",
            "\n",
            "original_text =   รอยต่อ ต.หนองจิก และ ต.เชียงรากน้อย\n",
            "predicted text = รอยต่อ ต.หนองจิก และ ต. เชียงรากน้อย\n",
            "\n",
            "original_text =   ชายชราคนนี้อ้างว่าทำธุรกิจส่งข้าวสาร\n",
            "predicted text = ชายชราคนนื้อ้างว่าทำธูรกิจส่งข้าวสาร\n",
            "\n",
            "original_text =   ไหหลำก็เจ้าเก่า\n",
            "predicted text = ไหหลำก็เล้าเก่า\n",
            "\n",
            "original_text =   คดีนี้ต่อสู้กันถึง 3 ศาล ที่สุดแล้ว\n",
            "predicted text = คดีนี้ต่อสู้กันถึง 3 ศาล ที่สุดแล้ว\n",
            "\n",
            "original_text =   ก่อนที่มันจะสายไป\n",
            "predicted text = ก่อนวันท่มันจะสายไป\n",
            "\n",
            "original_text =   เสือตัวสุดท้ายแห่งเมืองกรุงได้\n",
            "predicted text = เสือตัวสุดท้ายแห่งเมืองกรุงได้\n",
            "\n",
            "original_text =   ไม่ให้มีการกวดวิชา\n",
            "predicted text = ไมห้มการกวดวิชา\n",
            "\n",
            "original_text =   เพราะเวลาเดินจะกะเผลกๆ มักจะยืนอยู่ที่หน้าห้องน้ำชาย\n",
            "predicted text = เพราะเวลาเดินจะกะเพลกๆ มักจะยนอยที่หน้าห้องน้ำชาย\n",
            "\n",
            "original_text =   จนกระทั่งสาวนักศึกษาอนาคตไกล\n",
            "predicted text = ูนกระทั่งสาวนักศึกษาอนาคตไกล\n",
            "\n",
            "original_text =   จากนั้นหันหัวกลับกะทันหัน ซึ่งเรดาร์ทางทหารไทย\n",
            "predicted text = จากนั้นหันหัวกลับกะกันหัน ซึ่งเรดาร์างทหารไทย\n",
            "\n",
            "original_text =   เป็นไปได้หรือไม่ กัปตันจะทำเสียเอง\n",
            "predicted text = เป็นไปได้หรือไม่ กัปตันจะทำเสียเอง\n",
            "\n",
            "original_text =   ต้องลงมือเด็ดขาด\n",
            "predicted text = .เอวลงบ้เด็ดยาล\n",
            "\n",
            "original_text =   3 นาที\n",
            "predicted text = \n",
            "\n",
            "original_text =   ซีโฟร์ดับชีพ\n",
            "predicted text = ซีีโโรธันรี\n",
            "\n",
            "original_text =   นี่ถือเป็นนวัตกรรม\n",
            "predicted text = ี่ถือว่าเป็นนวัตกรรม\n",
            "\n",
            "original_text =   บังเอิญลงมานอนที่วัดข้างล่าง พระธาตุ\n",
            "predicted text = ปังเอิญลงมานอนที่วัดข้างล่าง พระธราร\n",
            "\n",
            "original_text =   วันที่ความเป็นธรรมทอแสง...\n",
            "predicted text = วันที่คววามวรเวรัวมมนอเลสง ..\n",
            "\n",
            "original_text =   ถูกยิงนั้น อาจเป็นพวกมือที่ 3\n",
            "predicted text = ถูกยิงนั้น อาจเป็นพวกมือที่ 3\n",
            "\n",
            "original_text =   เมื่อหันกลับมาดูคนในรถ คมกระสุนพุ่งเจาะทะลุเหล็ก\n",
            "predicted text = เมื่อหันกลับมาดูคนในรถ คมกระสุนพู่งเจาะกะลุเหล็ก\n",
            "\n",
            "original_text =   เค้าใช้พลังธรรมชาติบำบัดด้วยค่ะ\n",
            "predicted text = เค้าใช้ลังธรรมซชาติบำบัดด้วยค่ะ\n",
            "\n",
            "original_text =   ส่วนสีสันของลวดลายบนหนังจระเข้นั้น\n",
            "predicted text = ส่วนสีสันของลวดลายบนหนังจระเข้นั้น\n",
            "\n",
            "original_text =   สุดท้ายหงายเงิบ!\n",
            "predicted text = สุด้ายหงายเงิบ!\n",
            "\n",
            "original_text =   คอนโดฯ ราคากว่า 2 ล้าน\n",
            "predicted text = คอนโด. ราคากิว่า 2ล้าน\n",
            "\n",
            "original_text =   30\n",
            "predicted text = 3\n",
            "\n",
            "original_text =   จากการสอบสวนทราบว่า\n",
            "predicted text = จากการสอบสวนทราบว่า\n",
            "\n",
            "original_text =   TEMP COMFORT\n",
            "predicted text = TFNB COMROP\n",
            "\n",
            "original_text =   ไม่ลงทุนเรื่องป้ายร้าน\n",
            "predicted text = ไม่ลงทุนเรื่องป้ายร้าน\n",
            "\n",
            "original_text =   ไม่งั้นหมด\n",
            "predicted text = ไม่งิ้นหมัด\n",
            "\n",
            "original_text =   หม้าที่เค้าทำกับข้าววัด\n",
            "predicted text = หม้อที่เค้าทำกับข้าววัด\n",
            "\n",
            "original_text =   ผสมกับหินแร่ Tourmaline ค่ะ\n",
            "predicted text = ผสมกับหินแร่ ไดนrทาลไime ค่ะ\n",
            "\n",
            "original_text =   สมพงษ์ เลือดทหาร\n",
            "predicted text = สมพงษ์ เลือดทหาร\n",
            "\n",
            "original_text =   (ลงนาม) เจ้าพระยาธรรมาธิกรณาธิบดี\n",
            "predicted text = .ลงนามป เจำพระขาชรรบาช้กธิาาธิบดี\n",
            "\n",
            "original_text =   โดยเป็นการลงทุนร่วมกันระหว่างนักธุรกิจไทยและไต้หวัน\n",
            "predicted text = โดยเป็นการลงทุนร่วมระหว่างน้ทธุรทิไทยและไต้หวัน\n",
            "\n",
            "original_text =   แต่ก็ยังมีคนร่วมแก๊งบางคนที่ยังหลบหนีลอยนวลอยู่\n",
            "predicted text = แต่ก็ยังมีคนร่วมแก็งบางคนที่ยังหลบหนีลอยนวลอฮ่\n",
            "\n",
            "original_text =   มีทฤษฎีสมคบคิดเชื่อว่าสหรัฐฯ\n",
            "predicted text = มีทฤษฎีสมคบคิดเชื่อว่าสหรัฐฯ\n",
            "\n",
            "original_text =   ทุกคดีล้วนเกี่ยวข้องกับทรัพย์สินเงินทอง\n",
            "predicted text = ทุกคดีล้วนเกี่ยวข้องกับทรัพย์สินเงินทอง\n",
            "\n",
            "original_text =   5 มกราคม จีนระบุมีความเป็นไปได้ว่า  โรคซาร์ส\n",
            "predicted text = 5 มกราคม จีนร บมีความเป็นไปได้ว่า  เรคซาร์ส\n",
            "\n",
            "original_text =   จำเลยที่ 8 ผู้ดูแลด้านการเงิน\n",
            "predicted text = จำเลยที่ 8 ผู้ดูแลด้านการเงิน\n",
            "\n",
            "original_text =   ในแวดวงการเมือง\n",
            "predicted text = ในหวววัิงการเมือง\n",
            "\n",
            "original_text =   ต้องเป็นฟอนต์ แบบนี้เท่านั้น\n",
            "predicted text = ลองปน.โอนต์กบบขี้กกน้นา\n",
            "\n",
            "original_text =   ตั้งอยู่ที่ อ.สามพราน จ.นครปฐม\n",
            "predicted text = ตั้งอยู่ที่ อ.สามพราน จ.นครปรม\n",
            "\n",
            "original_text =   ระเบิดลูกหนึ่งโดนกลางหลังไอ้ด่าง\n",
            "predicted text = ระเบิดลูกหนึ่งโดนกลางหลังไอ้ด่าง\n",
            "\n",
            "original_text =   จ่าทหารคนดังกล่าวมาพร้อมลูกน้อง\n",
            "predicted text = จ่ากทหารคนด้งกล่าวมาพรั้อมลูกน้อง\n",
            "\n",
            "original_text =   พบเชื้อร้ายชนิดใหม่อยู่ในตระกูล โคโรน่าไวรัส\n",
            "predicted text = พบเชื้อร้ายชนิดใหม่อยู่ในตระกล โคโรน่าไวรัส\n",
            "\n",
            "original_text =   ซึ่งที่นอนซินด้านะคะ\n",
            "predicted text = ซึ่งที่นอนซินด้านะคะ\n",
            "\n",
            "original_text =   เชื่อไหม ผมมือสั่น ขาสั่น เหงื่อแตกพลั่ก\n",
            "predicted text = เชื่อไหม ผมมือสั่น ขาสั่น เหงื่อแตกพลั่ก\n",
            "\n",
            "original_text =   3 ปมปลิดชีพผู้กว้างขวาง\n",
            "predicted text = 3 ปมปลิดชิพผู้กว้างขวาง\n",
            "\n",
            "original_text =   บ เคเดอร์ และ บ ไทยจิวฟู\n",
            "predicted text = มCLesิ t ม erิวuป\n",
            "\n",
            "original_text =   เลือกใช้เพื่อ\n",
            "predicted text = เลือกใช้เพื่อ\n",
            "\n",
            "original_text =   วันที่ความเป็นธรรมทอแสง...\n",
            "predicted text = วันที่ควาเป็นารราอแส.ง....\n",
            "\n",
            "original_text =   ฉันเคยมี หัวใจ แต่แล้ว ก็โดนทำร้ายไป\n",
            "predicted text = ฉันเคยมี หัวใจ แต่แล้ว ก็โดนกำร้ายไป\n",
            "\n",
            "original_text =   สุเทพ วงศ์กำแหง\n",
            "predicted text = สุเทพ วงศั์กำแหง\n",
            "\n",
            "original_text =   ถ้าในอนาคตการศึกษาไทย\n",
            "predicted text = ้าในอนาดตการศีกษาโกย\n",
            "\n",
            "original_text =   ไอ้โจ๊ก ไอ้จิ๊บ ยิงพลางหนีไปข้างแมนชั่น\n",
            "predicted text = ไอ้โจ๊ก ไอ้จิ๊บ ยิงพลางหนีไปข้างแมนชั่น\n",
            "\n",
            "original_text =   ถ้าจบอย่างนี้\n",
            "predicted text = ถ้าจบอย่างน้\n",
            "\n",
            "original_text =   Search ให้ถูกด้วย\n",
            "predicted text = รearcsา ให้ดูกด้วย\n",
            "\n",
            "original_text =   พอเกิดเหตุร้ายขึ้น\n",
            "predicted text = พอเกิดเหตุร้ายขึ้น\n",
            "\n",
            "original_text =   หรือ น.ส.พสิษฐ์ อริญชย์ลาภิศ\n",
            "predicted text = หรือ น ส พสิษธิ อริญชย์ลากิศ\n",
            "\n",
            "original_text =   แต่\n",
            "predicted text = ต่ั\n",
            "\n",
            "original_text =   สิ่งที่น่าตกตะลึงไปกว่านั้น เมื่อผ่าท้องมันออกมา\n",
            "predicted text = สิ่งที่น่าตกตะลึงไปกว่านั้น เมื่อผ่าท้องมันออกมา\n",
            "\n",
            "original_text =   ที่มาภาพ   ศูนย์ควบคุมโรคระบาดแห่งชาติสหรัฐฯ\n",
            "predicted text = ที่มากาพ ผนย์ควบคุมโรคระบาดแห่งชาติสหรัฐฯ\n",
            "\n",
            "original_text =   อีกด้านหนึ่ง...วันนี้ ก็เป็นวันที่เหล่าพี่ใหญ่\n",
            "predicted text = อีกด้านหนึ่ง.  วันนี้ ก็เป็นวันที่เหล่าพี่ใหญ่\n",
            "\n",
            "original_text =   แต่ถ้ากินข้าวเปล่าๆอะ\n",
            "predicted text = แต่ด้ากินข้าวเปล่าๆ อะ\n",
            "\n",
            "original_text =   ผมเชื่อมั่นหมื่นเปอร์เซนต์\n",
            "predicted text = ผมเซื่อมั่นหมื่นเปอร์เซนต์\n",
            "\n",
            "original_text =   กล้องถ่ายรูป เงินสด ทรัพย์สินเงินทอง\n",
            "predicted text = กล้องถ่ายรูป เงินสด ทรัพย์สินเงิ็น้าอ้ง\n",
            "\n",
            "original_text =   เสียงสุดท้าย\n",
            "predicted text = เสียงสูุดกาย\n",
            "\n",
            "original_text =   ทำไมการศึกษาไทยถึงทำให้เด็กคนหนึ่งมีจุดจบแบบนี้\n",
            "predicted text = ทำไมการศีกษาไคยถึงทำให้เดิกคนหนึ่งมีจุดจบแนนน้\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRAdcqbS-2OC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "28b300c8-f488-4369-fcfc-78a441674b3e"
      },
      "source": [
        "print(history.history.keys())\n",
        "# Visualize training history\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "#print(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "#print(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['val_loss', 'loss'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'val_loss'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KjFwG5M4I5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}